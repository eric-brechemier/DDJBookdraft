--- /Users/jwyg/Downloads/DataJournalismHandbook.txt
+++ DataJournalismHandbook_UFT8.txt
@@ -16,6 +16,8 @@
 
 ////
 
+image::Figures/00-01.jpg[width=600]
+
 
 The Data Journalism Handbook was born at a 48 hour workshop at MozFest 2011 in London. It subsequently spilled over into an international, collaborative effort involving dozens of data journalism's leading advocates and best practitioners.
 
@@ -41,9 +43,9 @@
   * John Bones, Verdens Gang
   * Marianne Bouchart, Data Journalism Blog
   * Liliana Bounegru, European Journalism Centre
-  * Brian Boyer, Tribune
+  * Brian Boyer, Chicago Tribune
   * Jane Park, Creative Commons
-  * Paul Bradshaw, Birmingham City University, City University London
+  * Paul Bradshaw, Birmingham City University + City University London
   * Wendy Carlisle, ABC News
   * Lucy Chambers, Open Knowledge Foundation
   * Helen Darbishire, Access Info Europe
@@ -64,7 +66,7 @@
   * John Keefe, New York Public Radio
   * Friedrich Lindenberg, Open Knowledge Foundation
   * Mirko Lorenz, Deutsche Welle
-  * Esa M√§kinen, Helsingin Sanomat
+  * Esa Mäkinen, Helsingin Sanomat
   * Lorenz Matzat, OpenDataCity
   * David McCandless, Information Is Beautiful
   * Geoff McGhee, Stanford University
@@ -73,7 +75,7 @@
   * Claire Miller, WalesOnline
   * Cynthia O'Murchu, Financial Times
   * Aron Pilhofer, New York Times
-  * Cl√©ment Renaud, Sharism Lab?
+  * Clément Renaud, Sharism Lab?
   * Anthony Reuben, BBC
   * Simon Rogers, Guardian Datablog
   * Martin Rosenbaum, BBC
@@ -84,7 +86,7 @@
   * Andrew Vande Moere, infosthetics.com
   * Sascha Venohr, Zeit Online
   * Jerry Vermanen, De Stentor
-  * César Viana, Estacio de Sa University
+  * César Viana, Federal University of Goiás
   * Farida Vis, University of Leicester
   * Luk N. Van Wassenhove (Affiliation?)
 
@@ -102,7 +104,7 @@
 
 Lamentably the act of reading this book will not supply you with a comprehensive repertoire of all if the knowledge and skills you need to become a data journalist. This would require a vast library manned by hundreds of experts able to help answer questions on hundreds of topics. Luckily this library exists and it is called the internet. Instead we hope this book will give you a sense of how to get started and where to look if you want to go further. Examples and tutorials serve to be illustrative rather than exhaustive.
 
-The Data Journalism Handbook is a work in progress. If you think there is anything which needs to be amended or is conspicuously absent, then please flag it for inclusion in the next version. It is also freely available under a Creative Commons Attribution Sharealike license, and we strongly encourage you to share it with anyone that you think might be interested in reading it.
+The Data Journalism Handbook is a work in progress. If you think there is anything which needs to be amended or is conspicuously absent, then please flag it for inclusion in the next version. It is also freely available under a http://creativecommons.org/licenses/by-sa/2.5/[Creative Commons Attribution Sharealike] license, and we strongly encourage you to share it with anyone that you think might be interested in reading it.
 
 == 1. Introduction ==
 
@@ -116,11 +118,23 @@
 
 === What is data journalism? by Paul Bradshaw (City University) ===
 
+////
+
+Comments:
+
+Made minor revisions to the text.
+
+This is opening section, hence very important to set the scene and explain what data journalism is.
+
+Could we expand this section so that each of the examples mentioned below has a sentence or two explaining what it is about, and how it augments and is distinctive from traditional journalism?
+
+////
+
 What is data journalism? I could answer, simply, that it is journalism done with data. But that doesn't help much.
 
 Both `data' and `journalism' are troublesome terms. Some people think of `data' as any collection of numbers, most likely gathered on a spreadsheet. 20 years ago, that was pretty much the only sort of data that journalists dealt with. But we live in a digital world now, a world in which almost anything can be - and almost everything is - described with numbers.
 
-Your career history; 300,000 confidential documents; who knows who in your circle of friends can all be - and are - described with just two numbers: zeroes, and ones. Photos, video and audio are all described with the same two numbers: zeroes and ones. Murders, disease, political votes, corruption and lies: zeroes and ones.
+Your career history, 300,000 confidential documents, who knows who in your circle of friends can all be - and are - described with just two numbers: zeroes, and ones. Photos, video and audio are all described with the same two numbers: zeroes and ones. Murders, disease, political votes, corruption and lies: zeroes and ones.
 
 What makes data journalism different to the rest of journalism? Perhaps it is the new possibilities that open up when you combine the traditional `nose for news' and ability to tell a compelling story, with the sheer scale and range of digital information now available.
 
@@ -128,27 +142,40 @@
 
 Or using software to find connections between hundreds of thousands of documents, as The Telegraph did with http://www.telegraph.co.uk/news/newstopics/mps-expenses/[MPs' expenses].
 
-Data journalism can help a journalist tell a complex story through engaging infographics - such as Hans Rosling's talks on world poverty or David McCandless's visualisation work. Or it can help explain how a story relates to an individual, as the BBC and FT now routinely do with their budget interactives. And it can open up the newsgathering process itself, as The Guardian do so successfully with their DataBlog.
+Data journalism can help a journalist tell a complex story through engaging infographics - such as Hans Rosling's talks on world poverty with http://www.gapminder.org/[Gapminder] or David McCandless's visualisation work with http://www.informationisbeautiful.net/[Information is Beautiful]. Or it can help explain how a story relates to an individual, as the BBC and FT now routinely do with their budget interactives. And it can open up the newsgathering process itself, as The Guardian do so successfully with their http://www.guardian.co.uk/news/datablog[Datablog].
 
 Data can be the source of data journalism, or it can be the tool with which the story is told - or it can be both. Like any source, it should be treated with scepticism; and like any tool, we should be conscious of how it can shape and restrict the stories that are created with it.
 
 === Why journalists should use data by Mirko Lorenz (Deutsche Welle) ===
 
-Journalism is under siege. In the past we relied on being the only ones operating a technology to multiply and distribute what had happened over night. The printing press served as a gateway, if anybody wanted reach the people of a city or region the next morning, they would turn to newspapers.
+////
+
+Have made some substantial edits.
+
+This section could benefit from a greater focus on incentives for journalists to use data, preferably with more examples.
+
+If data journalism is an investment of time or money (which it almost always will be) - what kinds of benefits could freelance journalists or ordinary newsrooms hope to see?
+
+If this is the main writeup of the survey (which I believe that it is), then I think this could merit a bit more detail from the write-up. E.g. what makes newsrooms excited about data journalism?
+
+////
 
-This is over.
+Journalism is under siege. In the past we relied on being the only ones operating a technology to multiply and distribute what had happened over night. The printing press served as a gateway, if anybody wanted reach the people of a city or region the next morning, they would turn to newspapers. This is over.
 
 Today news stories are flowing in as they happen, from multiple sources, eye-witnesses, blogs and what has happened is filtered through a vast network of social connections, being ranked, commented and more often than not: ignored.
 
-This is why data journalism is so important. Gathering, filtering and visualizing what is happening beyond what the eye can see has a growing value. The orange juice you drink in the morning, the coffee you brew - in today's global economy there are invisible connections between things, networks and people. The language of this network is data: Little points of information that are often not relevant in a single instance, but massively important when viewed from the right angle.
+This is why data journalism is so important. Gathering, filtering and visualizing what is happening beyond what the eye can see has a growing value. The orange juice you drink in the morning, the coffee you brew - in today's global economy there are invisible connections between things, networks and people. The language of this network is data: little points of information that are often not relevant in a single instance, but massively important when viewed from the right angle.
 
-Right now, a few pioneering journalists already demonstrate how data can be used to create revealing, surprising and deeper insights into what is happening around us and how it might affect us. All of us.
+////
+"things, networks and people" - perhaps reword this to clarify?
+"the language of this network" - which network?
+////
 
-Data analysis can reveal http://www.poynter.org/latest-news/top-stories/95154/using-data-visualization-as-a-reporting-tool-can-reveal-storys-shape/ ["a story's shape"] (Sarah Cohen), provides a http://www.informationisbeautiful.net/ ["new camera"] (David McCandless). To get to that point the data investigation must be done in a step by step process that is in some ways similar to uncovering a lost city from the dirt by slowly brushing away all the stuff that keeps us from seeing its structure.
+Right now, a few pioneering journalists already demonstrate how data can be used to create deeper insights into what is happening around us and how it might affect us.
 
-Why journalists should use data
+Data analysis can reveal "a story's shape" (Sarah Cohen). It provides a "new camera" (David McCandless). To get to that point the data investigation must be done in a step by step process that is in some ways similar to uncovering a lost city from the dirt by slowly brushing away all the stuff that keeps us from seeing its structure.
 
-But why should - of all professions - journalists be more interested in learning how to work with data when doing research for stories? There are several reasons: First, journalists are a group in society taking care of distributing what is relevant. At least if they are good. How this is done might sometimes be to the point and very inspiring, at other times sloppy, rushed and even misconstruing the facts. But, quite simply, in doing this job journalists (insert: writers, photographers, film makers) strive to help us understand, and this is important.
+But why should journalists be interested in learning how to work with data when doing research for stories? There are several reasons: First, journalists are help to identify and disseminate what is important and relevant. At least if they are good. How this is done might sometimes be incisive and inspiring, at other times sloppy, over-hasty or misleading. But, quite simply, in doing this job journalists strive to help us understand the world around us.
 
 Using data the job of journalists shifts its main focus from being the first ones to report to being the ones telling us what a certain development might actually mean. The range of topics can be far and wide. The next financial crisis that is in the making. The economics behind the products we use. The misuse of funds or political blundery.
 
@@ -158,15 +185,25 @@
 
 On the other side: What choice do we as journalists have? Working with data can provide us with deep, original ways to report about what is going on. Once the data is "speaking" to us, all of sudden a very rich source to tell stories has opened up.
 
-And, increasingly, journalists see that particular opportunity. Judging on the results of a http://datadrivenjournalism.net/news_and_analysis/training_data_driven_journalism_mind_the_gaps[survey] we conducted to find out more about training needs for data journalism, there is a big willingness to get out of the comfort zone of traditional journalism and invest time to master the new skills. The results from the survey showed us that journalists are "seeing" the opportunity, but need a bit of support to cut through the initial problems keeping them from working with data. There is a confidence, that should data journalism get more adopted, the work flows, the tools and the results will improve quite quickly. The pacemakers, such as the Multimedia team of the New York Times, The Guardian Data Blog, the Texas Tribune, and Die Zeit play an important role by being willing to publish such stories.
+And, increasingly, journalists see that particular opportunity. The European Journalism Centre http://datadrivenjournalism.net/news_and_analysis/training_data_driven_journalism_mind_the_gaps[conducted a survey] to find out more about training needs of journalists. We found there is a big willingness to get out of the comfort zone of traditional journalism and invest time to master the new skills. The results from the survey showed us that journalists are "seeing" the opportunity, but need a bit of support to cut through the initial problems keeping them from working with data. There is a confidence, that should data journalism get more adopted, the work flows, the tools and the results will improve quite quickly. Pioneers such as the Guardian, the New York Times, the Texas Tribune and Die Zeit continue to raise the bar with their data-driven stories. 
+
+Will data journalism remain the preserve of a small handful of pioneers - or will every news organisation soon have its own dedicated data journalism team? We hope this handbook will help more journalists and newsrooms to take advantage of this emerging field.
+
+=== Why is data journalism important? by Various Contributors ===
+
+////
+
+Todo: add quotes from Simon Rogers on how data journalism is just journalism done well
+
+Todo: review secondary literature and see if there are other quotes we could use or adapt, or if there is anyone else that we should ask.
 
-As of now, we should not be too confident this data journalism will be more than a passing trend. There is potential, but as of now single journalists and newsrooms as a whole need to overcome the barriers keeping us from telling stories out of the data.
+Todo: ask Chris Taggart for something on this - along lines of his talk in Utrecht.
 
-This handbook provides one step towards that goal. It might not provide the total information needed to master data journalism, but it shows the enthusiasm, the power and the hope associated with it.
+Todo: ask nearly everyone who can write well who has contributed to the handbook for quotes on this. We can pick the best ones.
 
-Come join us.
+////
 
-=== What is it good for? Notes from the field ===
+We asked some of data journalism's leading practitioners and proponents why they think data journalism is an important development. Here is what they said.
 
 *Filtering the flow of data*
 [quote, Philip Meyer (University of North Carolina at Chapel Hill)]
@@ -273,19 +310,9 @@
 From the standpoint of a regional newspaper, data journalism is crucial. We have the saying `a loose tile in front of your door is considered more important than a riot in a far-away country'. It's hits you in the face and impacts your life more directly. At the same time, digitization is everywhere. Because local newspapers have this direct impact in their neighbourhood and sources become digitalized, a journalist must know how to find, analyze and visualize a story from data.
 ____
 
-////
-
-Todo: add quotes from Simon Rogers on how data journalism is just journalism done well
-
-////
+=== Favourite examples by Various Contributors ===
 
-=== Our favourite examples ===
-
-////
-
-Todo: collect screenshots + quotes from leading data journalists on their favourite examples
-
-////
+We asked some of our contributors for their favourite examples of data journalism and what they liked about them. Here they are.
 
 === Data journalism in perspective by Liliana Bounegru (European Journalism Centre) ===
 
@@ -295,7 +322,7 @@
 
 ////
 
-== 2. In the newsroom ==
+== 2. In The Newsroom ==
 
 
 ////
@@ -312,22 +339,26 @@
 
 todo - little overview in frame narrative
 
-https://docs.google.com/a/intern.ejc.net/document/d/1rvWcdQOeWBgptxc2nQ6sPWX9QFZlkWjJXtGn_P5KdJg/edit#heading=h.48i5dkjgacox[How is it done: journo-developers vs. coders for hire]
+How is it done: journo-developers vs. coders for hire
 
-https://docs.google.com/a/intern.ejc.net/document/d/1rvWcdQOeWBgptxc2nQ6sPWX9QFZlkWjJXtGn_P5KdJg/edit#heading=h.n5gcra9jo9fl[Overview]
+Overview
 In-house expertise
 How the news apps team at Chicago Tribune works
 Projects realized with external experts
-https://docs.google.com/a/intern.ejc.net/document/d/1rvWcdQOeWBgptxc2nQ6sPWX9QFZlkWjJXtGn_P5KdJg/edit#heading=h.ed1kfj2dcjbd[In-house resources plus external open data & visualisation expertise: the ZEIT-ONLINE model]
-https://docs.google.com/a/intern.ejc.net/document/d/1rvWcdQOeWBgptxc2nQ6sPWX9QFZlkWjJXtGn_P5KdJg/edit#heading=h.gt9872yppj1u[How to hire a hacker: Where to look]
-https://docs.google.com/a/intern.ejc.net/document/d/1rvWcdQOeWBgptxc2nQ6sPWX9QFZlkWjJXtGn_P5KdJg/edit#heading=h.gmg2axs7qqr[The Hackathon Model: RegioHack, a 30 hour datajournalism hackathon with regional subjects (Netherlands)]
+In-house resources plus external open data & visualisation expertise: the ZEIT-ONLINE model
+How to hire a hacker: Where to look
+The Hackathon Model: RegioHack, a 30 hour datajournalism hackathon with regional subjects (Netherlands)
 ////
 
+////
+To incorporate into short intro:
+
 A http://datadrivenjournalism.net/news_and_analysis/data_journalism_survey_analysis[survey] on training needs for data journalism circulated by the European Journalism Centre between April and August 2011 showed that 39% of the 234 respondents envisioned their organisation to start engaging in data journalism through engaging a combination of external experts and existing staff. 36% envisioned training existing staff.
 
 In the following chapter journalists involved in data journalism projects explain models for doing data journalism in their newsroom.
 
 In-house expertise
+////
 
 === How the news apps team at Chicago Tribune works by Brian Boyer (Chicago Tribune) ===
 
@@ -337,7 +368,7 @@
 
 ////
 
-The news applications team at the Chicago Tribune is a band of happy hackers embedded in the newsroom. We work closely with editors and reporters to help 1) research and report stories, 2) illustrate stories online and 3) build evergreen web resources for the fine people of Chicagoland.
+The news applications team at the Chicago Tribune is a band of happy hackers embedded in the newsroom. We work closely with editors and reporters to help: (1) research and report stories, (2) illustrate stories online and (3) build evergreen web resources for the fine people of Chicagoland.
 
 It's important that we sit in the newsroom. We usually find work via face-to-face conversations with reporters. They know that we're happy to help write a screen scraper for a crummy government website, tear up a stack of PDFs, or otherwise turn non-data into something you can analyze. It's sort of our team's loss leader -- this way we find out about potential data projects at their outset.
 
@@ -351,23 +382,23 @@
 
 Some datasets or methods require special skills i.e. programming skills to manage the data and visualize it. Don't stop your passion for your idea because of missing these skills in your newsroom. There are a lot of highly motivated developers and designers out there to come into your project.
 
-===  The ABC’s data journalism play by Wendy Carlisle ===
+===  The ABC's data journalism play by Wendy Carlisle ===
 
-Now in its 70th year the Australian Broadcasting Corporation is Australia’s national public broadcaster. Annual funding is around AUS$1bn which delivers seven radio networks, 60 local radio stations, three digital television services, a new international television service and an online platform to deliver this ever expanding offering of digital and user generated content. At last count there were in excess of 4,500 full time equivalent staff and nearly 70% of them make content.
+Now in its 70th year the Australian Broadcasting Corporation is Australia's national public broadcaster. Annual funding is around AUS$1bn which delivers seven radio networks, 60 local radio stations, three digital television services, a new international television service and an online platform to deliver this ever expanding offering of digital and user generated content. At last count there were in excess of 4,500 full time equivalent staff and nearly 70% of them make content.
 
-We are a national broadcaster fiercely proud of our independence – because although funded by government – we are separated at arm’s length through law. Our traditions are independent public service journalism. The ABC is regarded the most trusted news organisation in the country.
+We are a national broadcaster fiercely proud of our independence ‚Äì because although funded by government ‚Äì we are separated at arm's length through law. Our traditions are independent public service journalism. The ABC is regarded the most trusted news organisation in the country.
 
-These are exciting times  and under a managing director – the former newspaper executive Mark Scott – content makers at the ABC have been encouraged to  as the   corporate mantra puts it – be “agile”. 
+These are exciting times  and under a managing director ‚Äì the former newspaper executive Mark Scott ‚Äì content makers at the ABC have been encouraged to  as the   corporate mantra puts it ‚Äì be ‚Äúagile‚Äù. 
 
-Of course that’s easier said than done. 
+Of course that's easier said than done. 
 
 But one initiative in recent times designed to encourage this has been  a competitive staff pitch for money to develop multi-platform projects.
 
-This is how the ABC’s first ever data journalism project was conceived.
+This is how the ABC's first ever data journalism project was conceived.
 
-Sometime early in 2010 I wandered into the pitch session to face with three senior “ideas” people with my proposal.
+Sometime early in 2010 I wandered into the pitch session to face with three senior ‚Äúideas‚Äù people with my proposal.
 
-I’d been chewing it over for some time. Greedily lapping up the data journalism that the now legendary Guardian data journalism blog was offering, and that was just for starters.
+I'd been chewing it over for some time. Greedily lapping up the data journalism that the now legendary Guardian data journalism blog was offering, and that was just for starters.
 
 It was my argument that no doubt within 5 years the ABC would have its own data journalism unit. It was inevitable, I opined. But the question was how are we going to get there, and whose going to start.
 
@@ -375,13 +406,13 @@
 
 It is of course a work in progress. 
 
-But something else was happening with data journalism. Government 2.0 (which as we discovered is largely observed in the breach in Australia) was starting to offer new ways of telling stories that were hitherto buried in the zero’s and dots.
+But something else was happening with data journalism. Government 2.0 (which as we discovered is largely observed in the breach in Australia) was starting to offer new ways of telling stories that were hitherto buried in the zero's and dots.
 
 All this I said to the folk during my pitch. I also said we needed to identify new skills sets, train journalists in new tools. We needed a project to hit play. 
 
-And they gave me the money. 
+And they gave me the money.‚Ä®
 
-On the 24th of November 2011 the ABC’s multiplatform project and ABC News Online went live with “Coal Seam Gas by the Numbers” 
+On the 24th of November 2011 the ABC's multiplatform project and ABC News Online went live with ‚ÄúCoal Seam Gas by the Numbers‚Äù 
 
 http://www.abc.net.au/news/specials/coal-seam-gas-by-the-numbers/promise/
 
@@ -394,7 +425,7 @@
 ////
 
 
-It wasn’t exclusively data journalism – but a hybrid of journalisms that was born of the mix of people on the team and the story, which to put in context is raging as one of the hottest issues in Australia.  
+It wasn't exclusively data journalism ‚Äì but a hybrid of journalisms that was born of the mix of people on the team and the story, which to put in context is raging as one of the hottest issues in Australia.  
 
 The jewel was an interactive map showing coal seam gas wells and leases in Australia. Users could search by location and switch between modes to show leases or wells. By zooming in users could see who the explorer was, the status of the well and its drill date.  Another map showed the location of coal Seam gas activity compared to the location of groundwater systems in Australia. 
 
@@ -410,7 +441,7 @@
   * A part time junior journalist.
   * A consultant executive producer
   * A academic consultant with expertise in data mining, graphic visualisation and advanced research skills.
-  * The services of a project manager and the administrative assistance of the ABC’s multi-platform unit.
+  * The services of a project manager and the administrative assistance of the ABC's multi-platform unit.
   * Importantly we also had a reference group of journalists and others whom we consulted on a needs basis.
 
 *Where did we get the data from?*
@@ -421,11 +452,11 @@
 
 The data on chemical releases was taken from Environmental permits issued by the government. 
 
-*“The Learnings”*
+*‚ÄúThe Learnings‚Äù*
 
 Coal seam gas by the numbers was an ambitious in content and scale.  Uppermost in my mind was what did we learn and how might we do it differently next time?
 
-The data journalism project brought a lot of people into the room who do not normally meet at the ABC. In lay terms – the hacks and the hackers. Many of us did not speak the same language or even appreciate what the other does.  Data journalism is disruptive!   
+The data journalism project brought a lot of people into the room who do not normally meet at the ABC. In lay terms ‚Äì the hacks and the hackers. Many of us did not speak the same language or even appreciate what the other does.  Data journalism is disruptive!   
 
 The practical things:
 
@@ -433,16 +464,16 @@
   * Our consultant EP was also on another level of the building. We needed to be much closer, just for the drop-by factor
   * Choose a story that is solely data driven.
 
-**The big picture…some ideas.**
+**The big picture‚Ä¶some ideas.**
 
-  * Big media organisations need to engage in capacity building to meet the challenges of data journalism. My hunch is there are a lot of geeks and hackers hiding in media technical departments desperate to get out. So –we need “hack and hacker meets” workshops where the secret geeks, younger journalists, web developers and designers come out to play with more experienced journalists for skill sharing and mentoring. Task: download this data set and go for it! 
+  * Big media organisations need to engage in capacity building to meet the challenges of data journalism. My hunch is there are a lot of geeks and hackers hiding in media technical departments desperate to get out. So ‚Äìwe need ‚Äúhack and hacker meets‚Äù workshops where the secret geeks, younger journalists, web developers and designers come out to play with more experienced journalists for skill sharing and mentoring. Task: download this data set and go for it! 
   * Ipso facto Data journalism is interdisciplinary.  DJ teams are made of people who would not in the past have worked together. The digital space has blurred the boundaries/
-  * We live in a fractured, distrustful body politic.  The digital space makes everyone a content maker…we can all be journalists now, right?  Wrong. Journalists need to reassert themselves as ethical, trustworthy, honest story tellers.  Data journalism offers the opportunity to turn  the signal to noise ratio into something we can all understand. Journalists are going to need to be literate in data journalism tools to
+  * We live in a fractured, distrustful body politic.  The digital space makes everyone a content maker‚Ä¶we can all be journalists now, right?  Wrong. Journalists need to reassert themselves as ethical, trustworthy, honest story tellers.  Data journalism offers the opportunity to turn  the signal to noise ratio into something we can all understand. Journalists are going to need to be literate in data journalism tools to
   * Data journalism is still all about story telling. 
   * Increasingly the journalists of tomorrow will be   data journalists.
-  * Australia is behind Europe and the United States in data journalism. Why? That’s another discussion….
+  * Australia is behind Europe and the United States in data journalism. Why? That's another discussion‚Ä¶.
 
-Wendy Carlisle has been an ABC journalist for 20 years and is primarily an investigative reporter working with radio’s investigative program “Background Briefing” and the Four Corners program on ABC TV.  She was the lead journalist on “Coal Seam gas: by the Numbers” 
+Wendy Carlisle has been an ABC journalist for 20 years and is primarily an investigative reporter working with radio's investigative program ‚ÄúBackground Briefing‚Äù and the Four Corners program on ABC TV.  She was the lead journalist on ‚ÄúCoal Seam gas: by the Numbers‚Äù 
 Background Briefing http://www.abc.net.au/radionational/programs/backgroundbriefing/
 Four Corners http://www.abc.net.au/4corners/
 
@@ -454,7 +485,7 @@
 
 ////
 
-The http://opendata.zeit.de/pisa-wohlstands-vergleich/visualisierung.php#/en/DEU-OECD[PISA] based Wealth Comparison project is an interactive visualisation that enables comparison of standards of living in different countries. The interactive uses data from the OECD's comprehensive world education ranking report, http://en.wikipedia.org/wiki/Programme_for_International_Student_Assessment[PISA 2009], published in December 2010. The report is based on a questionnaire which asks fifteen-year-old pupils about their living situation at home.
+The PISA based Wealth Comparison project is an interactive visualisation that enables comparison of standards of living in different countries. The interactive uses data from the OECD's comprehensive world education ranking report, PISA 2009, published in December 2010. The report is based on a questionnaire which asks fifteen-year-old pupils about their living situation at home.
 
 The idea was to analyse and visualise this data to provide a unique way of comparing standards of living in different countries.
 
@@ -467,9 +498,9 @@
 
 With the help of the internal design team these facts were translated into self-explanatory icons. A front end design was built to make comparison between the different countries like in a card-game possible.
 
-Next we contacted people from the http://opendata-network.org/[German Open Data Network] to find developers who could help with the project. This community of highly motivated people suggested https://twitter.com/#!/driven_by_data[Gregor Aisch], a very talented information designer, to code the application that would make our dreams come true (Flash-free#, which is important to us!). Based on the http://raphaeljs.com/[Raphaël-Javascript Library] he created a very high quality and interactive visualisation with a beautiful bubble-style.
+Next we contacted people from the German Open Data Network to find developers who could help with the project. This community of highly motivated people suggested Gregor Aisch, a very talented information designer, to code the application that would make our dreams come true (Flash-free#, which is important to us!). Based on the Rapha√´l-Javascript Library he created a very high quality and interactive visualisation with a beautiful bubble-style.
 
-The result of our hand in hand work was a very successful interactive which got a lot of traffic and because of the easy possibility to combine two countries by URL. We can re-use the tool in our daily editorial work (i.e. on the coverage of the living situation in Indonesia we can have a quick view on the http://opendata.zeit.de/pisa-wohlstands-vergleich/visualisierung.php#/en/DEU-IDN [situation in that country] compared to Germany. The know-how transferred to our in house-team was a great starting-capital for future projects.
+The result of our hand in hand work was a very successful interactive which got a lot of traffic and because of the easy possibility to combine two countries by URL. We can re-use the tool in our daily editorial work (i.e. on the coverage of the living situation in Indonesia we can have a quick view on the situation in that country compared to Germany. The know-how transferred to our in house-team was a great starting-capital for future projects.
 
 For links and more information related to this case study. Please see the appendix.
 
@@ -485,13 +516,13 @@
 
 Hiring and Engaging
 
-  * Post on coders jobs boards e.g. the http://www.python.org/community/jobs/[Python Job Board]
-  * Disseminate ads via mailing lists. http://www.ire.org/resource-center/listservs/subscribe-nicar-l/[NICAR-L] and the http://lists.okfn.org/mailman/listinfo/data-driven-journalism[Data-Driven-Journalism List] are two notably popular ones.
-  * Organisations such as https://scraperwiki.com/[Scraperwiki] have a great address book of trusted and willing coders who can be hired for individual scraping tasks.
+  * Post on coders jobs boards e.g. the Python Job Board
+  * Disseminate ads via mailing lists. NICAR-L and the Data-Driven-Journalism List are two notably popular ones.
+  * Organisations such as Scraperwiki have a great address book of trusted and willing coders who can be hired for individual scraping tasks.
 
 Making contacts & possibilities for collaboration
 
-  * Look out for groups such as http://hackshackers.com/[Hacks/Hackers] which bring techies together with the media community - now springing up all over the world
+  * Look out for groups such as Hacks/Hackers which bring techies together with the media community - now springing up all over the world
   * Local Interest Communities: A quick Google e.g. Javascript + (Location) will usually bring you some interesting results. Sites such as Meetup.com - are also great places to look.
   * Hackathons & Competitions. Whether or not there is prize money available: app and visualisation competitions and development days are often fruitful ground for collaboration and making connections.
   * Ask a nerd! Nerds hang around with more nerds, as seen in Sascha's example, communities such as the open data community are often good places to start.
@@ -506,13 +537,13 @@
 
 Introduction
 
-March 2010, an digital culture organisation in Utrecht called SETUP held an event titled http://setup.nl/content/hacking-journalism[Hacking Journalism]. In a room filled with programmers, nerds and journalists, the need for collaboration between these people was evident.
+March 2010, an digital culture organisation in Utrecht called SETUP held an event titled Hacking Journalism. In a room filled with programmers, nerds and journalists, the need for collaboration between these people was evident.
 
 'We organize hackathons to make cool applications, but we can't recognise interesting stories in data. What we build has no social relevance', said the programmers. 'We recognize the importance of data journalism, but we miss the technical skills to really dig into this field', according to the journalists.
 
 Working for a regional newspaper, there was no money or incentive to hire a programmer for the newsroom. Besides that, data journalism was still an unproven discipline at that time for Dutch newspapers.
 
-The hackathon model seemed perfect. An unconstrained environment for collaboration, especially when combined with pizza and energy drink. http://www.regiohack.nl/[RegioHack] was a hackathon organised by my employer, the regional newspaper http://www.destentor.nl/[de Stentor], our sister publication http://www.tctubantia.nl/[TC Tubantia] and http://saxion.nl/[Saxion Hogescholen Enschede], who provided the location for the event.
+The hackathon model seemed perfect. An unconstrained environment for collaboration, especially when combined with pizza and energy drink. RegioHack was a hackathon organised by my employer, the regional newspaper de Stentor, our sister publication TC Tubantia and Saxion Hogescholen Enschede, who provided the location for the event.
 
 Main goals
 
@@ -532,13 +563,13 @@
 
 Results
 
-Before the event, TC Tubantia had an interview with the widow of a policeman who had written a book on her husband's working years. She also had a document with all registered murders in the eastern part of the Netherlands, maintained by her husband since 1945. Normally, we would publish this document on our website. This time, we made a http://www.tctubantia.nl/regio/9810350/Moord-en-doodslag-in-Twente.ece[dashboard in Tableau software]. We also http://www.regiohack.nl/regiohack-blog/een-moord-voor-goede-gegevens/[blogged] about how this came together on our RegioHack site.
+Before the event, TC Tubantia had an interview with the widow of a policeman who had written a book on her husband's working years. She also had a document with all registered murders in the eastern part of the Netherlands, maintained by her husband since 1945. Normally, we would publish this document on our website. This time, we made a dashboard in Tableau software. We also blogged about how this came together on our RegioHack site.
 
-During the hackathon, one project group came up with the subject of development of schools and the ageing of our region. http://public.tableausoftware.com/views/Krimpleerlingaantalshrinkingnumberofstudents/Dashboard1?:embed=yes&:toolbar=yes&:tabs=yes[By making a visualisation of future projections], we understood which cities would get in trouble after a few years of decline in enrollments. With this insight, we made an article on how this would affect schools in our region.
+During the hackathon, one project group came up with the subject of development of schools and the ageing of our region. By making a visualisation of future projections, we understood which cities would get in trouble after a few years of decline in enrollments. With this insight, we made an article on how this would affect schools in our region.
 
 We also started a very ambitious project, called De Tweehonderd van Twente (in English, The Two Hundred of Twente) to determine who had the most power in our region and build a database of the most influential people. Through a Google-ish calculation - who has the most ties with powerful organisations - a list of influential people will be composed. This could lead to a series of articles, but it's also a powerful tool for journalists. Who has connections with who? You can ask questions to this database and use it in our daily routine. Also, this database has cultural value. Artists already asked if they could use this database when finished to make interactive art installations.
 
-After RegioHack, we noticed that journalists considered data journalism as a viable addition to traditional journalism. My colleagues continued to use and build on the techniques learned on the day to create more ambitious and technical projects such as a database of the administrative costs of housing. With this data, I made http://www.destentor.nl/regio/10168441/.ece[an interactive map in Fusion Tables]. We asked our readers to play around with the data and crowdsourced results (http://tjoadesign.nl/blog/?p=439[here], for example). After a lot of questions on how we made a map in Fusion Tables, I also recorded a http://www.jerryvermanen.nl/2012/01/tutorial-fusion-tables/[video tutorial].
+After RegioHack, we noticed that journalists considered data journalism as a viable addition to traditional journalism. My colleagues continued to use and build on the techniques learned on the day to create more ambitious and technical projects such as a database of the administrative costs of housing. With this data, I made an interactive map in Fusion Tables. We asked our readers to play around with the data and crowdsourced results (here, for example). After a lot of questions on how we made a map in Fusion Tables, I also recorded a video tutorial.
 
 What did we learn?
 
@@ -611,9 +642,9 @@
 * National Prosecuting Authority - Pablo Parenti
 Coordination and Monitoring Unit of the Causes of Human Rights of the Attorney General's Office, Research Tools (Excalibur)
 
-* Asociaci√≥n Nunca M√°s + Gabriel Acquistapace (Drupal)
+* Asociaci‚àö‚â•n Nunca M‚àö¬∞s + Gabriel Acquistapace (Drupal)
 
-* No time contacted the Forensic Anthropology Team and Memoria Abierta, or the work of In√©s Caridi, Faculty of Sciences of the UBA, who made a mathematical model for Forensic Anthropology. Each of these projects have different types of quality, quantity and availability of public or private documents, but more or less similar purposes.
+* No time contacted the Forensic Anthropology Team and Memoria Abierta, or the work of Inés Caridi, Faculty of Sciences of the UBA, who made a mathematical model for Forensic Anthropology. Each of these projects have different types of quality, quantity and availability of public or private documents, but more or less similar purposes.
 
 What could serve mapa76?
 Both journalists and investigators, prosecutors, witnesses, can use it to establish relationships between disappeared, places, dates and conditions of detention.
@@ -634,7 +665,7 @@
 One way to understand the behavior patterns of Mapa76.info would be: the user uploads a document. This is analyzed by the software of automatic data extraction. Then the user chooses a person and paragraphs in which choose the name mentioned, the relevant dates and places related to the time.
 
 Call for hackathon
-We make a public announcement through the page Hacks/Hackers Buenos Aires http://meetupba.hackshackers.com At that time we had about 200 enrolled, there are currently about 540. We also called Human Rights associations and made a formal request for the hackathon in Tecnopolis, a vast exhibition organized by the national government dedicated to science in Argentina, which occurred place within the former Batallon 601, the base of military operations in the dictatorship government. The meeting was attended by about forty people including journalists, militant organizations, developers and designers. Other participants of hackathon were Junar makers of a platform for "streaming" data to organize the information automatically and export it to other websites. We received sponsorship from Mozilla Argentina and Tecn√≥polis.
+We make a public announcement through the page Hacks/Hackers Buenos Aires http://meetupba.hackshackers.com At that time we had about 200 enrolled, there are currently about 540. We also called Human Rights associations and made a formal request for the hackathon in Tecnopolis, a vast exhibition organized by the national government dedicated to science in Argentina, which occurred place within the former Batallon 601, the base of military operations in the dictatorship government. The meeting was attended by about forty people including journalists, militant organizations, developers and designers. Other participants of hackathon were Junar makers of a platform for "streaming" data to organize the information automatically and export it to other websites. We received sponsorship from Mozilla Argentina and Tecn‚àö‚â•polis.
 
 During the hackathon
 We searched for isolated tasks, so that participants could move independently
@@ -645,51 +676,51 @@
 
 Developers:
 Try other ways to extract data
-‚óè names, addresses, dates
-‚óè Organizations (currently done with regexes + a Bayesian filter for names).
-‚óè misspelled names, etc.
-‚óè alias
-‚óè disambiguations
-‚óè different ways of referring to the same person
-‚óè "Jorge Julio Lopez"
-‚óè "Julio Lopez"
-‚óè "Lopez"
-‚óè Work on the API data mapa76 exposing
+‚Äö√≥√® names, addresses, dates
+‚Äö√≥√® Organizations (currently done with regexes + a Bayesian filter for names).
+‚Äö√≥√® misspelled names, etc.
+‚Äö√≥√® alias
+‚Äö√≥√® disambiguations
+‚Äö√≥√® different ways of referring to the same person
+‚Äö√≥√® "Jorge Julio Lopez"
+‚Äö√≥√® "Julio Lopez"
+‚Äö√≥√® "Lopez"
+‚Äö√≥√® Work on the API data mapa76 exposing
 
 Journalists:
 Find use cases:
-‚óè Who was who?
-‚óè Follow the story of a person. What happened?
-‚óè Compare two life stories
-‚óè Compare the story depending on version
-‚óè Combing documents to try to tell a story based on documents
-‚óè Incorporate other sources such as newspapers, databases, etc..
+‚Äö√≥√® Who was who?
+‚Äö√≥√® Follow the story of a person. What happened?
+‚Äö√≥√® Compare two life stories
+‚Äö√≥√® Compare the story depending on version
+‚Äö√≥√® Combing documents to try to tell a story based on documents
+‚Äö√≥√® Incorporate other sources such as newspapers, databases, etc..
 
 Identify key words:
-‚óè Kidnapping
-‚óè Transfer
-‚óè Survivor
-‚óè Captivity
-‚óè Identity Theft
+‚Äö√≥√® Kidnapping
+‚Äö√≥√® Transfer
+‚Äö√≥√® Survivor
+‚Äö√≥√® Captivity
+‚Äö√≥√® Identity Theft
 
 Sort documents and relationships between documents:
-‚óè Testimony
-‚óè Expertise
-‚óè Case
-‚óè Judgment
-‚óè Fundamentals
+‚Äö√≥√® Testimony
+‚Äö√≥√® Expertise
+‚Äö√≥√® Case
+‚Äö√≥√® Judgment
+‚Äö√≥√® Fundamentals
 
 Future
 Improve the charging interface
-‚óè Smarter, faster
-‚óè Make a prototype query interface
-‚óè timelines (visualizations)
+‚Äö√≥√® Smarter, faster
+‚Äö√≥√® Make a prototype query interface
+‚Äö√≥√® timelines (visualizations)
 - Per person
 - For detention center
 - Per organization
-‚óè Consultation
+‚Äö√≥√® Consultation
 - Who was with who, where, etc..
-‚óè Layers own info / private
+‚Äö√≥√® Layers own info / private
 Newly transcribed testimony
 
 Later hackathon problems
@@ -698,14 +729,14 @@
 
 What are we doing?
 
-‚Ä¢ Generate technical documentation of the prototype.
-‚Ä¢ Define the functional scope of version 1.0, modular development plan, quantify the cost and size the equipment.
-‚Ä¢ Develop a Project Plan for version 1.0 and do a benchmarking for development funds.
-‚Ä¢ To survey the existence of functional modules to integrate into the platform Mapa76. For example, visualization of relationships between entities (people) to managing versions of a work product of the consultation on the system, etc.
-‚Ä¢ Improve data loading interface to make it more efficient and faster in the searches.
-‚Ä¢ Polish the query interface to improve the timelines per person per centerdetention.
-‚Ä¢ Set up a database query to establish relationships between people. By example, who was with who, where the disappearance occurred, how was your hostage situation, when it happened, and so on.
-‚Ä¢ Generate data layers of information for public and private consultation, to allow
+‚Äö√Ñ¬¢ Generate technical documentation of the prototype.
+‚Äö√Ñ¬¢ Define the functional scope of version 1.0, modular development plan, quantify the cost and size the equipment.
+‚Äö√Ñ¬¢ Develop a Project Plan for version 1.0 and do a benchmarking for development funds.
+‚Äö√Ñ¬¢ To survey the existence of functional modules to integrate into the platform Mapa76. For example, visualization of relationships between entities (people) to managing versions of a work product of the consultation on the system, etc.
+‚Äö√Ñ¬¢ Improve data loading interface to make it more efficient and faster in the searches.
+‚Äö√Ñ¬¢ Polish the query interface to improve the timelines per person per centerdetention.
+‚Äö√Ñ¬¢ Set up a database query to establish relationships between people. By example, who was with who, where the disappearance occurred, how was your hostage situation, when it happened, and so on.
+‚Äö√Ñ¬¢ Generate data layers of information for public and private consultation, to allow
 store them "stories" at the user level, etc.
 
 Current Status
@@ -719,7 +750,7 @@
 
 Who we are
 Mapa76.info is an initiative of the Buenos Aires chapter of Hacks / Hackers, an area of
-meeting comprised of journalists, software programmers and designers who come together to help build the future of media. The organizers of Hacks / Hackers Buenos Aires is made up Mariano Blejman (P√°gina/12), Martin Sarsale (Sumavisos), Guillermo Movia (Mozilla Argentina), Cesar Miquel (EasyTech), Mariana Berruezo, Sorin Sergio and Ezequiel Clerici.
+meeting comprised of journalists, software programmers and designers who come together to help build the future of media. The organizers of Hacks / Hackers Buenos Aires is made up Mariano Blejman (P‚àö¬∞gina/12), Martin Sarsale (Sumavisos), Guillermo Movia (Mozilla Argentina), Cesar Miquel (EasyTech), Mariana Berruezo, Sorin Sergio and Ezequiel Clerici.
 
 
 == 3. Case studies ==
@@ -730,8 +761,8 @@
 
 More case studies
 
-http://www.guardian.co.uk/politics/2009/may/15/mps-expenses-heather-brooke-foi[MPs expenses scanda]l in the UK is an example of how a simple Freedom of Information (FOI) request can trigger a large scale investigation. An FOI request uncovered some interesting stories about how elected officials spend taxpayers' money.
-http://blogs.lanacion.com.ar/projects/data/subsidies-for-the-bus-transportation-system-datajournalism-project-in-argentina-la-nacion/[Subsidies for the Bus Transportation System]: Angelica Peralta Ramos , LA NACION (Argentina)
+MPs expenses scandal in the UK is an example of how a simple Freedom of Information (FOI) request can trigger a large scale investigation. An FOI request uncovered some interesting stories about how elected officials spend taxpayers' money.
+Subsidies for the Bus Transportation System: Angelica Peralta Ramos , LA NACION (Argentina)
 
 case study 1
 
@@ -739,17 +770,17 @@
 
 === Data Stories by Martin Rosenbaum (BBC) ===
 
-Data journalism can sometimes give the impression that it is mainly about presentation of data ‚Äì such as visualisations which quickly and powerfully convey an understanding of an aspect of the figures, or interactive searchable databases which allow individuals to look up say their own local street or hospital. All this can be very valuable, but like other forms of journalism, data journalism should also be about stories. So what are the kinds of stories you can find in data? Based on my experience at the BBC, I have drawn up a list or 'typology' of different kinds of data stories.
+Data journalism can sometimes give the impression that it is mainly about presentation of data ‚Äö√Ñ√¨ such as visualisations which quickly and powerfully convey an understanding of an aspect of the figures, or interactive searchable databases which allow individuals to look up say their own local street or hospital. All this can be very valuable, but like other forms of journalism, data journalism should also be about stories. So what are the kinds of stories you can find in data? Based on my experience at the BBC, I have drawn up a list or 'typology' of different kinds of data stories.
 
 I think it helps to bear this list below in mind, not only when you are analysing data, but also at the stage before that, when you are collecting it (whether looking for publicly available datasets or compiling freedom of information requests).
 
 *1. Measurement*
 
-The simplest story ‚Äì counting or totalling something.
+The simplest story ‚Äö√Ñ√¨ counting or totalling something.
 
-'Local councils across the country spent a total of ¬£x billion on paper clips last year'.
+'Local councils across the country spent a total of ¬¨¬£x billion on paper clips last year'.
 
-- but it's often difficult to know if that's a lot or a little. For that, you need context ‚Äì which can be
+- but it's often difficult to know if that's a lot or a little. For that, you need context ‚Äö√Ñ√¨ which can be
 provided by:
 
 *2. Proportion*
@@ -792,7 +823,7 @@
 
 *8. Association*
 
-'Councils run by politicians who have received donations from stationery companies spend more on paper clips, with spending increasing on average by ¬£100 for each pound donated'
+'Councils run by politicians who have received donations from stationery companies spend more on paper clips, with spending increasing on average by ¬¨¬£100 for each pound donated'
 
 (but, of course, always remember that correlation and causation are not the same thing).
 
@@ -810,17 +841,17 @@
 
 ////
 
-Investigative reporters at  gotten tips from sources that a large chain of hospitals in California might be systematically gaming the federal Medicare program that pays for the costs of medical treatments of Americans aged 65 or older. The particular scam that was alleged is called "upcoding", which means reporting patients having more complicated conditions ‚Äì worth higher reimbursement ‚Äì than actually existed. But a key source was a union that was fighting with the hospital chain's management, and the CaliforniaWatch team knew that independent verification was necessary for the story to have credibility.
+Investigative reporters at CaliforniaWatch had gotten tips from sources that a large chain of hospitals in California might be systematically gaming the federal Medicare program that pays for the costs of medical treatments of Americans aged 65 or older. The particular scam that was alleged is called "upcoding", which means reporting patients having more complicated conditions ‚Äö√Ñ√¨ worth higher reimbursement ‚Äö√Ñ√¨ than actually existed. But a key source was a union that was fighting with the hospital chain's management, and the CaliforniaWatch team knew that independent verification was necessary for the story to have credibility.
 
-Luckily, California's department of health has public http://www.oshpd.ca.gov/HID/Products/PatDischargeData/PublicDataSet/index.html[records] that give very detailed information about each case treated in all the state's hospitals. The 128 variables include up to 25 diagnosis codes from the "International Statistical Classification of Diseases and Related Health Problems" manual (commonly known as ICD-9) published by the World Health Organization. While patients aren't identified by name in the data, other variables tell the age of the patient, how the costs are paid and which hospital treated him or her. The reporters realized that with these records, they could see if the hospitals owned by the chain were reporting certain unusual conditions at significantly higher rates than were being seen at other hospitals.
+Luckily, California's department of health has public records that give very detailed information about each case treated in all the state's hospitals. The 128 variables include up to 25 diagnosis codes from the "International Statistical Classification of Diseases and Related Health Problems" manual (commonly known as ICD-9) published by the World Health Organization. While patients aren't identified by name in the data, other variables tell the age of the patient, how the costs are paid and which hospital treated him or her. The reporters realized that with these records, they could see if the hospitals owned by the chain were reporting certain unusual conditions at significantly higher rates than were being seen at other hospitals.
 
-The data sets were large ‚Äì nearly 4 million records per year, and the reporters wanted to study six years worth of records in order to see how patterns changed over time. They ordered the data from the state agency; it arrived on CD-ROMs that were easily copied into a desktop computer. The reporter doing the actual data analysis used a system called http://www.sas.com/[SAS] to work with the data. SAS is very powerful (allowing analysis of many millions of records) and is used by many government agencies, including the California health department, but it is expensive - the same kind of analysis could have been done using any of a variety of other database tools, such as Microsoft Access or the open-source http://www.mysql.com/[MySQL]#.
+The data sets were large ‚Äö√Ñ√¨ nearly 4 million records per year, and the reporters wanted to study six years worth of records in order to see how patterns changed over time. They ordered the data from the state agency; it arrived on CD-ROMs that were easily copied into a desktop computer. The reporter doing the actual data analysis used a system called SAS to work with the data. SAS is very powerful (allowing analysis of many millions of records) and is used by many government agencies, including the California health department, but it is expensive - the same kind of analysis could have been done using any of a variety of other database tools, such as Microsoft Access or the open-source MySQL#.
 
 With the data in hand and the programs written to study it, finding suspicious patterns was relatively simple. For example, one allegation was that the chain was reporting various degrees of malnutrition at much higher rates than were seen at other hospitals. Using SAS, the data analyst extracted frequency tables that showed the numbers of malnutrition cases being reported each year by each of California's more than 300 acute care hospitals. The raw frequency tables then were imported into Microsoft Excel for closer inspection of the patterns for each hospital; Excel's ability to sort, filter and calculate rates from the raw numbers made seeing the patterns easy.
 
-Particularly striking were reports of a condition called Kwashiorkor, a protein deficiency syndrome that almost exclusively is seen in starving infants in famine-afflicted developing countries. Yet the chain was reporting its hospitals were diagnosing Kwashiorkor among elderly Californians at rates as much as 70 times higher than the state average of all hospitals. http://californiawatch.org/health-and-welfare/hospital-chain-already-under-scrutiny-reports-high-malnutrition-rates-8786[Read the story].
+Particularly striking were reports of a condition called Kwashiorkor, a protein deficiency syndrome that almost exclusively is seen in starving infants in famine-afflicted developing countries. Yet the chain was reporting its hospitals were diagnosing Kwashiorkor among elderly Californians at rates as much as 70 times higher than the state average of all hospitals. Read the story.
 
-For other stories, the analysis used similar techniques to examine the reported rates of conditions like septicemia, encephalopathy, malignant hypertension and autonomic nerve disorder. Read the story. And another analysis looked at allegations that the chain was admitting from its emergency rooms into hospital care unusually high percentages of Medicare patients, whose source of payment for hospital care is more certain than is the case for many other emergency room patients. http://californiawatch.org/health-and-welfare/prime-healthcares-treatment-rare-ailments-stands-out-13021[Read the story].
+For other stories, the analysis used similar techniques to examine the reported rates of conditions like septicemia, encephalopathy, malignant hypertension and autonomic nerve disorder. Read the story. And another analysis looked at allegations that the chain was admitting from its emergency rooms into hospital care unusually high percentages of Medicare patients, whose source of payment for hospital care is more certain than is the case for many other emergency room patients. Read the story.
 
 To summarize, stories like these become possible when you use data to produce evidence to test independently allegations being made by sources who may have their own agendas. These stories also are a good example of the necessity for strong public records laws; the reason the government requires hospitals to report this data is so that these kinds of analyses can be done, whether by government, academics, investigators or even citizen journalists. The subject of these stories is important because it examines whether millions of dollars of public money is being spent properly.
 
@@ -838,9 +869,9 @@
 
 Our inquiry began with analyzing data we obtained from the UK regulator in charge of inspecting care homes. The information was public, but it required a lot of persistence to get the data in a form that was usable.
 
-The data included ratings (now defunct) on individual homes' performance and a breakdown of whether they were private, government-owned or non-profit. The Care Quality Commission (CQC), up to June 2010, rated care homes on quality ranging from a verdict of "zero stars - poor" to "three stars ‚Äì excellent".
+The data included ratings (now defunct) on individual homes' performance and a breakdown of whether they were private, government-owned or non-profit. The Care Quality Commission (CQC), up to June 2010, rated care homes on quality ranging from a verdict of "zero stars - poor" to "three stars ‚Äö√Ñ√¨ excellent".
 
-The first step required extensive data cleaning, as the data provided by the Care Quality Commission for example contained categorizations that were not uniform. This was primarily done using Excel. We also determined ‚Äì through desk and phone research ‚Äì whether particular homes were owned by private-equity groups. Before the financial crisis, the care home sector was a magnet for private equity and property investors, but several ‚Äì such as Southern Cross ‚Äì had begun to face serious financial difficulties. We wanted to establish what effect, if any, private equity ownership had on quality of care.
+The first step required extensive data cleaning, as the data provided by the Care Quality Commission for example contained categorizations that were not uniform. This was primarily done using Excel. We also determined ‚Äö√Ñ√¨ through desk and phone research ‚Äö√Ñ√¨ whether particular homes were owned by private-equity groups. Before the financial crisis, the care home sector was a magnet for private equity and property investors, but several ‚Äö√Ñ√¨ such as Southern Cross ‚Äö√Ñ√¨ had begun to face serious financial difficulties. We wanted to establish what effect, if any, private equity ownership had on quality of care.
 
 A relatively straight forward set of Excel calculations enabled us to establish that the non-profit and government-run homes on average performed significantly better than the private sector. Some private equity-owned care home groups performed well over average, and others well below average.
 
@@ -861,7 +892,7 @@
 
 ////
 
-In 2010, the Financial Times and the Bureau of Investigative Journalism (BIJ) joined forces to investigate European Structural Funds. The intention was to review who the beneficiaries of European Structural Funds are and check whether the money was put to good use. At ‚Ç¨347bn over seven years Structural Funds is the second largest subsidy programme in the EU. The programme has existed for decades, but apart from broad, generalised overviews, there was little transparency about who the beneficiaries are. As part of a rule change in the current funding round, authorities are obliged to make public a list of beneficiaries, including project description and amount of EU and national funding received.
+In 2010, the Financial Times and the Bureau of Investigative Journalism (BIJ) joined forces to investigate European Structural Funds. The intention was to review who the beneficiaries of European Structural Funds are and check whether the money was put to good use. At ‚Äö√á¬®347bn over seven years Structural Funds is the second largest subsidy programme in the EU. The programme has existed for decades, but apart from broad, generalised overviews, there was little transparency about who the beneficiaries are. As part of a rule change in the current funding round, authorities are obliged to make public a list of beneficiaries, including project description and amount of EU and national funding received.
 
 The project was done with up to 12 journalists and one coder and took nine months. Data gathering alone took many months. The project resulted in five days of coverage in the Financial Times and the BIJ, a BBC radio documentary, and several TV documentaries.
 
@@ -871,7 +902,7 @@
 
 *1. Identify who keeps the data and how it is kept*
 
-The EU Commission's Directorate General for the Regions have a http://ec.europa.eu/regional_policy/index_en.cfm[portal] to the websites of regional authorities that publish the data. We believed that the EU commission would have an overarching database of project data that we could either access directly, or which we could obtain through a Freedom of Information request. No such database exists to the level of detail we required. We quickly realised that many of the links the Commission provided were faulty and that most of the authorities published the data in PDF format, rather than analysis-friendly formats such as CSV or XML.
+The EU Commission's Directorate General for the Regions have a portal to the websites of regional authorities that publish the data. We believed that the EU commission would have an overarching database of project data that we could either access directly, or which we could obtain through a Freedom of Information request. No such database exists to the level of detail we required. We quickly realised that many of the links the Commission provided were faulty and that most of the authorities published the data in PDF format, rather than analysis-friendly formats such as CSV or XML.
 
 A team of up to 12 people worked on identifying the latest data and collating the links into one large spreadsheet we used for collaboration. Since the data fields were not uniform (for example headers were in different languages, some data sets used different currencies, some included breakdowns of EU and National Funding) we needed to be as precise as possible in translating and describing the data fields available in each data set.
 
@@ -903,8 +934,8 @@
 
 Read the story:
 
-http://www.ft.com/intl/eu-funds[Financial times coverage]
-http://www.thebureauinvestigates.com/category/projects/europes-hidden-billions/[The Bureau of Investigative Journalism Coverage]
+Financial times coverage
+The Bureau of Investigative Journalism Coverage
 
 === The tell-all telephone by Sascha Venohr (Zeit Online) ===
 
@@ -916,20 +947,20 @@
 
 Most people's understanding of what can actually be done with the data provided by our mobile phones is theoretical; there were few real-world examples. That is why Malte Spitz from the German Green party decided to publish his own data. To access the information, he had to file a suit against telecommunications giant Deutsche Telekom. The data is the basis for ZEIT ONLINE's accompanying interactive map, were contained in a massive Excel document. Each of the 35,831 rows of the spreadsheet represent an instance when Spitz's mobile phone transferred information over a half-year period.
 
-Seen individually, the pieces of data are mostly harmless. But taken together, they provide what investigators call a profile ‚Äì a clear picture of a person's habits and preferences, and indeed, of his or her life. This profile reveals when Spitz walked down the street, when he took a train, when he was in an plane. It shows that he mainly works in Berlin an which cities he visited. It shows when he was awake and when he slept.
+Seen individually, the pieces of data are mostly harmless. But taken together, they provide what investigators call a profile ‚Äö√Ñ√¨ a clear picture of a person's habits and preferences, and indeed, of his or her life. This profile reveals when Spitz walked down the street, when he took a train, when he was in an plane. It shows that he mainly works in Berlin an which cities he visited. It shows when he was awake and when he slept.
 
 To illustrate just how much detail from someone's life can be mined from this stored data, ZEIT ONLINE has "augmented" Spitz's information with records that anyone can access: the politician's tweets and blog entries were added to the information on his movements. It is the kind of process that any good investigator would likely use to profile a person under observation. ZEIT ONLINE decided to keep one part of Spitz's data record private, namely, whom he called and who called him. That kind of information would not only infringe on the privacy of many other people in his life, it would also, even if the numbers were encrypted, reveal much too much about Spitz (but government agents in the real world would have access to this information).
 
-We were very happy to work with Lorenz Matzat and Michael Kreil from Open Data City to find a solution how to understand and extract the geolocation from the dataset. Every connection of Spitz' mobile phone has to be triangulated to the positions of the antenna pole. Every pole has three antennas, each covering 120¬∞. The two programmers found out, that the saved position indicated the direction from the pole Spitz' mobile phone was connecting.
+We were very happy to work with Lorenz Matzat and Michael Kreil from Open Data City to find a solution how to understand and extract the geolocation from the dataset. Every connection of Spitz' mobile phone has to be triangulated to the positions of the antenna pole. Every pole has three antennas, each covering 120¬¨‚àû. The two programmers found out, that the saved position indicated the direction from the pole Spitz' mobile phone was connecting.
 
-Matching this with the positions of the poles-map of the http://emf2.bundesnetzagentur.de/karte.html[state-controlled agency] gave us the possibility to get his position for each of the 260,640 minutes during the 181 days and put it via API on a Google Map. Together with the in-house graphics and design team we created a great interface to navigate: By pushing the play button, you will set off on a trip through Malte Spitz's life.
+Matching this with the positions of the poles-map of the state-controlled agency gave us the possibility to get his position for each of the 260,640 minutes during the 181 days and put it via API on a Google Map. Together with the in-house graphics and design team we created a great interface to navigate: By pushing the play button, you will set off on a trip through Malte Spitz's life.
 
 After a very successful launch of the Project in Germany, we recognized a great traffic from outside Germany and decided to translate the app in an English version. After earning the German Grimme Online Award, the project was honoured with an ONA award in September 2011, the first time for a German news website.
 
-https://docs.google.com/a/intern.ejc.net/spreadsheet/ccc?authkey=COCjw-kG&key=0An0YnoiCbFHGdGp3WnJkbE4xWTdDTVV0ZDlQeWZmSXc&hl=en_GB&authkey=COCjw-kG#gid=0[See the data]
-http://www.zeit.de/datenschutz/malte-spitz-data-retention[Read the story]
+See the data
+Read the story
 
-=== Citizen data reporters by Amanda Rossi (http://amigosdejanuaria.wordpress.com/[Friends of Janu√°ria]) ===
+=== Citizen data reporters by Amanda Rossi (Friends of Janu‚àö¬∞ria) ===
 
 ////
 
@@ -937,33 +968,33 @@
 
 ////
 
-Coordinator of the Friends of Janu√°ria citizen media project, Brasil
+Coordinator of the Friends of Janu‚àö¬∞ria citizen media project, Brasil
 
 Large newsrooms are not the only ones that can work on data-powered stories. Even those that may be considered as citizen reporters have the opportunity to use data in their stories. The same skills that are useful for data journalists can also help ordinary citizens access data about their local reality, and turn them into stories.
 
-This was the primary assumption that led to the citizen media outreach project Friends of Janu√°ria, which began in September of 2011. The project received a grant from http://rising.globalvoicesonline.org/[Rising Voices], the outreach arm of http://globalvoicesonline.org/[Global Voices Online], and received additional support from the organization Article 19. Between September and October 2011, a group of young residents of a small town in Brazil were trained in basic journalism techniques and budget monitoring. They also learned how to make Freedom of Information requests and access publicly available information from official databases on the Internet.
+This was the primary assumption that led to the citizen media outreach project Friends of Janu‚àö¬∞ria, which began in September of 2011. The project received a grant from Rising Voices, the outreach arm of Global Voices Online, and received additional support from the organization Article 19. Between September and October 2011, a group of young residents of a small town in Brazil were trained in basic journalism techniques and budget monitoring. They also learned how to make Freedom of Information requests and access publicly available information from official databases on the Internet.
 
-The pilot project took place in Janu√°ria, a small town of approximately 65,000 residents located in north of the state of Minas Gerais, which is one of the poorest regions of Brazil. The town is also renowned for the failure of its local politicians. In just six years (2004-2010), Janu√°ria had seven different mayors. Almost all of them were removed from office due to wrongdoing in their public administrations, including charges of corruption.
+The pilot project took place in Janu‚àö¬∞ria, a small town of approximately 65,000 residents located in north of the state of Minas Gerais, which is one of the poorest regions of Brazil. The town is also renowned for the failure of its local politicians. In just six years (2004-2010), Janu‚àö¬∞ria had seven different mayors. Almost all of them were removed from office due to wrongdoing in their public administrations, including charges of corruption.
 
-Small towns like Janu√°ria often fail to attract attention from the Brazilian media, which tends to focus on larger cities and state capitals. However, there is an opportunity for residents of small towns to become a potential ally in the monitoring of the public administration because they know the daily challenges facing their local communities better than anyone. With the Internet as another important ally, residents can now better access information such as budget information and other data about their towns.
+Small towns like Janu‚àö¬∞ria often fail to attract attention from the Brazilian media, which tends to focus on larger cities and state capitals. However, there is an opportunity for residents of small towns to become a potential ally in the monitoring of the public administration because they know the daily challenges facing their local communities better than anyone. With the Internet as another important ally, residents can now better access information such as budget information and other data about their towns.
 
-After taking part in twelve workshops, some of the new citizen reporters from Janu√°ria began to demonstrate how this concept of accessing publicly available data in small towns can be put into practice. For example, Soraia Amorim, a 22 year-old citizen journalist, wrote a story about the number of doctors that are on the city payroll according to Federal Government data. However, she found that the official number did not match with the town's reality. To write this story, Soraia had access to health data about her town, which is available online at the http://tabnet.datasus.gov.br/tabdata/cadernos/cadernosmap.htm[website of the Sistema √önico de Sa√∫de (SUS - Unique Health System)], a federal program that provides free medical assistance to the Brazilian population. According to SUS data, Janu√°ria should have 71 doctors in various health specialities. See the table below:
+After taking part in twelve workshops, some of the new citizen reporters from Janu‚àö¬∞ria began to demonstrate how this concept of accessing publicly available data in small towns can be put into practice. For example, Soraia Amorim, a 22 year-old citizen journalist, wrote a story about the number of doctors that are on the city payroll according to Federal Government data. However, she found that the official number did not match with the town's reality. To write this story, Soraia had access to health data about her town, which is available online at the website of the Sistema ‚àö√∂nico de Sa‚àö‚à´de (SUS - Unique Health System), a federal program that provides free medical assistance to the Brazilian population. According to SUS data, Janu‚àö¬∞ria should have 71 doctors in various health specialities. See the table below:
 
-The number of doctors indicated by SUS data did not match what she knew about the local reality. Taking into account that the town's residents were always complaining about the lack of doctors and that even some patients had to travel to neighboring towns to see a doctor. Later, Soraia interviewed a woman that had recently been in a motorcycle accident and could not find medical assistance at Janu√°ria's hospital because no doctor was available. She also talked to the town's Health Secretary, who admitted that there were less doctors in town than the number published by SUS.
+The number of doctors indicated by SUS data did not match what she knew about the local reality. Taking into account that the town's residents were always complaining about the lack of doctors and that even some patients had to travel to neighboring towns to see a doctor. Later, Soraia interviewed a woman that had recently been in a motorcycle accident and could not find medical assistance at Janu‚àö¬∞ria's hospital because no doctor was available. She also talked to the town's Health Secretary, who admitted that there were less doctors in town than the number published by SUS.
 
 These initial findings raise many questions about reasons for this difference between the official information published online and the town's reality. One of them is that the federal data may be wrong, which would mean that there is an important lack of health information in Brazil. Another possibility may be that the town is incorrectly reporting the information to SUS. Both of these possibilities should lead to a deeper investigation to find the definitive answer. However, Soraia's story is an important part of this chain because it highlights an inconsistency and may also encourage others to look more closely about this issue. "Access to data is a tool to provide information so that citizens can do something and fight for their rights," says Soraia.
 
-This was an important first step, and only after a few short trainings, Soraia was better equipped to search for data, make a Freedom of Information request, and write a story. "I used to live in the countryside, and finished high school with a lot of difficulty. When people asked me what I wanted to do with my life, I always told them that I wanted to be a journalist. But I imagined that it was almost impossible due to the world I lived in." After taking part in the Friends of Janu√°ria training. Soraia believes that access to information and data is an important tool to change the reality of her town. "I feel capable of changing my town, my country, the world. And I will pursue the access to information in my daily life," adds Soraia. See below for an excerpt from her story:
+This was an important first step, and only after a few short trainings, Soraia was better equipped to search for data, make a Freedom of Information request, and write a story. "I used to live in the countryside, and finished high school with a lot of difficulty. When people asked me what I wanted to do with my life, I always told them that I wanted to be a journalist. But I imagined that it was almost impossible due to the world I lived in." After taking part in the Friends of Janu‚àö¬∞ria training. Soraia believes that access to information and data is an important tool to change the reality of her town. "I feel capable of changing my town, my country, the world. And I will pursue the access to information in my daily life," adds Soraia. See below for an excerpt from her story:
 
-"According to the Health Handbook of SUS, Janu√°ria has approximately one doctor per one thousand residents (71 doctors). (...) Despite this number, many people are not assisted. That is what happened with Geiciane (who had a motorcycle accident and could not be assisted at the town's hospital). (...) The town's Health Secretary, Andr√© Rocha, does not confirm the amount of doctors mentioned by SUS".
+"According to the Health Handbook of SUS, Janu‚àö¬∞ria has approximately one doctor per one thousand residents (71 doctors). (...) Despite this number, many people are not assisted. That is what happened with Geiciane (who had a motorcycle accident and could not be assisted at the town's hospital). (...) The town's Health Secretary, André Rocha, does not confirm the amount of doctors mentioned by SUS".
 
-Another citizen journalist from the project is Alysson Monti√©riton, 20 years-old, who also used data for his final article. It was during the project's first class, when the citizen reporters walked around the city to look for subjects that could become stories, that Alysson decided to write about a broken traffic light located in a very important intersection, which had remained broken since the beginning of the year. After learning how to look for data on the Internet, Alysson searched for the number of vehicles that exists in town and the amount of taxes paid by those who own vehicles. See below an extract of his report:
+Another citizen journalist from the project is Alysson Montiériton, 20 years-old, who also used data for his final article. It was during the project's first class, when the citizen reporters walked around the city to look for subjects that could become stories, that Alysson decided to write about a broken traffic light located in a very important intersection, which had remained broken since the beginning of the year. After learning how to look for data on the Internet, Alysson searched for the number of vehicles that exists in town and the amount of taxes paid by those who own vehicles. See below an extract of his report:
 
-"The situation in Janu√°ria gets worse because of the high number of vehicles in town. According to IBGE (the most important statistics research institute in Brazil), Janu√°ria had 13,771 vehicles (among which 7,979 were motorcycles) in 2010. (...) The town's residents believe that the delay in fixing the traffic light is not a result of lack of resources. According to the Treasury Secretary of Minas Gerais state, the town received 470 thousand reais in vehicle taxes in 2010".
+"The situation in Janu‚àö¬∞ria gets worse because of the high number of vehicles in town. According to IBGE (the most important statistics research institute in Brazil), Janu‚àö¬∞ria had 13,771 vehicles (among which 7,979 were motorcycles) in 2010. (...) The town's residents believe that the delay in fixing the traffic light is not a result of lack of resources. According to the Treasury Secretary of Minas Gerais state, the town received 470 thousand reais in vehicle taxes in 2010".
 
-By having access to data, Alysson was able to show that Janu√°ria has many vehicles (almost one for every five residents) and that a broken traffic light could put a lot of people in danger. Besides, he was able to tell his audience the amount of funds received by the town from taxes paid by vehicle owners and, based on that, to question whether this money would not be enough to repair the traffic light to provide safe conditions to drivers and pedestrians. See the graph below:
+By having access to data, Alysson was able to show that Janu‚àö¬∞ria has many vehicles (almost one for every five residents) and that a broken traffic light could put a lot of people in danger. Besides, he was able to tell his audience the amount of funds received by the town from taxes paid by vehicle owners and, based on that, to question whether this money would not be enough to repair the traffic light to provide safe conditions to drivers and pedestrians. See the graph below:
 
-"At the http://www.ibge.gov.br/home/[IBGE site] , I clicked on "Cities", looked for Janu√°ria, and saw all the information that is available about the town. Then, I selected the data on the number of vehicles that exists in Janu√°ria. Besides, I looked for the amount of money that Janu√°ria receives from IPVA (vehicle tax). The town receives a good amount of funds and should provide a better maintenance for equipment, like traffic lights and so many others public equipment that citizens demand on a daily basis", explains Alysson.
+"At the IBGE site , I clicked on "Cities", looked for Janu‚àö¬∞ria, and saw all the information that is available about the town. Then, I selected the data on the number of vehicles that exists in Janu‚àö¬∞ria. Besides, I looked for the amount of money that Janu‚àö¬∞ria receives from IPVA (vehicle tax). The town receives a good amount of funds and should provide a better maintenance for equipment, like traffic lights and so many others public equipment that citizens demand on a daily basis", explains Alysson.
 
 Although these two reports, written by Soraia and Alysson, are very simple, they show that data can be used by citizen reporters. You don't need to be in a large newsroom, with the need for specialists, to use data in your reports. After twelve workshops, Soraia and Alysson, with no journalism background, were able to work on data powered stories and write interesting pieces about their local reality. In addition, their articles show that data itself can be useful even on a small scale. In other words, that there is also valuable information in small datasets and tables - not only in huge spreadsheets.
 
@@ -977,11 +1008,11 @@
 
 ////
 
-In January 2010 the BBC obtained data about the MOT pass and fail rates for different makes and models of cars. This is the test which assesses whether a car is safe and roadworthy ‚Äì any car over three years old has to have an MOT test annually.
+In January 2010 the BBC obtained data about the MOT pass and fail rates for different makes and models of cars. This is the test which assesses whether a car is safe and roadworthy ‚Äö√Ñ√¨ any car over three years old has to have an MOT test annually.
 
 We obtained the data under freedom of information following an 18-month battle with VOSA, the Department for Transport agency which oversees the MOT system. VOSA turned down our FOI request for these figures on the grounds that it would breach commercial confidentiality. It argued that it could be 'commercially damaging' to vehicle manufacturers with high failure rates. However, we then appealed to the Information Commissioner, who ruled that disclosure of the information would be in the public interest. VOSA then released the data, 18 months after we asked for it.
 
-We analysed the figures, focusing on the most popular models and comparing cars of the same age. This showed wide discrepancies. For example, among three year old cars, 28% of Renault M√©ganes failed their MOT in contrast to only 11% of Toyota Corollas. The figures were reported on television, radio and online.
+We analysed the figures, focusing on the most popular models and comparing cars of the same age. This showed wide discrepancies. For example, among three year old cars, 28% of Renault Méganes failed their MOT in contrast to only 11% of Toyota Corollas. The figures were reported on television, radio and online.
 
 The data was given to us in the form of a 1,200 page PDF document, which we then had to convert into a spreadsheet to do the analysis. As well as reporting our conclusions, we published this Excel spreadsheet (with over 14,000 lines of data) on the BBC News website along with our story. This gave everyone else access to the data in a usable form.
 
@@ -997,7 +1028,7 @@
 
 4. It's part of incorporating accountability and transparency into the journalistic process. Others can understand your methods and check your working if they want to.
 
-=== Finnish Parliamentary elections and campaign funding by Esa M√§kinen (Helsingin Sanomat) ===
+=== Finnish Parliamentary elections and campaign funding by Esa M‚àö¬ßkinen (Helsingin Sanomat) ===
 
 ////
 
@@ -1019,13 +1050,13 @@
 
 The National Audit Office of Finland is the authority that keeps records of campaign funding. That was the easy part. Chief information Officer, Jaakko Hamunen, built a website that provides real time access to their campaign funding database. The Audit Office made this in just two months after our request.
 
-http://www.vaalirahoitus.fi/[Vaalirahoitus.fi] site will provide the press and public information on campaign funding on every elections from now on.
+Vaalirahoitus.fi site will provide the press and public information on campaign funding on every elections from now on.
 
 Second step was to get ideas: what should we do with the data?
 
-The participants of HS Open 2 came up with twenty different prototypes about what to do with the data. You can find all the prototypes http://blogit.hs.fi/hsnext/hs-open-2-tuotti-parikymmenta-prototyyppia[here] (text in Finnish).
+The participants of HS Open 2 came up with twenty different prototypes about what to do with the data. You can find all the prototypes here (text in Finnish).
 
-Researcher of bioinformatics, Janne Peltola, noted that campaign funding data looked like gene data they research in terms of containing many interdependencies. Moreover, they have an open source tool to map out these interdependencies. It's called http://www.cytoscape.org/[Cytoscape]. So we ran the data through Cytoscape, and had a very interesting prototype.
+Researcher of bioinformatics, Janne Peltola, noted that campaign funding data looked like gene data they research in terms of containing many interdependencies. Moreover, they have an open source tool to map out these interdependencies. It's called Cytoscape. So we ran the data through Cytoscape, and had a very interesting prototype.
 
 Third step was to implement the idea on paper and on our site, HS.fi.
 
@@ -1035,7 +1066,7 @@
 
 When the data was cleaned and reformatted, we just ran it through Cytoscape. Then our graphics department made a page of it.
 
-Second part was to make a visualization for our web page. You can find the result http://www.vaaliraha.com/[here].
+Second part was to make a visualization for our web page. You can find the result here.
 
 The idea of this was not network analysis. We wanted to show people in easy format how much campaign funding there is and who gives it. The first view shows the distribution of funding between MPs. When you click on one MP, you get the breakdown on his or her funding. You can also vote on whether this particular donor is good or not. The visualization was made by Juha Rouvinen and Jukka Kokko, from ad agency Satumaa.
 
@@ -1043,7 +1074,7 @@
 
 Fourth step was to publish the data.
 
-Of course, the National Audit Office already publishes the data, so there was no need to republish. But, as we had a better data structure, we decided to publish it. We give out our data with http://creativecommons.org/choose/[Creative Commons licence]. And there have been several visualizations made by independent developers that have used our data subsequently. We have also published some of these.
+Of course, the National Audit Office already publishes the data, so there was no need to republish. But, as we had a better data structure, we decided to publish it. We give out our data with Creative Commons licence. And there have been several visualizations made by independent developers that have used our data subsequently. We have also published some of these.
 
 The tools we used for the project were: Excel and Google Refine for data cleaning and analysis. Cytoscape for network analysis. Illustrator and Flash for the visualizations. The Flash should have been HTML5, but we ran out of time.
 
@@ -1095,7 +1126,7 @@
 The application was generated during the 2011 Election Hackathon by Hacks/Hackers Buenos Aires the day before the election on October 23, 2011.  The hackathon was a day of work and programming with collaborations from 30 volunteer specialists. Electoral Hack was developed as an open platform for anyone interested in introducing improvements over time.  As technological tools we utilized developments that integrated Google Fusion Tables, maps, and vector graphics libraries, etc.
 
 
-We worked on the construction of polygons for displaying geographic mapping and electoral demographics. Combining polygons in GIS software and geometries from public tables in Google Fusion Tables we generated tables with keys corresponding to the electoral database of the Ministry of Interior—Indra and sociodemographic data from INDEC, creating from this data visualizations in Google Maps.
+We worked on the construction of polygons for displaying geographic mapping and electoral demographics. Combining polygons in GIS software and geometries from public tables in Google Fusion Tables we generated tables with keys corresponding to the electoral database of the Ministry of Interior‚ÄîIndra and sociodemographic data from INDEC, creating from this data visualizations in Google Maps.
 
 Using the GoogleMaps API we put several thematic maps online representing the spatial distribution of voting with different tones of color, where the gradation of intensity expressed different intervals of the percentage of votes for the various presidential tickets in different administrative departments and polling stations, with particular emphasis on major urban centers: the City of Buenos Aires, the 24 districts of Greater Buenos Aires, the City of Cordoba, and Rosario.
 
@@ -1105,7 +1136,7 @@
 
 Pros:
 
-* We set out to find data and articulate it and we were able to do that.  At hand we had the Unicef’s database of child sociodemographics, http://infoargentina.unicef.org.ar/, as well as the database of candidates created by the group yoquierosaber.org of Torcuato Di Tella University.  During the hackathon we gathered a large volume of additional data that we did not end up including.
+* We set out to find data and articulate it and we were able to do that.  At hand we had the Unicef's database of child sociodemographics, http://infoargentina.unicef.org.ar/, as well as the database of candidates created by the group yoquierosaber.org of Torcuato Di Tella University.  During the hackathon we gathered a large volume of additional data that we did not end up including.
 
 * It was clear that the journalistic and programming work was enriched by scholarship. Without the contribution of Andy Tow and Hilario Moreno Campos, the project would have been impossible to pull off.
 
@@ -1120,12 +1151,12 @@
 * For the same reason, all the collaborative work of 30 people ended up condensed into a single programmer when the data offered by the government began to appear, and we ran into some problems regarding the importation of date in real time that were solved within hours.
 
 Implications
-Electoral Hack’s platform had a big impact at the media, with television coverage, radio, graphics and online sites; its maps were used by several media platforms during the elections and in subsequent days. As the days went by, the maps and visualizations were updated, increasing traffic even more. On Election Day, the site created that very day received about 20 thousand unique visitors and its maps were reproduced by the newspaper Página/12 on its cover page for two consecutive days as well as in articles in La Nacion; some of its maps appeared in the print edition of the newspaper Clarín. It was the first time that an interactive display of real-time maps had been used in the history of Argentine journalism. In the central maps one could clearly see the overwhelming victory of Cristina Fernandez de Kirchner by 54 percent of the vote, broken up by color saturation. It also served to help understand very specific individual cases where local candidates swept the provincial votes.
+Electoral Hack's platform had a big impact at the media, with television coverage, radio, graphics and online sites; its maps were used by several media platforms during the elections and in subsequent days. As the days went by, the maps and visualizations were updated, increasing traffic even more. On Election Day, the site created that very day received about 20 thousand unique visitors and its maps were reproduced by the newspaper P√°gina/12 on its cover page for two consecutive days as well as in articles in La Nacion; some of its maps appeared in the print edition of the newspaper Clar√≠n. It was the first time that an interactive display of real-time maps had been used in the history of Argentine journalism. In the central maps one could clearly see the overwhelming victory of Cristina Fernandez de Kirchner by 54 percent of the vote, broken up by color saturation. It also served to help understand very specific individual cases where local candidates swept the provincial votes.
 
 What is Hacks/Hackers Buenos Aires?
-In April 2011, a local chapter of Hacks / Hackers opened in Buenos Aires, a meeting space comprising journalists, software developers, and IT professionals coming together to help build the future of media. The organizers of Hacks / Hackers Buenos Aires are Mariano Blejman (Página/12), Martin Sarsale (Sumavisos), Guillermo Movia (Mozilla Argentina), Cesar Miquel (EasyTech), Mariana Berruezo, Sorin Sergio Clerici, and Ezekiel. In 2011 there were four meetups, four hackathons, a conference, and a webinar. We currently have a base of 540 people, including journalists, programmers, designers, and entrepreneurs.
+In April 2011, a local chapter of Hacks / Hackers opened in Buenos Aires, a meeting space comprising journalists, software developers, and IT professionals coming together to help build the future of media. The organizers of Hacks / Hackers Buenos Aires are Mariano Blejman (P√°gina/12), Martin Sarsale (Sumavisos), Guillermo Movia (Mozilla Argentina), Cesar Miquel (EasyTech), Mariana Berruezo, Sorin Sergio Clerici, and Ezekiel. In 2011 there were four meetups, four hackathons, a conference, and a webinar. We currently have a base of 540 people, including journalists, programmers, designers, and entrepreneurs.
 
-For this project, the Buenos Aires Chapter of Hacks/Hackers joined with the blogger and political analyst Andy Tow Hilario and political scientist Moreno-Field – of the PR consulting firm Dicen – to develop  with journalists, social scientists, programmers and graphic designers an innovative information system. Those who worked on the  idea of Sergio Sorin’s included: Andy Tow - Andres Snitcofsky - Catalina Marino - Cesar Miquel - Damian Janowski – Ezequiel Clerici - Federico Ricciardi - Fernanda Roux - Florence Coelho - Guido Labonia - Guillermo Movia - Hilario Moreno Campos - Juan Pablo Renzi - Kevin Hanna - Lucas Aznar - Luis E. Guardiola - Mariana Berruezo - Mariano Mancuso - Martin Sarsale – Momi Peralta Ramos - Nicholas Cisco - Oscar Guindzberg - Sebastian Alvarez - Sebastian Melendez - Soledad Gherardi - Tania Wassaf - Valeria Bula and Mariano Blejman.
+For this project, the Buenos Aires Chapter of Hacks/Hackers joined with the blogger and political analyst Andy Tow Hilario and political scientist Moreno-Field ‚Äì of the PR consulting firm Dicen ‚Äì to develop  with journalists, social scientists, programmers and graphic designers an innovative information system. Those who worked on the  idea of Sergio Sorin's included: Andy Tow - Andres Snitcofsky - Catalina Marino - Cesar Miquel - Damian Janowski ‚Äì Ezequiel Clerici - Federico Ricciardi - Fernanda Roux - Florence Coelho - Guido Labonia - Guillermo Movia - Hilario Moreno Campos - Juan Pablo Renzi - Kevin Hanna - Lucas Aznar - Luis E. Guardiola - Mariana Berruezo - Mariano Mancuso - Martin Sarsale ‚Äì Momi Peralta Ramos - Nicholas Cisco - Oscar Guindzberg - Sebastian Alvarez - Sebastian Melendez - Soledad Gherardi - Tania Wassaf - Valeria Bula and Mariano Blejman.
 
 Twitter @ HacksHackersBA
 Mail ba@hackshackers.com
@@ -1143,27 +1174,27 @@
 
 ////
 
-‚óè   Overview: An overview of open data sources, what they contain, how to find them, how to search them, examples of open data being used by journalists
-‚óã   Is data copyrightable? "In the United States, data will be protected by copyright only if they express creativity. Some databases will satisfy this condition, such as a database containing poetry or a wiki containing prose. Many databases, however, contain factual information that may have taken a great deal of effort to gather, such as the results of a series of complicated and creative experiments." http://sciencecommons.org/old/databases/
-‚óã 	What is Open Data?
-                     ‚ñ†http://en.wikipedia.org/wiki/Open_data, http://opendefinition.org/
-                     ‚ñ†Data published using Creative Commons tools and licenses: http://wiki.creativecommons.org/Data
-                     ‚ñ†Other open licenses for data: http://opendefinition.org/licenses/
-                     ‚ñ†National and local governments have begun publishing data on portals like http://www.data.gov/ and http://data.cityofchicago.org/
-                     ‚ñ†Commercial re-use clauses
-‚óè   Authors: Jonathan Gray (Open Knowledge Foundation), Brian Boyer (Chicago Tribune), Jane Park (Creative Commons), John Keefe (WNYC), Chrys Wu (Hacks/Hackers),
-‚óè   Editor: Lucy Chambers, Friedrich Lindenberg
-‚óè 	Length: 1-3 pages (with links and examples)
+‚Äö√≥√®   Overview: An overview of open data sources, what they contain, how to find them, how to search them, examples of open data being used by journalists
+‚Äö√≥√£   Is data copyrightable? "In the United States, data will be protected by copyright only if they express creativity. Some databases will satisfy this condition, such as a database containing poetry or a wiki containing prose. Many databases, however, contain factual information that may have taken a great deal of effort to gather, such as the results of a series of complicated and creative experiments." http://sciencecommons.org/old/databases/
+‚Äö√≥√£ 	What is Open Data?
+                     ‚Äö√±‚Ä†http://en.wikipedia.org/wiki/Open_data, http://opendefinition.org/
+                     ‚Äö√±‚Ä†Data published using Creative Commons tools and licenses: http://wiki.creativecommons.org/Data
+                     ‚Äö√±‚Ä†Other open licenses for data: http://opendefinition.org/licenses/
+                     ‚Äö√±‚Ä†National and local governments have begun publishing data on portals like http://www.data.gov/ and http://data.cityofchicago.org/
+                     ‚Äö√±‚Ä†Commercial re-use clauses
+‚Äö√≥√®   Authors: Jonathan Gray (Open Knowledge Foundation), Brian Boyer (Chicago Tribune), Jane Park (Creative Commons), John Keefe (WNYC), Chrys Wu (Hacks/Hackers),
+‚Äö√≥√®   Editor: Lucy Chambers, Friedrich Lindenberg
+‚Äö√≥√® 	Length: 1-3 pages (with links and examples)
 
 Introduction
 
 by Lucy Chambers
 In this chapter, we aim to show you how to get your hands on the best data available to further your investigation. Sometimes you don't have to look far, the data may already be out there: it is a matter of knowing where to look. Other times, you may need to find the right people to ask. In particular, this chapter deals with:
-‚óè 	Tips and tricks for where to look for data: before launching into FOI requests or embarking down a technical route such as scraping.
-‚óè 	Search tips: How to make Google give you want you want, in the format you want it.
-‚óè   Communities for data: useful forums and mailing lists to ask experts directly
-‚óè 	Data houses: data catalogues, government portals, accessing research data and social data sites
-Finally, we'll have a quick look at the legal implications of re-using data from web databases ‚Äì while you may decide to break copyright to get your story out, it is still useful to know the boundaries in current law.
+‚Äö√≥√® 	Tips and tricks for where to look for data: before launching into FOI requests or embarking down a technical route such as scraping.
+‚Äö√≥√® 	Search tips: How to make Google give you want you want, in the format you want it.
+‚Äö√≥√®   Communities for data: useful forums and mailing lists to ask experts directly
+‚Äö√≥√® 	Data houses: data catalogues, government portals, accessing research data and social data sites
+Finally, we'll have a quick look at the legal implications of re-using data from web databases ‚Äö√Ñ√¨ while you may decide to break copyright to get your story out, it is still useful to know the boundaries in current law.
 
 A Journalist's Guide to Finding Data -- Open or Otherwise!
 
@@ -1172,10 +1203,10 @@
 
 **1. Google for 5 minutes.**
 
-Often enough, databases on the web are included in Google ‚Äì whether the publisher intended or not. When searching for data, make sure that you include both search terms relating to the content of the data you're trying to find as well as some information on the format or source that you would expect it to be in.
-‚óè   A handy feature of google is that it allows you to limit the file types of the returned results. For example, you can look only for spreadsheets (filetype:XLS filetype:CSV), geodata (filetype:shp), or database extracts (filetype:MDB, filetype:SQL, filetype:DB). If you're into that sort of thing, you can even look for PDFs (filetype:pdf).
-‚óè   Another option is searching by a part of a URL: (inurl:downloads filetype:xls) will try to find all Excel files that have "downloads" in their web address (if you find a single download, its often worth just checking what other results exist for the same folder on the web server). You can also limit your search to only those results on a single domain name: (site:agency.gov).
-‚óè   Another popular trick is not to search for content directly, but for places where bulk data may be available. For example, (site:agency.gov Directory Listing) may give you some listings generated by the web server with easy access to raw files, while (site:agency.gov Database Download) will look for intentionally created listings.
+Often enough, databases on the web are included in Google ‚Äö√Ñ√¨ whether the publisher intended or not. When searching for data, make sure that you include both search terms relating to the content of the data you're trying to find as well as some information on the format or source that you would expect it to be in.
+‚Äö√≥√®   A handy feature of google is that it allows you to limit the file types of the returned results. For example, you can look only for spreadsheets (filetype:XLS filetype:CSV), geodata (filetype:shp), or database extracts (filetype:MDB, filetype:SQL, filetype:DB). If you're into that sort of thing, you can even look for PDFs (filetype:pdf).
+‚Äö√≥√®   Another option is searching by a part of a URL: (inurl:downloads filetype:xls) will try to find all Excel files that have "downloads" in their web address (if you find a single download, its often worth just checking what other results exist for the same folder on the web server). You can also limit your search to only those results on a single domain name: (site:agency.gov).
+‚Äö√≥√®   Another popular trick is not to search for content directly, but for places where bulk data may be available. For example, (site:agency.gov Directory Listing) may give you some listings generated by the web server with easy access to raw files, while (site:agency.gov Database Download) will look for intentionally created listings.
           	
 **2. Ask an Expert.**
 
@@ -1183,22 +1214,22 @@
 
 **3. Ask a mailing list.**
 
-Mailing lists combine the wisdom of a whole community on a particular topic. For data journalists, http://www.ire.org/membership/subscribe/nicar-l.html/[NICAR-L] is an excellent starting point. This is a listserv of data-journalism geeks, working on all kinds of projects. Chances are that someone has done a story like yours, and would have an idea of where to start ‚Äî if not a link to the data itself.
+Mailing lists combine the wisdom of a whole community on a particular topic. For data journalists, NICAR-L is an excellent starting point. This is a listserv of data-journalism geeks, working on all kinds of projects. Chances are that someone has done a story like yours, and would have an idea of where to start ‚Äö√Ñ√Æ if not a link to the data itself.
 
 Other Mailing lists you could try:
-‚óè   http://project-wombat.org/[Project Wombat] - "Project Wombat is a discussion list for difficult reference questions". Ask them anything. They'll likely be able to find you an answer with references
-‚óè   Open Knowledge Foundation Lists: http://wiki.okfn.org/Mailing_Lists. In particular the http://lists.okfn.org/mailman/listinfo/data-driven-journalism[Data Driven Journalism List], which acts as a hub for many journalistic enquiries.
-‚óè   http://theinfo.org/[theInfo] is an older set of mailing lists that has a lot of knowledgeable experts subscribed.
+‚Äö√≥√®   Project Wombat - "Project Wombat is a discussion list for difficult reference questions". Ask them anything. They'll likely be able to find you an answer with references
+‚Äö√≥√®   Open Knowledge Foundation Lists: http://wiki.okfn.org/Mailing_Lists. In particular the Data Driven Journalism List, which acts as a hub for many journalistic enquiries.
+‚Äö√≥√®   theInfo is an older set of mailing lists that has a lot of knowledgeable experts subscribed.
 
 Topic Specific Lists:
-‚óè   Transparency: http://groups.google.com/group/sunlightlabs?pli=1[Sunlight Labs Mailing List] - The Sunlight Foundation focuses their activities into promoting and facilitating government transparency.
-‚óè   Mapping: http://www.nacis.org/index.cfm?x=1[North American Cartographic Information Society]
-‚óè   Mapping: Society of Cartographers http://soc.org.uk/cartosoc.htm[CARTO-SoC]
-‚óè   Mapping: MAPS-L: LISTSERV@LISTSERV.UGA.EDU - MAPS-L is an international discussion forum for anyone dealing with cartographic information, cartographers, remote sensors, geographers, and cartomaniacs of all types.
+‚Äö√≥√®   Transparency: Sunlight Labs Mailing List - The Sunlight Foundation focuses their activities into promoting and facilitating government transparency.
+‚Äö√≥√®   Mapping: North American Cartographic Information Society
+‚Äö√≥√®   Mapping: Society of Cartographers CARTO-SoC
+‚Äö√≥√®   Mapping: MAPS-L: LISTSERV@LISTSERV.UGA.EDU - MAPS-L is an international discussion forum for anyone dealing with cartographic information, cartographers, remote sensors, geographers, and cartomaniacs of all types.
           	
 **4. Use Forums.**
 
-Search for existing answers or ask a question at http://getthedata.org/[Get The Data] or on http://www.quora.com/[Quora]. GetTheData is Q&A site where you can ask your data related questions, including where to find data relating to a particular issue, how to query or retrieve a particular data source, what tools to use to explore a data set in a visual way, how to cleanse data or get it into a format you can work with.
+Search for existing answers or ask a question at Get The Data or on Quora. GetTheData is Q&A site where you can ask your data related questions, including where to find data relating to a particular issue, how to query or retrieve a particular data source, what tools to use to explore a data set in a visual way, how to cleanse data or get it into a format you can work with.
 
 **5. Join Hacks/Hackers**
 
@@ -1206,7 +1237,7 @@
 
 **6. Learn a bit about government IT.**
 
-Understanding the technical and administrative context in which governments maintain their information is often helpful when trying to access data. Whether it's CORDIS, COINS or THOMAS ‚Äì big-acronym databases often become most useful once you understand a bit about their intended purpose.
+Understanding the technical and administrative context in which governments maintain their information is often helpful when trying to access data. Whether it's CORDIS, COINS or THOMAS ‚Äö√Ñ√¨ big-acronym databases often become most useful once you understand a bit about their intended purpose.
 
 Find government org charts and look for departments/units with a cross-cutting function (e.g. reporting, IT services), then explore their web sites. A lot of data is kept in multiple departments and while for one, a particular database may be their crown jewels, another may give it to you freely.
 
@@ -1224,22 +1255,22 @@
 
 Over the last couple of years, a number of data portals have sprung up all over the web, that aim to help you get access to all kinds of information:
 
-‚óè 	Government Data Portals: the government's willingness to release a given dataset will vary from country to country. A growing number of states are providing data portals (inspired by data.gov and data.gov.uk) to promite the civic and commercial re-use of government information. An up-to-date, global index of such sites can be found at datacatalogs.org. Another handy site is the http://www.guardian.co.uk/world-government-data[Guardian World Government Data], a meta search engine that includes many international government data catalogues.
-‚óè 	http://thedatahub.org/[The DataHub] ‚Äì a community-driven resource that makes it easy to find, share and reuse open content and data, especially in ways that are machine automatable.
-‚óè   https://scraperwiki.com/[ScraperWiki] an online tool to make the process of extracting "useful bits of data easier so they can be reused in other apps, or rummaged through by journalists and researchers." Most of the scrapers and their databases are public and can be re-used.
-‚óè   http://data.worldbank.org/[World Bank] and http://data.un.org/[United Nations] data portals provide high-level indicators for all countries, often for many years in the past.
-‚óè 	A number of startups are emerging, that aim to build communities around data sharing and re-sale. This includes http://buzzdata.com/[Buzzdata] - a place to share and collaborate on private and public datasets ‚Äì and data shops such as http://www.infochimps.com/[Infochimps] and [DataMarket].
-‚óè   http://datamarket.com/[DataCouch] - A place to upload, refine, share & visualize your data.
-‚óè   An interesting Google subsidiary, http://www.freebase.com/[Freebase], provides "an entity graph of people, places and things, built by a community that loves open data."
+‚Äö√≥√® 	Government Data Portals: the government's willingness to release a given dataset will vary from country to country. A growing number of states are providing data portals (inspired by data.gov and data.gov.uk) to promite the civic and commercial re-use of government information. An up-to-date, global index of such sites can be found at datacatalogs.org. Another handy site is the Guardian World Government Data, a meta search engine that includes many international government data catalogues.
+‚Äö√≥√® 	The DataHub ‚Äö√Ñ√¨ a community-driven resource that makes it easy to find, share and reuse open content and data, especially in ways that are machine automatable.
+‚Äö√≥√®   ScraperWiki an online tool to make the process of extracting "useful bits of data easier so they can be reused in other apps, or rummaged through by journalists and researchers." Most of the scrapers and their databases are public and can be re-used.
+‚Äö√≥√®   World Bank and United Nations data portals provide high-level indicators for all countries, often for many years in the past.
+‚Äö√≥√® 	A number of startups are emerging, that aim to build communities around data sharing and re-sale. This includes Buzzdata - a place to share and collaborate on private and public datasets ‚Äö√Ñ√¨ and data shops such as Infochimps and DataMarket.
+‚Äö√≥√®   DataCouch - A place to upload, refine, share & visualize your data.
+‚Äö√≥√®   An interesting Google subsidiary, Freebase, provides "an entity graph of people, places and things, built by a community that loves open data."
 
 ### Research data ###
 
 by Jonathan Gray
-‚óè   http://scholar.google.co.uk/[Google Scholar]
-‚óè   http://www.mendeley.com/[Mendeley]
-‚óè   IBM Research - [Technical paper search]
-‚óè   http://www.jstor.org/[JSTOR] - "With more than a thousand academic journals and over 1 million images, letters, and other primary sources, JSTOR is one of the world's most trusted sources for academic content."
-‚óè   http://www.data-archive.ac.uk/find[UK Data Archive] - "The UK's largest collection of digital research data in the social sciences and humanities"
+‚Äö√≥√®   Google Scholar
+‚Äö√≥√®   Mendeley
+‚Äö√≥√®   IBM Research - Technical paper search
+‚Äö√≥√®   JSTOR - "With more than a thousand academic journals and over 1 million images, letters, and other primary sources, JSTOR is one of the world's most trusted sources for academic content."
+‚Äö√≥√®   UK Data Archive - "The UK's largest collection of digital research data in the social sciences and humanities"
 
 ### Reference data ###
 
@@ -1248,10 +1279,10 @@
 It's often helpful to pull in data from code sheets, such as lists of countries, states, organizations etc. This kind of data - which is used to augment another collection - is called reference data. Other examples of reference data include code sheets to decipher classifications and taxonomies, such as the EU's procurement vocabulary: on most portals, only short identifiers are provided, while the actual term descriptions are quite helpful.
 
 Some sources for reference data include:
-‚óè   http://www.geonames.org/[GeoNames] and http://open.mapquestapi.com/nominatim/[Nominatim] for geographic names and coordinates.
-‚óè   National statistics agencies
-‚óè   Web sites of standards bodies, such as the ISO (e.g. country codes) or the http://iatistandard.org/[IATI Standard] site.
-‚óè   International organisations such as the United Nations (e.g. classification of functions of government).
+‚Äö√≥√®   GeoNames and Nominatim for geographic names and coordinates.
+‚Äö√≥√®   National statistics agencies
+‚Äö√≥√®   Web sites of standards bodies, such as the ISO (e.g. country codes) or the IATI Standard site.
+‚Äö√≥√®   International organisations such as the United Nations (e.g. classification of functions of government).
 
 === Doing the legal stuff ===
 
@@ -1261,7 +1292,7 @@
 
 ////
 
-(Source: http://opendatahandbook.org/[The Open Data Manual], with input from Helen Darbishire, Access Info)
+(Source: The Open Data Manual, with input from Helen Darbishire, Access Info)
 
 Most of the new Open Data portals being set up by governments now make clear that the data that is released can be used free of charge, same goes for information obtained through Freedom of Information Requests. If you have scraped the data from a database such as a public body's website, then you may be particularly liable for limitations on reuse. Sometimes there will be intellectual property limitations, but normally the only requirement is that you cite the source of the information.
 
@@ -1273,7 +1304,7 @@
 
 To illustrate, consider the simple example of a database which lists the melting point of various substances. While the database as a whole might be protected by law so that one is not allow to access, reuse or redistribute it without permission this would never prevent you from stating the fact that substance Y melts at temperature Z.
  
-You can read more about the situation your jurisdiction in the http://opendefinition.org/guide/data/[Guide to Open Data Licensing].
+You can read more about the situation your jurisdiction in the Guide to Open Data Licensing.
 
 If you find you are having problems with your right to reuse information, then please let the campaign group Access Info Europe know (helpdesk@access-info.org). Access Info will help you with legal advice and will try to find lawyers in your country should that be necessary.
 Success? What now...? Share the data...
@@ -1283,7 +1314,7 @@
 
 When you do publish data, include an explicit IP statement, in particular an open license like the Creative Commons Zero or Attribution terms or the Open Database License (ODbL). If the data is government information not covered by copyright, publish it using Creative Commons' PD Mark dedication to make it clear that the data will be available in the public domain forever and for others to reuse!
 
-NOTE FOR JWYG: Much of the information in this chapter formerly related to submitting an FOI request, differences in legislation in different countries... It's interesting but not specific to data journalism. The overflow material is in this doc: https://docs.google.com/a/intern.ejc.net/document/d/1qwBjKHieAvttZulIG-aaQo0KRGF7so1-Vah3yIUHQAM/edit[FOI tipsheet] (also linked from overflow materials) Thought perhaps we could turn the other sections into an FOI tipsheet and publish it on DDJnet and link to it
+NOTE FOR JWYG: Much of the information in this chapter formerly related to submitting an FOI request, differences in legislation in different countries... It's interesting but not specific to data journalism. The overflow material is in this doc: FOI tipsheet (also linked from overflow materials) Thought perhaps we could turn the other sections into an FOI tipsheet and publish it on DDJnet and link to it
 
 === Asking for data ===
 
@@ -1307,7 +1338,7 @@
 
 
 
-For more detailed information on the process of submitting an FOI request, the difference in FOI legislation in different countries and appeal procedures see the https://docs.google.com/a/intern.ejc.net/document/d/1qwBjKHieAvttZulIG-aaQo0KRGF7so1-Vah3yIUHQAM/edit[FOI tipsheet].
+For more detailed information on the process of submitting an FOI request, the difference in FOI legislation in different countries and appeal procedures see the FOI tipsheet.
 Before FOI - Where to look
 
 Before you delve into making a FOI request, see if the data is already available - or has already been requested by others. See 2.1 'Where Does Data Live' for more information on where you can look online for the data.
@@ -1321,7 +1352,7 @@
 
 FOI requests - useful tips
 
-from the Legal http://www.legalleaks.info/[Leaks Toolkit] (Access Info Europe and n-ost)
+from the Legal Leaks Toolkit (Access Info Europe and n-ost)
 Tips by Martin Rosenbaum, BBC
 Fact boxes - Helen & Fabrizio
 Before you submit your request
@@ -1353,7 +1384,7 @@
 Tip: Especially important if you are planning to compare data from different public authorities. Is your request in any way ambiguous?
 
 For example, if you ask for figures for 'the past three years', some authorities will send you information for the past three calendar years and others for the past three financial years, which you won't be able to directly compare.
-Submit international requests: Increasingly requests can be submitted electronically, so it doesn't matter where you live. Alternatively, if you do not live in the country where you want to submit the request, you can sometimes send the request to the embassy and they should transfer it to the competent public body. You will need to check with the relevant embassy first if they are ready to do this ‚Äì sometimes the embassy staff will not have been trained in the right to information and if this seems to be the case, it's safer to submit the request directly to the relevant public body.
+Submit international requests: Increasingly requests can be submitted electronically, so it doesn't matter where you live. Alternatively, if you do not live in the country where you want to submit the request, you can sometimes send the request to the embassy and they should transfer it to the competent public body. You will need to check with the relevant embassy first if they are ready to do this ‚Äö√Ñ√¨ sometimes the embassy staff will not have been trained in the right to information and if this seems to be the case, it's safer to submit the request directly to the relevant public body.
 Use appropriate language: use language and etiquette appropriate to any other professional communication in your country.
 
 Tip: If you are planning to send the same request to many public authorities start by sending an initial draft of the request to a few authorities as a pilot exercise. This will show you whether you are using the right terminology to obtain the material you want and whether answering your questions is feasible, so that you can then revise the request if necessary before sending it to everyone.
@@ -1365,7 +1396,7 @@
 
 FACT BOX: Governments are not obliged to process data for you, but should give you all the data they have, and if it is data that they should have according to perform their legal competencies, they should certainly produce it for you.
 Keep a record! Make your request in writing and save a copy or a record of it so that in the future you are able to demonstrate that your request was sent, in case you need to make an appeal against failure to answer. This also gives you evidence of submitting the request if you are planning to do a story on it.
-Speed up answers by making it public that you submitted a request: If you write or broadcast a story that the request has been submitted, it can put pressure on the public institution to process and respond to the request. You can update the information as and when you get a response to the request ‚Äì or if the deadline passes and there is no response you can make this into a news story as well. Doing this has the additional benefit of educating members of the public about the right of access to information and how it works in practice.
+Speed up answers by making it public that you submitted a request: If you write or broadcast a story that the request has been submitted, it can put pressure on the public institution to process and respond to the request. You can update the information as and when you get a response to the request ‚Äö√Ñ√¨ or if the deadline passes and there is no response you can make this into a news story as well. Doing this has the additional benefit of educating members of the public about the right of access to information and how it works in practice.
 Involve your colleagues in using access to information: If your colleagues are sceptical about the value of access to information requests, one of the best ways to convince them is to write a story based on information you obtained using an access to information law. Mentioning in the final article or broadcast piece that you used the law is also recommended as a way of enforcing its value and raising public awareness of the right.
 Data Specific FOI requests
 
@@ -1375,21 +1406,21 @@
 The focus of many access to information advocates has turned towards persuading governments to make more information available in formats you can use and reuse.
 
 This reframing of the right to data seeks to make clear that:
-Detailed information should be available in a "disaggregated" or "granular" format ‚Äì this is sometimes also referred to as "raw data" before it has been "cooked" by public officials and statisticians.
+Detailed information should be available in a "disaggregated" or "granular" format ‚Äö√Ñ√¨ this is sometimes also referred to as "raw data" before it has been "cooked" by public officials and statisticians.
 Entire data sets or databases should be made available, free of charge and in an open source and machine readable format in order to permit re-use of the information.
 
 
 
 In the following sections you will find a brief definition of what access to information means globally and nationally.
 
-Read More: http://www.access-info.org/documents/Access_Docs/Advancing/Beyond_Access_7_January_2011_web.pdf[A recent report by the Open Knowledge Foundation and Access Info Europe] provides a thorough description of this evolving field.
+Read More: A recent report by the Open Knowledge Foundation and Access Info Europe provides a thorough description of this evolving field.
 Case Studies
 
 === Wobbing works. Use it! by Brigitte Alfter (Freelance Journalist) ===
 
-http://www.alfter.dk/[www.alfter.dk], journalist / co-founder of the http://www.wobbing.eu/[www.Wobbing.eu network], co-founder of the http://www.farmsubsidy.org/[www.Farmsubsidy.org] network
+www.alfter.dk, journalist / co-founder of the www.Wobbing.eu network, co-founder of the www.Farmsubsidy.org network
 
-Using freedom of information legislation ‚Äì or wobbing, as the slang goes ‚Äì is an excellent tool. But it requires method and often persistence. Three examples from Brigitte Alfter about the strength and challenges of Wobbing:
+Using freedom of information legislation ‚Äö√Ñ√¨ or wobbing, as the slang goes ‚Äö√Ñ√¨ is an excellent tool. But it requires method and often persistence. Three examples from Brigitte Alfter about the strength and challenges of Wobbing:
 
 
 Case Study 1: The Farmsubsidy project
@@ -1400,13 +1431,13 @@
 
 ////
 
-These years the EU pays almost ‚Ç¨ 60 billion to farmers and the farming industry. Per year. This has been going on since late 1950ies and the political narrative was that the subsidies help our poorest farmers. However a first FOI breakthrough in Denmark in 2004 indicated: The story was just a narrative. The small farmers were struggling as they so often complained about in private and in public, and in reality most of the money went to a few large land owners and to the agro industry. So obviously I wanted to know: Is there a pattern throughout the EU?
+These years the EU pays almost ‚Äö√á¬® 60 billion to farmers and the farming industry. Per year. This has been going on since late 1950ies and the political narrative was that the subsidies help our poorest farmers. However a first FOI breakthrough in Denmark in 2004 indicated: The story was just a narrative. The small farmers were struggling as they so often complained about in private and in public, and in reality most of the money went to a few large land owners and to the agro industry. So obviously I wanted to know: Is there a pattern throughout the EU?
 
 In the summer of 2004 I asked the European Commission for the data. Every year in February the Commission receives data from the member states. Data show who applied for EU funding, how much beneficiaries got, and whether they got it for farming their land, developing their region or for exporting milkpowder. At the time, the Commission received the figures on CD-roms with csv files. A lot of data, but in principle easy to work with. If you got them out, that is.
 
-In 2004 the Commission refused ‚Äì the key argument being, that the data were uploaded into a database and couldn't be retrieved without a lot of work. An argument, that the European Ombudsmand called "maladministration". You can find all documents in this case on http://www.wobbing.eu/[www.wobbing.eu] http://www.wobbing.eu/news/eu-watchdog-criticises-commission-and-comments-access-databases[here]. Back in 2004 we did not have the time to be legal foodies. We wanted the data.
+In 2004 the Commission refused ‚Äö√Ñ√¨ the key argument being, that the data were uploaded into a database and couldn't be retrieved without a lot of work. An argument, that the European Ombudsmand called "maladministration". You can find all documents in this case on www.wobbing.eu here. Back in 2004 we did not have the time to be legal foodies. We wanted the data.
 
-So we teamed up throughout Europe and went country by country to get the data. English, Swedish and Dutch colleagues got the data in 2005. Finland, Poland, Portugal, regions of Spain, Slovenia and other countries opened up in the too. Even in wob-difficult Germany I got a breakthrough and received some data in the province of North Rhine-Westfalia in 2007. I had to go to court to get the data ‚Äì but it then resulted in some nice articles in news magazine http://www.stern.de/wirtschaft/news/unternehmen/agrarsubventionen-volle-toepfe-fuer-die-grossen-601794.html[Stern and Stern online].
+So we teamed up throughout Europe and went country by country to get the data. English, Swedish and Dutch colleagues got the data in 2005. Finland, Poland, Portugal, regions of Spain, Slovenia and other countries opened up in the too. Even in wob-difficult Germany I got a breakthrough and received some data in the province of North Rhine-Westfalia in 2007. I had to go to court to get the data ‚Äö√Ñ√¨ but it then resulted in some nice articles in news magazine Stern and Stern online.
 
 Was it random, that Denmark and the UK were the first to open? Not necessarily. In a larger political picture the farm subsidies at the time had to be seen in the context of the WTO negotiations, where subsidies were under pressure. Denmark and the UK are among the more liberal countries in the EU, so there may well have been political winds blowing into the direction of transparency in those countries.
 
@@ -1416,7 +1447,7 @@
 
 Case Study 2: Side effects
 
-We are all guinea pigs when it comes to taking medicine. Drugs can have side-effects. We know, we consider it compared to the effect we wish for ‚Äì and we make a decision. Unfortunately often this decision is not an informed decision.
+We are all guinea pigs when it comes to taking medicine. Drugs can have side-effects. We know, we consider it compared to the effect we wish for ‚Äö√Ñ√¨ and we make a decision. Unfortunately often this decision is not an informed decision.
 
 When teenagers take a pill against pimples, they hope for a smooth skin and not for a bad mood. Yet exactly that happened with one drug, where the youngsters turned depressive and even suicidal. The danger of this particular side effect was not easily available - an obvious story for journalists.
 
@@ -1424,25 +1455,25 @@
 
 The initial breakthrough again came on national level in Denmark. During a cross-border research by a Danish-Dutch-Belgian team, also the Netherlands opened. Another example of wob-shopping: This time it helped to point out to the Dutch authorities, that the data were accessible in Denmark.
 
-But the story was true, in Europe there were suicidal young people and sadly also suicides in several countries. Journalists, university researchers, the family of a young victim were all pushing hard to get access to this information. The EU-ombudsman helped push the transparency at the European Medicines Agency - and it http://www.ombudsman.europa.eu/press/release.faces/en/5498/html.bookmark[looks, as if he succeeded]. So now the task is upon journalists to get out data and analyse the material thoroughly. Are we ‚Äì as one researcher put it ‚Äì all guinea pigs, or are the control mechanisms sound?
+But the story was true, in Europe there were suicidal young people and sadly also suicides in several countries. Journalists, university researchers, the family of a young victim were all pushing hard to get access to this information. The EU-ombudsman helped push the transparency at the European Medicines Agency - and it looks, as if he succeeded. So now the task is upon journalists to get out data and analyse the material thoroughly. Are we ‚Äö√Ñ√¨ as one researcher put it ‚Äö√Ñ√¨ all guinea pigs, or are the control mechanisms sound?
 
 Lessons learnt: Don't take no for an answer when it's about transparency, be persistent and follow a story over time. Things may well change and allow better reporting based upon better access at a later point.
 
 Case Study 3: Smuggling death
 
 
-Recent history can be utterly painful for entire populations, particularly after wars and in times of transition. So how can journalists obtain hard data to investigate, whether ‚Äì for example - last decades war profiteers are in power now? This was the task two Slovenian, a Croatian and a Bosnian journalist set out, the Slovene team being the driving force.
+Recent history can be utterly painful for entire populations, particularly after wars and in times of transition. So how can journalists obtain hard data to investigate, whether ‚Äö√Ñ√¨ for example - last decades war profiteers are in power now? This was the task two Slovenian, a Croatian and a Bosnian journalist set out, the Slovene team being the driving force.
 
 In their home country Slovenia parliamentary commissions had set out to look into the question of profiting from the Balkan wars, but never reached a conclusion. Yet there was a highly valuable trail of declassified documents and data. 6000 pages which the Slovene team obtained through a freedom of information request.
 
-In this case the data had to be extracted from the documents and sorted in databases ‚Äì for example transports had to be traced by vessel number in ports and license plates of trucks. Thanks to the data and in combination with further data, analysis and research, they were able to map numerous of the routes of the http://www.kaasogmulvad.dk/unv/kiev/Arms%20smuggling%20-%20TRILOGY%20In%20the%20Name%20of%20the%20State%20-%20Matej%20Surc,%20Blaz%20Zgaga%20-%20Slovenia.pdf[illegal weapon trade].
+In this case the data had to be extracted from the documents and sorted in databases ‚Äö√Ñ√¨ for example transports had to be traced by vessel number in ports and license plates of trucks. Thanks to the data and in combination with further data, analysis and research, they were able to map numerous of the routes of the illegal weapon trade.
 
-But the team succeeded and the results are http://www.journalismfund.eu/index.php?page=10&detail=154&be785f3421ff8f5ed50dfda00382b66049da3f53=a499c267af42d8392057f24e3fa5b9ca[unique] and have already brought the http://www.journalismfund.eu/index.php?page=9&detail=155[first award] to the team. But more importantly the story matters for the entire region and may well be picked up by journalists in other countries along the routes of the deadly material.
+But the team succeeded and the results are unique and have already brought the first award to the team. But more importantly the story matters for the entire region and may well be picked up by journalists in other countries along the routes of the deadly material.
 
 Lessons learnt: Get out good raw material even if you find it in unexpected places and combine with already accessible public data.
 
 Useful resources
-For further case studies and tools to facilitate making FOI requests, please see https://docs.google.com/a/intern.ejc.net/document/d/1HDcW0wFhmjwXFaIQ9dIOHzQm0ZkTONf89_Pi2Wbxt2M/edit[Further Resources]. 
+For further case studies and tools to facilitate making FOI requests, please see Further Resources. 
 
 === Getting data from the web by Friedrich Lindenberg (Open Knowledge Foundation) ===
 
@@ -1481,7 +1512,7 @@
 A lack of complete item listings and possibilities for wildcard search.
 Blocking of bulk access by the server administrators.
 
-Another set of limitations are legal barriers: some countries recognize database rights, which may limit your right to re-use information that has been published online. Sometimes, you can choose to ignore the license and do it anyway - depending on your jurisdiction, you may have special rights as a journalist. Politically, for Government data you'll be fine too. Commercial organizations ‚Äì and certain NGOs ‚Äì react with less tolerance and may try to claim that you're "sabotaging" their systems. Other information may infringe the privacy of individuals and thereby violate data privacy laws or professional ethics.
+Another set of limitations are legal barriers: some countries recognize database rights, which may limit your right to re-use information that has been published online. Sometimes, you can choose to ignore the license and do it anyway - depending on your jurisdiction, you may have special rights as a journalist. Politically, for Government data you'll be fine too. Commercial organizations ‚Äö√Ñ√¨ and certain NGOs ‚Äö√Ñ√¨ react with less tolerance and may try to claim that you're "sabotaging" their systems. Other information may infringe the privacy of individuals and thereby violate data privacy laws or professional ethics.
 
 Tools that help you scrape
 
@@ -1501,13 +1532,13 @@
 
 Any HTML page is structured as a hierarchy of boxes: a large box (or "tag") will contain many smaller ones - for example a table that has many smaller divisions: rows and cells. There are many types of tags that perform different functions - some produce boxes, others tables, images or links. Tags can also additional properties such as unique identifiers and belong to groups called 'classes', which makes it possible to target and capture individual elements within a document. Selecting the appropriate elements this way and extracting their content is the key to writing a scraper.
 Viewing the elements in a web page: everything can be broken up into boxes within boxes.
-To scrape web pages, you'll need to learn a bit about the different types of elements that can be in an HTML document - for example, the <table> element wraps a whole table, which has <tr> elements for its rows, which in turn contain <td> for each cell. The most common element type you will encounter is <div>, which can basically mean anything#. The easiest way to get a feel for these elements is by using the http://skypoetsworld.blogspot.com/2008/01/browser-debugging-tools.html[developer toolbar] in your browser: they will allow you to hover over any part of a web page and see what the underlying code is.
+To scrape web pages, you'll need to learn a bit about the different types of elements that can be in an HTML document - for example, the <table> element wraps a whole table, which has <tr> elements for its rows, which in turn contain <td> for each cell. The most common element type you will encounter is <div>, which can basically mean anything#. The easiest way to get a feel for these elements is by using the developer toolbar in your browser: they will allow you to hover over any part of a web page and see what the underlying code is.
 
 Tags work like book ends, marking the start and the end of a unit. For example <strong> signifies the start of a bold piece of text </strong> signifies the end of that section. Easy.
 
 An Example: Nuclear incidents
 
-http://www-news.iaea.org/EventList.aspx[NEWS] is the International Atomic Energy Agency's (IAEA) portal on world-wide radiation incidents and a strong contender for membership in the Weird Title Forum. The web page lists incidents in a simple, blog-like site that can be easily scraped. To start, create a new Python scraper on https://scraperwiki.com/[ScraperWiki] and you will be presented with a text area that is mostly empty, except for some scaffolding code. In another browser window, open the http://www-news.iaea.org/EventList.aspx[IAEA site] and open the developer toolbar in your browser. In the "Elements" view, try to find the HTML element for one of the news item titles.
+NEWS is the International Atomic Energy Agency's (IAEA) portal on world-wide radiation incidents and a strong contender for membership in the Weird Title Forum. The web page lists incidents in a simple, blog-like site that can be easily scraped. To start, create a new Python scraper on ScraperWiki and you will be presented with a text area that is mostly empty, except for some scaffolding code. In another browser window, open the IAEA site and open the developer toolbar in your browser. In the "Elements" view, try to find the HTML element for one of the news item titles.
 Your browsers developer toolbar helps you connect elements on the web page with the underlying HTML code.
 
 Investigating this page will reveal that the titles are <h4> elements within a <table>. Each event is a <tr> row, which also contains a description and a date. If we want to extract the titles of all events, we should find a way to select each row in the table sequentially, while fetching all the text within the title elements.
@@ -1561,11 +1592,8 @@
 
 ////
 
-### Crowdsourcing data ###
-
-2.3.2  Crowdsourcing data
-
-**1. definition of crowdsourcing data for journalism**
+This sub-chapter will show what is data crowdsourcing an dhow it can be used both as a collection tool and a helping hand to sort out existing datasets. We will be examining the examples of  two organisations, Buzz Data and the Guardian, and how they use data crowdsourcing in their work and make it easier for the audience and other journalists to get involved and have a go at it.
+definition of crowdsourcing data for journalism
 
 - Crowdsourcing is the act of sourcing tasks traditionally performed by specific individuals to a group of people or community (crowd) through an open call.
 
@@ -1573,18 +1601,17 @@
 
 It has been used by journalists to turn readers into contributors for a few years now, some more successfully than others.
 
-“When you have tones of files, statistics, reports to go through, like with the MPs expenses or the wikileaks cables, crowdsourcing is a really good way to get things done,” argues Simon Rogers, editor of the Guardian’s Data Blog in an interview conducted for this handbook.
+‚ÄúWhen you have tones of files, statistics, reports to go through, like with the MPs expenses or the wikileaks cables, crowdsourcing is a really good way to get things done,‚Äù argues Simon Rogers, editor of the Guardian's Data Blog in an interview conducted for this handbook.
 
-Data crowdsourcing can be helpful both for collecting data and sorting out big datasets you already have but that are too big for you to sort out alone. It’s also a very good way to get different perspectives on a subject you work on as the audience will often point out details that you didn’t notice on your own. 
-Although this trend to ask the audience to become contributors in the analysis of big data has been a real success in projects such as the MPs expenses in the UK or the Wikileaks cables worldwide, the actual “collection” of data via crowdsourcing stays a problem as journalists and editors still don’t know how to make sure the data people contribute is reliable.
-This sub-chapter will show you how data crowdsourcing can be used both as a collection tool and a helping hand to sort out existing datasets. We will be examining the example of  one media organisation, the Guardian, and how it implemented data crowdsourcing in their everyday work.
+Data crowdsourcing can be helpful both for collecting data and sorting out big datasets you already have but that are too big for you to sort out alone. It's also a very good way to get different perspectives on a subject you work on as the audience will often point out details that you didn't notice on your own. 
+Although this trend to ask the audience to become contributors in the analysis of big data has been a real success in projects such as the MPs expenses in the UK or the Wikileaks cables worldwide, the actual ‚Äúcollection‚Äù of data via crowdsourcing stays a problem as journalists and editors still don't know how to make sure the data people contribute is reliable.
 To crowdsource data, journalists can use surveys, polls, or comment fields. They can also ask their audience to contribute to a Google Doc or a spreadsheet. 
 
 Online resources like the Open Data Cook Book gives you help on how to collect data using Google forms.
 
-“Google forms (part of the Google Docs online office suite) allow you to collect and share data, the wesbite says.
+‚ÄúGoogle forms (part of the Google Docs online office suite) allow you to collect and share data, the wesbite says.
 
-“This recipe isn't about using an existing source of data, but instead allows you to create your own data. You might want to run a survey, or log events that occur. With Google forms you can easily share the data you collect as a spreadsheet.”
+‚ÄúThis recipe isn't about using an existing source of data, but instead allows you to create your own data. You might want to run a survey, or log events that occur. With Google forms you can easily share the data you collect as a spreadsheet.‚Äù
 
 Go to the Open Data cook book website to follow their tutorial.
 
@@ -1594,10 +1621,62 @@
 
 Video interview with Nick Edouard from Buzz Data: Data crowdsourcing meets social media http://vimeo.com/36859634 
 
-**2. How to collect data from content already published in social media**
+Nick: ‚ÄúI am the executive vice president of business development and marketing at Buzz Data. I got into data through Buzz Data CTO Pete Forde who I've known for a while and who I think is a visionary in this space. Pete introduced me to open data and data in general. I have worked with a lot of data in previous jobs but it was a privilege to come on board at Buzz Data. 
+
+Q: What's Buzz Data and how was it created?
+
+‚ÄúBuzz Data makes data sharing and collaboration on both private and public datasets very easy. It's important that we are not just about open data. We love open data, but we are really focused on how people interact with data of all type whether they are public or private. So what we've done is create essentially a platform that makes it very easy to add context, visualisations, articles, links around a dataset to create a story rather than just a dateset per say. An other major feature is the degree of user engagement that you can get. Not only have we incorporated some of the best features of social networks into Buzz Data, but at the same time, we've made it very easy for you to find collaborators to work with on a dataset. Whether as I said, it's in a public fashion or indeed privately, just between you and me for example.‚Äù
+
+Q: So do you consider yourself as the social medium of data?
+
+‚ÄúI guess there are a lot of ways in which Buzz Data can be described: it's a social network for data, it's a gate hump for data, etc. I think what we are doing is unique. I can't see anything in the market that is the same thing. We really think about what data needs to be to become meaningful, to become useful, to add insight. And that is really two things: the context and the engagement.‚Äù
+
+Q: How do you deal with truthfulness and trust on Buzz Data? How can people make sure the data they crowdsource is reliable?
+
+‚ÄúFrom a truthfulness prospective, obviously, we are looking to the community tu curate itself, I guess in that degree, our model is somewhat similar to Wikipedia: we are expecting people to engage, to point out errors and inacuracies in the datasets. I very much believe that we gonna find that communities of interest around topics are very engaged and as a result will self police.‚Äù
+
+Q: So you don't have a webmaster whose role is to verify the data that is on the site?
+
+‚ÄúWe gonna be doing that in the future, we gonna verify that the people that are publishing say who they are. At the moment we have The Economist Intelligence Unit, the Globe and Mail, a Canadian national newspaper, who are publishing data. We know who they are, but that is certainly something that we are working on and we will be able to verify who the data publisher is so that as a data user, you gonna have confidence in the veracity of the data. The other thing as well is that there's a virtual control on Buzz Data so if somebody post an original dataset, you can download their data, play around with it and if there's something you don't like or might not agree with some of the data points in it, you can push that back, upload that and point out innacuracies in the original datasets. I think this is a place for data to live, it is not overwritten it will very much evolve.‚Äù 
+
+Q: Are people able to share their activity on Buzz Data with other sociel networks like Twitter or Facebook?
+
+‚ÄúYes, without a doubt. We have already done the overall integration so at the moment you can see who is already on Buzz Data from existing from existing social networks (Linked'in, Twitter and Facebook). But we are working on it so you can see more easily your activity on Buzz Data through your other social networks. Hand in hand with that we are working on some features for data publishers so that they can widgetize a lot of the Buzz Data functionalities. They are going to be able to display what is happening on Buzz Data with their datasets within their own landing pages and normal websites, etc.‚Äù
+
+Q: How useful can Buzz Data be to data journalists?
+
+‚ÄúI think it can be enormously useful for data journalists. We have our own in-house data journalist Momoko Price who is our communication director. There is a number of ways [our site acn be useful to data journalists], 
+Buzz Data can be used privately to collaborate on datasets. Let's say a group of two or three investigative journalists could use Buzz Data to essentially work out the story to get it to the point where they are ready to publish. 
+Once you are ready to publish then obviously the story can go to print, you can link potentially to the underlining dataset it is based on, you can publish that on Buzz Data openly and then see what the community does to it. I think it's going to be really interesting to see how people take that story forward. We've already seen this first-hand on Buzz Data in a couple of occasions where the community has become engaged with a dataset, they've taken it in a different direction to the guy that originally written the story an published it and as a result there is a follow up story and not only that but the community is far more engaged with the story than it would have been otherwise.‚Äù
+
+
+Q: What do you think about data journalism in general and the way it is evolving today?
+
+‚ÄúI think it is massively important. I think it is very important for the future of open data and open data full stop actually. As someone described, data journalists are essentially data engineers. You guys are going to be taking data as a raw ingredient and turn it into something that's useful. And I think thats the oil in the machine essentialy. One thing that the open data mouvement need to address full stop is when data is published, something has to happen with it otherwise people will be less inclined to publish it. Great things do happen when data is shared and published so I think data journalists' job is gonna be key to that.‚Äù
+
+Q: The Open Data movement campaigns for more openess from governments and big organisations to publish more data online. How do you see this evolve in the future?
+
+‚ÄúI hope we'll stop talking about it as needing to evolve, I think it's gonna become part of the course sooner rather than later. I am really encouraged by the activity of some governments, the UK for example is very good in this regard. Is there any room to be better? Without a shutter of a doubt. I think part of that too is adding the context around the dataset. So thinking about how things become published, the more information you can wrap around it is obviously the better, the more useful it becomes. I don't think it's just about open data too. I think open data tends to be too much focused on kind of governments', etc. I think a lot of organisations, a lot of private companies are starting to realise the value in sharing data. Obvisouly there are types of data that will never be made public, I don't want my credit card information to ever be public, and at Buzz Data we fully understand that there is information that will always be confidential to companies. I think the open data movement will continue and I think thrive. I am excited about that but I think there's also gonna be more and more private organisations that will be looking in-house and thinking ‚Äòwhat should we be sharing with our consumers? And how do we benefit from that?‚Äù
+
+Q: So what's next for Buzz Data?
+
+‚Äú The way I see it is that Buzz Data is good and it's only gonna get better from hereon in. We have some very exciting things on the road map, we are working on things like smarter recommendation algorythms, and better around discoverabilitty, producing widgets for data publishers, how do you embed functionality on your website. 
+
+We are working on improving the collaboration side of it, it is far better that anything I can see out there at the moment but I think we can still make it better. A lot that I have been doing in the past couple of weeks is actually talking to epole that have been using the service, getting their feedback and then we'll build that in the product road map. So we are listening to the people who are using the service at the moment, we gonna make it better based on their feedback. It's already jolly good but I think we can make it better.‚Äù
+
+Q: Three golden rules to data?
+
+‚ÄúThree golden rules to data? 
+I think firstly data needs context. So if you are thinking about sharing or publishing data, think about what else you can provide like ‚Äòthis heading in this spreadsheet is actually composed of the following three or four factors'. Because that's gonna enable your user community, fondamentally people who want to play with your data to actually know where they should take it. You gonna be able to give them more of a steer. So context is important..
+Secondly is to think about engagement. How best to stimulate it within your community so rather than just publishing and like the Duke of Wellington ‚Äúbeing damned‚Äù, do not just sit back. Imagine stuff that's gonna happen, I think you do need to think ‚Äòwho do we need to tell that we've done this?' That's one marking that needs to be put in place and then stimulate that activity. 
+I guess the third would be ‚ÄòPublish! Publish! Publish!' The more the merrier, I think great things happen when data is shared. You just have to see the NASA dark matter competition last year, the Netflix recommendation algorythm, a contest from a while back‚Ä¶ It's not just advances in science, there are also great things commercially that happened and I hope Buzz Data is going to be a big part of those stories over the next couple of years. 
+
+Something great is going to happen on Buzz Data sooner rather than later and I am excited for that.‚Äù 
+How to collect data from content already published in social media 
 
 using Twitter hashtags (examples: emergency hashtags used in the event of an earthquake or huricane in the US)
 using Tools such as:
+
 People Browser
 Social mention (media monitoring tools)
 Disqus
@@ -1609,48 +1688,50 @@
 gather information from different platforms to get a common opinion
 cross check to make sure the information is reliable and consistent 
 
-**3. Data Crowdsourcing at the Guardian - Getting the readers involved**
+Data Crowdsourcing at the Guardian - Getting the readers involved
+
 
 While there is already a huge amount of data available online, some media organisations are going one step further by getting their readers involved in the process of collecting and analysing data. 
 
-“Crowdsourcing” has become a common practice in the world of data journalism and the Guardian is now considered as a reference in the field. 
+‚ÄúCrowdsourcing‚Äù has become a common practice in the world of data journalism and the Guardian is now considered as a reference in the field. 
 
-The Guardian’s Data Blog won the 2011 Newspaper Awards prize for Best use of New Media and the Guardian’s DataStore was honoured at the Knight Batten awards for innovation in journalism in 2011.
+The Guardian's Data Blog won the 2011 Newspaper Awards prize for Best use of New Media and the Guardian's DataStore was honoured at the Knight Batten awards for innovation in journalism in 2011.
 
-We went to the Guardian’s offices in London to talk to their data journalism team about data crowdsourcing and the different projects they have recently set up.
+We went to the Guardian's offices in London to talk to their data journalism team about data crowdsourcing and the different projects they have recently set up.
 
 Simon Rogers is the editor of the Data Blog. He told us how crowdsourcing can help when other ways of collecting and analysing data are not enough... 
 
 SIMON ROGERS, Editor of the Data Blog:
 
-“ I suppose the thing about crowdsourcing is that when you have tones of stuff to go through, like with the MPs expenses where there were 40,000 pages to go through, that’s impossible for one person to do. Also, when you have got all this stuff that is inaccessible or in a bad format, that’s really where crowdsourcing can help. 
+‚Äú I suppose the thing about crowdsourcing is that when you have tones of stuff to go through, like with the MPs expenses where there were 40,000 pages to go through, that's impossible for one person to do. Also, when you have got all this stuff that is inaccessible or in a bad format, that's really where crowdsourcing can help. 
 
-One thing the Guardian has got is lots of readers, lots of pairs of eyes, and if there is something interesting to do then it can really work. That’s what we did with the MPs expenses. We had 450,000 documents and very little time to do anything. So what better way than open up to readership? 
+One thing the Guardian has got is lots of readers, lots of pairs of eyes, and if there is something interesting to do then it can really work. That's what we did with the MPs expenses. We had 450,000 documents and very little time to do anything. So what better way than open up to readership? 
 
-But what we found with the MPs expenses is that what we generated was tip-offs, stories more than data. So although it was remarquably successful in terms of traffic, people really liked it, it wasn’t in terms of actual raw data. It was hard to know who we could trust.
+But what we found with the MPs expenses is that what we generated was tip-offs, stories more than data. So although it was remarquably successful in terms of traffic, people really liked it, it wasn't in terms of actual raw data. It was hard to know who we could trust.
 
-We are doing something at the moment with MixMag on drug use and that has been phenomenal as well, it looks like it is going to be bigger than the British crime survey in terms of how many people come back to it. It’s brilliant. 
+We are doing something at the moment with MixMag on drug use and that has been phenomenal as well, it looks like it is going to be bigger than the British crime survey in terms of how many people come back to it. It's brilliant. 
 
 I think what those things have in common is that they are things people care about so they are willing to spend the time. A lot of the crowdsource we have done mostly relies on the obsessives. So with the MPs expenses we had a massive amount of traffic at the beginning and it really died down. But what we still got are people that are obsessively going through every page looking for that story. One person has done 30,000 pages. They know a lot of stuff.
 
-So in terms of generating stories it worked really well and people really liked it, it made the Guardian ‘look good’, but I think in terms of generating raw data, not so much. 
+So in terms of generating stories it worked really well and people really liked it, it made the Guardian ‚Äòlook good', but I think in terms of generating raw data, not so much. 
 
 Then we did it with the Sarah Palin papers, that was again a good way of looking for stories, scouring the raw information for stories. 
 
-But it also seems to me that some of the (crowdsourcing projects) that we’ve done that worked really well have been more like ‘all fashioned’ surveys. When you are asking people about their experience, about their lives, about what they’ve done, they work very well because people aren’t as likely to make that up. They will say what they feel. When we asked people to kind of do our job for us, you have to find a framework for people to produce the data in a way you can trust them.”
+But it also seems to me that some of the [crowdsourcing projects] that we've done that worked really well have been more like ‚Äòall fashioned' surveys. When you are asking people about their experience, about their lives, about what they've done, they work very well because people aren't as likely to make that up. They will say what they feel. When we asked people to kind of do our job for us, you have to find a framework for people to produce the data in a way you can trust them.‚Äù
 
 Q: You were talking about reliability, how do you deal with that on a daily basis? How do you trust people to contribute? 
 
- “I think the approach that Old Weather have got, where they get ten people to do each one, is a really good test on that. It is an old fashioned computer science technique to get a warm up as a train starter. I think that’s a very good way to do it. 
+ ‚ÄúI think the approach that Old Weather have got, where they get ten people to do each one, is a really good test on that. It is an old fashioned computer science technique to get a warm up as a train starter. I think that's a very good way to do it. 
 
-With the MPs expenses, we tried to minimise the risk of MPs going online and editing their own records to make themselves look better. But you can’t permanently guard that site, you can only look out for certain urls or if it’s coming from the SW1 area of London. So that’s a bit trickier. That’s where I felt out of it because I felt like the data we were getting out was not reliable. Even though stories were great, it wasn’t producing raw numbers that we could confidently use.”
+With the MPs expenses, we tried to minimise the risk of MPs going online and editing their own records to make themselves look better. But you can't permanently guard that site, you can only look out for certain urls or if it's coming from the SW1 area of London. So that's a bit trickier. That's where I felt out of it because I felt like the data we were getting out was not reliable. Even though stories were great, it wasn't producing raw numbers that we could confidently use.‚Äù
 
 Q: Could you give a piece of advice to journalists who want to use crowdsourcing to collect data online?
 
-“I would say:
+‚ÄúI would say:
 making it something personal to people really helps,
 otherwise make it about what the people care about, or are gonna care about after, even when the news dies down, where they will still want to get involved.
-also, what is really worth it is when you make it more like a game. Second time around when we did the expenses story, it was much more like a game, with individual tasks for people to do. It really help to give people specific tasks and things to do. That made a big difference because I think if you just present people with the mountain of information to go through, it’s a hard work, that’s what we get paid for. So I think making it fun is really important.”
+also, what is really worth it is when you make it more like a game. Second time around when we did the expenses story, it was much more like a game, with individual tasks for people to do. It really help to give people specific tasks and things to do. That made a big difference because I think if you just present people with the mountain of information to go through, it's a hard work, that's what we get paid for. So I think making it fun is really important.‚Äù
+
 
 In October 2011 The Data Blog set up a crowdsourced map of the Occupy movement. 
 
@@ -1658,138 +1739,108 @@
 
 The result is a very straight forward map of the Occupy movement worldwide which is still being updated today.
 
-The Guardian’s data journalism team has done many of these projects in the past few years, each of them proved to be very successful. So we asked them for tips on how to use crowdsourcing in data journalism and we asked Data journalist James Ball to tell us about the Guardian’s most successful crowdsourcing projects…
+The Guardian's data journalism team has done many of these projects in the past few years, each of them proved to be very successful. So we asked them for tips on how to use crowdsourcing in data journalism and we asked Data journalist James Ball to tell us about the Guardian's most successful crowdsourcing projects‚Ä¶
 
 JAMES BALL, data journalist at the Guardian
 
-“I think the one that got the biggest response was something that we did on olympic ticketing. Thousands of people in the UK tried to get tickets for this year’s Olympics and there was a lot of fury that people hadn’t got them. People had ordered hundreds of pounds worth and been told they’ll get nothing. But no one really knew if it was just some people complaining quite loudly while actually most people were happy. 
+‚ÄúI think the one that got the biggest response was something that we did on olympic ticketing. Thousands of people in the UK tried to get tickets for this year's Olympics and there was a lot of fury that people hadn't got them. People had ordered hundreds of pounds worth and been told they'll get nothing. But no one really knew if it was just some people complaining quite loudly while actually most people were happy. 
 
-So we tried to work out a way to find out. We decided the best thing we could really do, in the lack of any good data, was to ask people. And we thought we’d have to treat it as a light thing because it wasn’t a balanced sample. 
+So we tried to work out a way to find out. We decided the best thing we could really do, in the lack of any good data, was to ask people. And we thought we'd have to treat it as a light thing because it wasn't a balanced sample. 
 
 We created a Google form and asked very specific questions. It was actually a long form, it asked how much in value people had ordered their tickets, how much their card had been debited for, which events they went for, this kind of thing. 
 
-We put it up as a small picture on the front of the site but it was shared around really rapidly. I think this is one of the key things, you can’t just think ‘what do I want to know’ for my story’, you have to think ‘what are people wanting to tell me right now’. And it’s only when you tap into what are people wanting to talk about that crowdsourcing is going to be successful. 
+We put it up as a small picture on the front of the site but it was shared around really rapidly. I think this is one of the key things, you can't just think ‚Äòwhat do I want to know' for my story', you have to think ‚Äòwhat are people wanting to tell me right now'. And it's only when you tap into what are people wanting to talk about that crowdsourcing is going to be successful. 
 
 But the volume of responses on this, which is one of the earliest times we have ever tried to do this approach, was huge. We had a thousand responses in less than an hour and seven thousands by the end of that day. 
 
 So obviously we took presenting the results a bit more seriously at this point, we had no idea how well it would do. So we put on some cavy hats you know, Guardian readers may be more wealthy than other people, also people who got less than they expected might be more willing to talk to us. 
 
-So we didn’t know how much value the results would have. So we did that and cut it down and we had a good seven thousand records to base it on and we found about half the people who’d asked for tickets had got nothing, how many people had ordered and got. We ran all of this stuff, and obviously because so many people had taken part the day before, there was a lot of interest in the results. 
+So we didn't know how much value the results would have. So we did that and cut it down and we had a good seven thousand records to base it on and we found about half the people who'd asked for tickets had got nothing, how many people had ordered and got. We ran all of this stuff, and obviously because so many people had taken part the day before, there was a lot of interest in the results. 
 
 A few weeks later, the official summary report came out, and our numbers were shockingly close, they were almost exactly spot on. I think partly through luck but also because we got just so many people.
 
-Generally though, I tend to find that crowdsourcing is more useful for the content around the data story or for getting people to follow one up. So if we publish a story based on data that we do internally and I do quite a lot of work on lobying, I publish the full register or the whole thing that I based it on because sometimes you will get someone who doesn’t like a particular MP or Lord who will say ‘Oh, that research doesn’t declare anything but I know that they work for here’. Now you love to get that as an email rather than on your open tools that you usually use but that’s fine. You know, it’s all about learning how to follow up. So while it is less frequent that it helps you compile data, it often lets you do more with the data than you could yourself. You can only know so many people.
+Generally though, I tend to find that crowdsourcing is more useful for the content around the data story or for getting people to follow one up. So if we publish a story based on data that we do internally and I do quite a lot of work on lobying, I publish the full register or the whole thing that I based it on because sometimes you will get someone who doesn't like a particular MP or Lord who will say ‚ÄòOh, that research doesn't declare anything but I know that they work for here'. Now you love to get that as an email rather than on your open tools that you usually use but that's fine. You know, it's all about learning how to follow up. So while it is less frequent that it helps you compile data, it often lets you do more with the data than you could yourself. You can only know so many people.
 
 Q: Can you talk me through the process of going through all the data you collected, you had about 7000 responses, how did you deal with this huge amount of data?
 
-“We’d preempted that we wanted to do analysis on it, which helped. If you start something in a comment thread, it is often too late to turn it into a usable way. So you have to set out at the start and think ‘what’s the best tool for what I want to know?’ Is it a comment thread, is it building an app, and if it is building an app, you have to think ‘Is this worth the wait? And is it worth the resource to do it?’ 
+‚ÄúWe'd preempted that we wanted to do analysis on it, which helped. If you start something in a comment thread, it is often too late to turn it into a usable way. So you have to set out at the start and think ‚Äòwhat's the best tool for what I want to know?' Is it a comment thread, is it building an app, and if it is building an app, you have to think ‚ÄòIs this worth the wait? And is it worth the resource to do it?' 
 
 In this case we thought of Google forms and if someone fills that out it turns into a row on a spreadsheet. So it meant that straight away, even if it was still updating, I could open the spreadsheet and see all of the results. 
 
 I could have tried to do the work in Google but I downloaded it into Microsoft Excel and then did things like sort it from low to high and found the people who decided to write in instead of putting digits on how much they spent and fixed all of those. I decided not to exclude as little as I could. So rather than taking only valid responses, I tried to fix other ones. People had used foreign currencies so I converted them to sterling, all of which was a bit painstaking. 
 
-But the whole analysis was done in a few hours, then I knocked out the obviously silly entries. A lot of people decided to fill it out pointing out they spent nothing on tickets, that’s a bit facetious but fine, I mean, that was less than a hundred out of seven thousands several hundreds. 
+But the whole analysis was done in a few hours, then I knocked out the obviously silly entries. A lot of people decided to fill it out pointing out they spent nothing on tickets, that's a bit facetious but fine, I mean, that was less than a hundred out of seven thousands several hundreds. 
 
-And then a few dozens who put obviously fake high amounts to try and destort it. I am talking things like ten million pounds in there, I wasn’t jumping to assumptions. So that left me with a set that I could use with the normal data principles we use every day. I did what’s called a ‘pivot table’, I did some averaging, that kind of thing. 
+And then a few dozens who put obviously fake high amounts to try and destort it. I am talking things like ten million pounds in there, I wasn't jumping to assumptions. So that left me with a set that I could use with the normal data principles we use every day. I did what's called a ‚Äòpivot table', I did some averaging, that kind of thing. 
 
-So because we planned it ahead, it meant it was quite simple, if we had stumble into it just through a comment thread, it would have been harder. It shows the value of thinking about what you might do with the results of crowdsourcing in advance.”
+So because we planned it ahead, it meant it was quite simple, if we had stumble into it just through a comment thread, it would have been harder. It shows the value of thinking about what you might do with the results of crowdsourcing in advance.‚Äù
 
 Q: There was a lot of manual work to sort out the data, how many people did you have on this?
 
-“Just me. We hadn’t really any idea it would get the momentum it did so I worked with the Sports blog editor, we put our heads together and thought this might be a fun project. We did it, start to finish, in 24 hours. We had the idea, we put something up at lunch time, we put it on the front of the site, we saw it was proving quite popular, we kept it on the front of the site for the rest of the day and we presented the results online the next morning.”
+‚ÄúJust me. We hadn't really any idea it would get the momentum it did so I worked with the Sports blog editor, we put our heads together and thought this might be a fun project. We did it, start to finish, in 24 hours. We had the idea, we put something up at lunch time, we put it on the front of the site, we saw it was proving quite popular, we kept it on the front of the site for the rest of the day and we presented the results online the next morning.‚Äù
 
 Q: What made you choose Google Doc for this, compared to other poll or survey tools that are available online?
 
-“It’s because it gives complete control over the results. I don’t have to use anyone else’s analytic tools. I can put it easily into a database software or into spreadsheets which was enough for that job. When you start using specialist polling softwares, you are often going through their tools and their restrictions. I think if the information we’d been asking for was particularly sensitive, we might have hesitated before using Google and thought about doing something ‘in house’. But generally, the ease of dropping a Google Form into a Guardian page and it’s virtually visible to the user that we are using one, is so convenient. 
+‚ÄúIt's because it gives complete control over the results. I don't have to use anyone else's analytic tools. I can put it easily into a database software or into spreadsheets which was enough for that job. When you start using specialist polling softwares, you are often going through their tools and their restrictions. I think if the information we'd been asking for was particularly sensitive, we might have hesitated before using Google and thought about doing something ‚Äòin house'. But generally, the ease of dropping a Google Form into a Guardian page and it's virtually visible to the user that we are using one, is so convenient. 
 
 Q: What advice would you give to other journalists who want to give a go to data crowdsourcing, in terms of what questions to ask the audience or how to tackle the subject?
 
-“- You have to have very specific things you want to know, and as much as possible, ask things that get multiple choice responses.
+‚Äú- You have to have very specific things you want to know, and as much as possible, ask things that get multiple choice responses.
 Try to get some basic demographics of who you are talking to so you can see if your sample might be biased.
-If you are asking for amounts and things like this, try in the guidance to specify that it’s in digits, that they have to use a specific currency and things like that. A lot won’t, but the more you hold their hand through, the better.
-and always, always put on a comment box because a lot of people will fill out the other things but what they really want is to give you their opinion on the story, specially on a consumer story or an outrage. You might actually be interested in only a few of the controlled fields but as long as they have got a chance to comment and as long as you use and reflects on some of the interesting ones, you get a much greater degree of response.”
+If you are asking for amounts and things like this, try in the guidance to specify that it's in digits, that they have to use a specific currency and things like that. A lot won't, but the more you hold their hand through, the better.
+and always, always put on a comment box because a lot of people will fill out the other things but what they really want is to give you their opinion on the story, specially on a consumer story or an outrage. You might actually be interested in only a few of the controlled fields but as long as they have got a chance to comment and as long as you use and reflects on some of the interesting ones, you get a much greater degree of response.‚Äù
 
-  * trust/ethical issues around data crowdsourcing/ limitation
+trust/ethical issues around data crowdsourcing/ limitation
 
-“There’s some kind of flaw in the theory that crowdsourcing is a realistic way of converting data into information and stories, because it doesn’t seem to be happening.” Nick Davies: Data, crowdsourcing and the ‘immeasurable confusion’ around Julian Assange
-
-- Some media create a ranking, reward system to establish trust within the community that contributes to their data (The Guardian, Citizen side, etc.)
-
-- Most importantly, webmasters are needed to verify and clean the data along the way
-
-- In the data crowdsourcing process, give precise guidelines to your crowd, ask people to give a source link to verify the information they contribute
 
 There is still a lot to be done to make crowdsourcing data more reliable.
- 
-
-END
-
-
-
-VERY ROUGH DRAFT!
-Marianne Bouchart will be writing up this section in the next few days with more information, a case study and an interview. Other members of the team were keen to learn about the subject but didn't have more to contribute on the spot.
-
-How to collaborate (or crowdsource) by combining Delicious and Google Docs
-
-INTRO
-
-How do you collect the data ? Introduction on how to get data using crowdsourcing
-
-Benefits of crowdsourcing data: crowdsource is a great way to to collect information on a specific topic, or even finding a story idea
-
-Difference between data you can use and data you can only read, how useful are they?
-
-Difference between active and passive contribution
-
-
-**1. Passive data crowdsourcing**
-
-Tools:
-People Browser
-Social mention (media monitoring tools)
-Disqus
-
-Keyword search, what is discussed about specific topics on the web? Look for the right keywords. Certain topics have different words in different countries (football, soccer, etc.). Make your search as specified or as wide as possible, as adapted as possible to your search. - consider language, land, target groups - gather information from different platforms to get a common opinion
-
-
-Good to cross check to make sure the information is reliable.
-
-
-**2. Active data crowdsourcing**
-
-Tools:
-Google Forms: via Tim Davies http://www.opendatacookbook.net/wiki/recipe/grow_your_own_with_google_forms
-Buzzdata
-Help me investigate
-My Society
-Twitter # examples: emergency hashtags like in an earthquake
-http://www.one.org/data/[Get the data.org]
+As Nick Davies said in a discussion at the Frontline Club: ‚ÄúThere's some kind of flaw in the theory that crowdsourcing is a realistic way of converting data into information and stories, because it doesn't seem to be happening.‚Äù Nick Davies: Data, crowdsourcing and the ‚Äòimmeasurable confusion' around Julian Assange
 
-The Guardian's data crowdsourcing projects --> case study by Marianne Bouchart
+To engage better with their audience and to try and develop a more reliable approach to crowdsourcing, some organisations create a ranking/reward system to establish trust within the community that contributes to their data (The Guardian, Citizen side, etc.)
 
-Googles Fusion Tables, wikis give people the link to it
-Polls (online or not) but ask the right questions (unbiased)
+Most importantly, webmasters are needed to verify and clean the data along the way.
 
+In the data crowdsourcing process, journalists need to give precise guidelines to their ‚Äúcrowd‚Äù, asking people to give a source link to verify the information they contribute.
 
+ 
 
-**3. Legal and ethical issues in data crowdsourcing**
+END
 
-how to verify the information people give? Can you trust the crowd?
+Relevant sources for other chapters? :
 
-Some media create a ranking, reward system to establish trust within the community that contributes to their data
+For the getting data chapter:
+Are those new resources mentioned? --> Ocean.data.gov, Geo.data.gov (which joins Energy.data.gov, health.data.goc and data.gov/Law)
 
-To verify whether a source is reliable, you could also check klout/kred ranking of sources?
+I will be interviewing Jeanne Holm, who is:
+- Co-Chair, eGovernment Interest Group at W3C
+- Data.gov, Evangelist at GSA
+- Chief Knowledge Architect at Jet Propulsion Laboratory
+- Chair, Knowledge Management at NASA
+- Instructor at UCLA
+- Member at International Academy of Astronautics
+- Chair, IAF Web and KM for Space at International Astronautical Federation
+(yes, she is all that ;D)
+I can hurry the interview to this week if you think it would be useful to the handbook. Just let me know.
+
+I also interviewed David Stevenson, open data consultant in the US and author of Data Dynamite about open public data if that could be of any interest, let me know‚Ä¶ I attached the audio file to this email so you can see whether it would be interesting or not to integrate that in the handbook. It is quite long but I was thinking of maybe using just some parts of it like:
+ 7m56sec Some people, some journalists even, think that open data is not for them because they are scared of numbers. What would you tell them?
+11m41sec on data visualisation tools
+14min23sec What do you think about data journalism and data visualizations, how important do you think they will be in the future?
+15min 09sec Stephenson's theory about the 2008 collapse and how data sharing could have prevented it.
+22min 05sec The impact that dat.gov has had in the US
+25min 05sec Is the US leading the way in terms of data liberation?
+39min 32sec The risks of real-time open data
+41min51sec 3 golden rules to access data online
+----
+The UNECE Making Data Meaningful guides
 
-Most importantly, webmasters are needed to verify and clean the data along the way
+http://www.unece.org/stats/documents/writing.html 
 
-In the data crowdsouricng process, give precise guidelines to your crowd, ask people to give a source link to verify the information they contribute
+Making Data Meaningful - Part 1: A guide to writing stories about numbers, by the United Nations Economic Commission for Europe http://www.unece.org/fileadmin/DAM/stats/documents/writing/MDM_Part1_English.pdf
 
-interview with Pete Forde from Buzz Data on legal and ethical issues around data crowdsourcing (already done, needs editing)
+Making Data Meaningful - Part2: A guide to presenting statistics by the United Nations Economic Commission for Europe http://www.unece.org/fileadmin/DAM/stats/documents/writing/MDM_Part2_English.pdf 
+-----
 
-CCL
-the future of crowdsourcing data for journalism
-whosedata.net project
-There is still a lot to be done to make crowdsourcing data more reliable. etc.
 
 
 You can now see a basic scraper operating: it downloads the web page, transforms it into the DOM form and then allows you to pick and extract certain content. Given this skeleton, you can try and solve some of the remaining problems using the ScraperWiki and Python documentation:
@@ -1804,8 +1855,8 @@
 Further Reading
 
 Other Tutorials:
-Scraperwiki screencast for non-programmers: http://blog.scraperwiki.com/2011/08/15/scraperwiki-tutorial-screencast-for-non-programmers/[http://blog.scraperwiki.com/2011/08/15/scraperwiki-tutorial-screencast-for-non-programmers/]
-ProPublica tutorial: http://www.propublica.org/nerds/item/scraping-websites[http://www.propublica.org/nerds/item/scraping-websites]
+Scraperwiki screencast for non-programmers: http://blog.scraperwiki.com/2011/08/15/scraperwiki-tutorial-screencast-for-non-programmers/
+ProPublica tutorial: http://www.propublica.org/nerds/item/scraping-websites
 
 
 
@@ -1816,10 +1867,10 @@
 
 
 Working with APIs:
-http://www.poynter.org/how-tos/digital-strategies/138211/beginners-guide-for-journalists-who-want-to-understand-api-documentation/[Beginner's guide for journalists who want to understand API documentation]
-Working with APIs: http://chronicle.com/blogs/profhacker/working-with-apis-part-1/22674[http://chronicle.com/blogs/profhacker/working-with-apis-part-1/22674]
-http://code.google.com/apis/chart/image/docs/making_charts.html[Getting Started With Google Charts] and Interactive Charts. There are also samples in the http://code.google.com/apis/chart/interactive/docs/gallery.html[Google Visualization API Gallery].
-http://onlinejournalismblog.com/2011/07/22/how-to-grab-useful-political-data-with-the-they-work-for-you-api/[How to grab useful political data with the They Work For You API]
+Beginner's guide for journalists who want to understand API documentation
+Working with APIs: http://chronicle.com/blogs/profhacker/working-with-apis-part-1/22674
+Getting Started With Google Charts and Interactive Charts. There are also samples in the Google Visualization API Gallery.
+How to grab useful political data with the They Work For You API
 
 
 
@@ -1849,15 +1900,15 @@
 
 === Become data literate in 3 simple steps by Nicolas Kayser-Bril (J++) ===
 
-Just as http://en.wikipedia.org/wiki/Literacy[literacy] refers to "the ability to read for knowledge, write coherently and think critically about printed material" data-literacy is the ability to consume for knowledge, produce coherently and think critically about data. Data literacy includes statistical literacy but also understanding how to work with large data sets, how they were produced, how to connect various data sets and how to interpret them. This chapter will focus on the former. The latter is covered in chapter 3.2 Working with data.
+Just as literacy refers to "the ability to read for knowledge, write coherently and think critically about printed material" data-literacy is the ability to consume for knowledge, produce coherently and think critically about data. Data literacy includes statistical literacy but also understanding how to work with large data sets, how they were produced, how to connect various data sets and how to interpret them. This chapter will focus on the former. The latter is covered in chapter 3.2 Working with data.
 
 Innumeracy is a big thing
 
-Poynter's News University offers classes of http://www.newsu.org/courses/math-journalists[Math for journalists], in which reporters get help with concepts such as percentage changes and averages. Interestingly enough, these concepts are being taught simultaneously near Poynter's offices, in Floridian schools, to fifth grade pupils (age 10-11), http://www.k12.com/courses/scope-sequence/ma5f1[as the curriculum attests].
+Poynter's News University offers classes of Math for journalists, in which reporters get help with concepts such as percentage changes and averages. Interestingly enough, these concepts are being taught simultaneously near Poynter's offices, in Floridian schools, to fifth grade pupils (age 10-11), as the curriculum attests.
 
-That journalists need help in math topics normally covered before high school shows how far newsrooms are from being data literate. This does not go without problems. How can a data-journalist make use of a bunch of numbers on climate change if she doesn't know what a confidence interval means? How can a data-reporter write a story on income distribution if he cannot tell the http://karenberger.suite101.com/mean-median-and-mode-journalists-guide-to-calculating-averages-a352390[mean from the median]?
+That journalists need help in math topics normally covered before high school shows how far newsrooms are from being data literate. This does not go without problems. How can a data-journalist make use of a bunch of numbers on climate change if she doesn't know what a confidence interval means? How can a data-reporter write a story on income distribution if he cannot tell the mean from the median?
 
-A reporter certainly does not need a degree in statistics to become more efficient when dealing with data. When faced with numbers, a few simple tricks can help her get a much better story. As Max Planck Institute professor http://datadrivenjournalism.net/news_and_analysis/the_importance_of_numeracy_for_data_journalists[Gerd Gigerenzer says], better tools will not lead to better journalism if they are not used with insight.
+A reporter certainly does not need a degree in statistics to become more efficient when dealing with data. When faced with numbers, a few simple tricks can help her get a much better story. As Max Planck Institute professor Gerd Gigerenzer says, better tools will not lead to better journalism if they are not used with insight.
 
 Get data literate in 3 simple steps!
 
@@ -1867,13 +1918,13 @@
 
 Amazing GDP growth
 
-The easiest way to show off with spectacular data is to fabricate it. It sounds obvious, but data as commonly commented upon as GDP figures can very well be phony. Former British ambassador Craig Murray reports in his book, http://www.amazon.com/Murder-Samarkand-Ambassadors-Controversial-Defiance/dp/1845962214[Murder in Samarkand], that growth rates in Uzbekistan are subject to intense negotiations between the local government and international bodies. In other words, it has nothing to do with the local economy.
+The easiest way to show off with spectacular data is to fabricate it. It sounds obvious, but data as commonly commented upon as GDP figures can very well be phony. Former British ambassador Craig Murray reports in his book, Murder in Samarkand, that growth rates in Uzbekistan are subject to intense negotiations between the local government and international bodies. In other words, it has nothing to do with the local economy.
 
-GDP is used as the number one indicator because governments need it to watch over their main source of income ‚Äì VAT. When a government is not funded by VAT, or when it does not make its budget public, it has no reason to collect GDP data and will be better-off fabricating them.
+GDP is used as the number one indicator because governments need it to watch over their main source of income ‚Äö√Ñ√¨ VAT. When a government is not funded by VAT, or when it does not make its budget public, it has no reason to collect GDP data and will be better-off fabricating them.
 
 Crime is always on the rise
 
-"Crime in Spain grew by 3%", http://internacional.elpais.com/internacional/2008/09/29/actualidad/1222639208_850215.html[writes El Pais]. Brussels is prey to increased crime from illegal aliens and drug addicts, http://www.rtl.be/info/votreregion/bruxelles/835282/criminalite-en-hausse-a-bruxelles-la-faute-aux-illegaux-et-aux-drogues-[says RTL]. This type of reporting based on police-collected statistics is common, but it doesn't tell us much about violence.
+"Crime in Spain grew by 3%", writes El Pais. Brussels is prey to increased crime from illegal aliens and drug addicts, says RTL. This type of reporting based on police-collected statistics is common, but it doesn't tell us much about violence.
 
 We can trust that within the European Union, the data isn't tampered with. But police personnel respond to incentives. When performance is linked to elucidation rate, for instance, policemen have an incentive to reports as much as possible on incidents that don't require an investigation. One such crime is smoking pot. This explains why drug-related crimes in France increased fourfold in the last 15 years while consumption remained constant.
 
@@ -1889,13 +1940,13 @@
 
 Risk of Multiple Sclerosis doubles when working at night
 
-Surely any German in her right mind would stop working night shifts after http://www.dmsg.de/multiple-sklerose-news/index.php?w3pid=news&kategorie=forschung&anr=2476[reading this headline]. But the article doesn't tell us what the risk really is in the end.
+Surely any German in her right mind would stop working night shifts after reading this headline. But the article doesn't tell us what the risk really is in the end.
 
-Take 1,000 Germans. http://www.springerlink.com/content/xg0vn3ygfk7x3le1/[A single one] will develop MS over his lifetime. Now, if every one of these 1,000 Germans worked night shifts, the number of MS sufferers would jump to 2. The additional risk of developing MS when working in shifts is 1 in 1,000, not 100%. Surely this information is more useful when pondering whether to take the job.
+Take 1,000 Germans. A single one will develop MS over his lifetime. Now, if every one of these 1,000 Germans worked night shifts, the number of MS sufferers would jump to 2. The additional risk of developing MS when working in shifts is 1 in 1,000, not 100%. Surely this information is more useful when pondering whether to take the job.
 
 On average, 1 in every 15 Europeans totally illiterate
 
-The above headline looks frightening. It is also absolutely true. Among the 500 million Europeans, 36 million probably don't know how to read. As an aside, 36 million are also under 7 (data from http://epp.eurostat.ec.europa.eu/portal/page/portal/statistics/search_database[Eurostat]).
+The above headline looks frightening. It is also absolutely true. Among the 500 million Europeans, 36 million probably don't know how to read. As an aside, 36 million are also under 7 (data from Eurostat).
 
 When writing about an average, always think "an average of what?" Is the reference population homogeneous? Uneven distribution patterns explain why most people drive better than average, for instance. Many people have zero or just one accident over their lifetime. A few reckless drivers have a great many, pushing the average number of accidents way higher than what most people experience. The same is true of the income distribution: most people earn less than average.
 
@@ -1907,13 +1958,13 @@
 
 The sample size problem
 
-"80% dissatisfied with the judicial system", says a survey http://www.diariodenavarra.es/noticias/mas_actualidad/sociedad/una_encuesta_revela_que_casi_los_espanoles_esta_insatisfecho_con_justicia_50090_1035.html[reported in Zaragoza-based Diaro de Navarra]. How can one extrapolate from 800 respondents to 46 million Spaniards? Surely this is full of hot air.
+"80% dissatisfied with the judicial system", says a survey reported in Zaragoza-based Diaro de Navarra. How can one extrapolate from 800 respondents to 46 million Spaniards? Surely this is full of hot air.
 
 When researching a large population (over a few thousands), you rarely need more than a thousand respondents to achieve a margin of error under 3%. It means that if you were to retake the survey with a totally different sample, 9 times out of 10, the answers you'll get will be within a 3% interval of the results you had the first time around. Statistics are a powerful thing, and sample sizes are rarely to blame in dodgy surveys.
 
 Drinking tea lowers the risk of stroke
 
-Articles about the benefits of tea-drinking are commonplace. This short http://www.welt.de/print-welt/article249051/Tee_schuetzt_vor_Herzinfarkt.html[item in Die Welt] saying that tea lowers the risk of myocardial infarction is no exception. Although the effects of tea are seriously studied by some, many pieces of research fail to take into account lifestyle factors, such as diet, occupation or sports.
+Articles about the benefits of tea-drinking are commonplace. This short item in Die Welt saying that tea lowers the risk of myocardial infarction is no exception. Although the effects of tea are seriously studied by some, many pieces of research fail to take into account lifestyle factors, such as diet, occupation or sports.
 
 In most countries, tea is a beverage for the health-conscious upper classes. If researchers don't control for lifestyle factors in tea studies, they tell us nothing more than 'rich people are healthier - and they probably drink tea'.
 
@@ -1930,19 +1981,19 @@
 Tools
 
 Section 3.3 of this book
-http://www.tcij.org/training-material/data-journalism[Excel for data journalists]: How do simple operations (averages, proportions) in Excel.
+Excel for data journalists: How do simple operations (averages, proportions) in Excel.
 
 Blogs
 
-http://xkcd.com/[XKCD]: Nerdy strips that often make use of statistical concepts.
-http://understandinguncertainty.org/blog[Understanding uncertainty]: Analysis of risk-related current events.
+XKCD: Nerdy strips that often make use of statistical concepts.
+Understanding uncertainty: Analysis of risk-related current events.
 
 Books
 
-http://www.amazon.com/Calculated-Risks-Know-Numbers-Deceive/dp/0743254236/ref=sr_1_2?ie=UTF8&qid=1314092449&sr=8-2[Calculated Risks], by Gerd Gigerenzer. The most comprehensive piece on how to communicate risks effectively and how to understand what a percentage really means. If you want to be able to debunk PR mystifications, that's the place to start.
-http://www.amazon.com/Tiger-That-Isnt-Andrew-Dilnot/dp/1846681111/ref=sr_1_1?ie=UTF8&qid=1321014673&sr=8-1[The Tiger that isn't], by Andrew Dilnot & Michael Blastland. Lots of examples (from the UK) examining journalistic failures at fending off data-driven PR.
-http://www.amazon.com/Numbers-Rule-Your-World-Probabilities/dp/0071626530/ref=sr_1_1?ie=UTF8&qid=1314092432&sr=8-1[Numbers Rule Your World], by Kaiser Fung. The easier-to-read version of Gigerenzer's book. Through 6 in-depth examples, it introduces you to similar concepts but remains shallow.
-http://www.amazon.com/Proofiness-Dark-Arts-Mathematical-Deception/dp/0670022160/ref=sr_1_1?ie=UTF8&qid=1314092460&sr=8-1[Proofiness], by Charles Seife. Explains in an enjoyable way how numbers can be fabricated ‚Äì and how you can deconstruct them.
+Calculated Risks, by Gerd Gigerenzer. The most comprehensive piece on how to communicate risks effectively and how to understand what a percentage really means. If you want to be able to debunk PR mystifications, that's the place to start.
+The Tiger that isn't, by Andrew Dilnot & Michael Blastland. Lots of examples (from the UK) examining journalistic failures at fending off data-driven PR.
+Numbers Rule Your World, by Kaiser Fung. The easier-to-read version of Gigerenzer's book. Through 6 in-depth examples, it introduces you to similar concepts but remains shallow.
+Proofiness, by Charles Seife. Explains in an enjoyable way how numbers can be fabricated ‚Äö√Ñ√¨ and how you can deconstruct them.
 
 === Tips for working with numbers in the news from Michael Blastland (BBC) ===
 
@@ -1954,7 +2005,7 @@
 
 1. The best tip for handling data is to enjoy yourself. Data can appear forbidding. But allow it to intimidate you and you'll get nowhere. Treat it as something to play with and explore and it will often yield secrets and stories with surprising ease. So handle it simply as you'd handle other evidence, without fear or favour. In particular, think of this as an exercise in imagination. Be creative by thinking of the alternative stories that might be consistent with the data and explain it better, then test them against more evidence. 'What other story could explain this?' is a handy prompt to think about how this number, this obviously big or bad number, this clear proof of this or that, might be nothing of the sort.
 
-2. Don't confuse scepticism about data with cynicism. Scepticism is good; cynicism has simply thrown up its hands and quit. If you believe in data journalism, and you probably do or you wouldn't be reading this book, then you must believe that data has something far better to offer than the lies and damned lies of caricature or the killer facts of swivel-eyed headlines. Data often give us profound knowledge, if used carefully. We need to be neither cynical nor na√Øve, but alert.
+2. Don't confuse scepticism about data with cynicism. Scepticism is good; cynicism has simply thrown up its hands and quit. If you believe in data journalism, and you probably do or you wouldn't be reading this book, then you must believe that data has something far better to offer than the lies and damned lies of caricature or the killer facts of swivel-eyed headlines. Data often give us profound knowledge, if used carefully. We need to be neither cynical nor na‚àö√òve, but alert.
 
 3. If I tell you that drinking has gone up during the recession, you might tell me it's because everyone is depressed. If I tell you that drinking is down, you might tell me it's because everyone is broke. In other words, what the data says makes no difference to the interpretation that you are determined to put on it, namely that things are terrible one way or the other. If it goes up, it's bad, if it goes down, it's bad. The point here is that if you believe in data, try to let it speak before you slap on your own mood, beliefs or expectations. There's so much data about that you will often be able to find confirmation of your prior beliefs if you simply look around a bit. In other words, data journalism, to me at least, adds little value if you are not open-minded. It is only as objective as you strive to make it, and not by virtue of being based on numbers.
 
@@ -1965,7 +2016,7 @@
 6. The best questions are the old ones: is that really a big number? Where did it come from? Are you sure it counts what you think it counts? These are generally just prompts to think around the data, the stuff at the edges that got squeezed by looking at a single number, the real-life complications, the wide range of other potential comparisons over time, group or geography; in short, context.
 
 To add:
-http://blogs.channel4.com/factcheck/welcome-to-the-new-factcheck-blog/18[http://blogs.channel4.com/factcheck/welcome-to-the-new-factcheck-blog/18]
+http://blogs.channel4.com/factcheck/welcome-to-the-new-factcheck-blog/18
 
 
 === Basic steps in working with data by Steve Doig (Walter Cronkite School of Journalism) ===
@@ -1986,7 +2037,7 @@
 Consider an example involving local crime reports. Let's say you want to do a story looking at crime patterns in your city, and the statements you want to make involve the times of day and the days of a week in which different kinds of crimes are most likely to happen, as well as what parts of town are hot spots for various crime categories.
 You would realize that your data request has to include the date and the time each crime was reported, the kind of crime (murder, theft, burglary, etc.) as well as the address of where the crime occurred. So Date, Time, Crime Category and Address are the minimum variables you need to answer those questions.
 But be aware that there are a number of potentially interesting questions that this four-variable data set CAN'T answer, like the race and gender of victims, or the total value of stolen property, or which officers are most productive in making arrests. Also, you may only be able to get records for a certain time period, like the past three years, which would mean you couldn't say anything about whether crime patterns have changed over a longer period of time. Those questions may be outside of the planned purview of your story, and that's fine. But you don't want to get into your data analysis and suddenly decide you need to know what percent of crimes in different parts of town are solved by arrest.
-One lesson here is that it's often a good idea to request ALL the variables and records in the database, rather than the subset that could answer the questions for the immediate story. (In fact, getting all the data can be cheaper than getting a subset, if you have to pay the agency for the programming necessary to write out the subset.) You can always subset the data on your own, and having access to the full data set will let you answer new questions that may come up in your reporting and even produce new ideas for follow-up stories. It may be that confidentiality laws or other policies mean that some variables, such as the identities of victims or the names of confidential informants, can't be released. But even a partial database is much better than none, as long as you understand which questions the redacted database can ‚Äì and ‚Äì can't answer.
+One lesson here is that it's often a good idea to request ALL the variables and records in the database, rather than the subset that could answer the questions for the immediate story. (In fact, getting all the data can be cheaper than getting a subset, if you have to pay the agency for the programming necessary to write out the subset.) You can always subset the data on your own, and having access to the full data set will let you answer new questions that may come up in your reporting and even produce new ideas for follow-up stories. It may be that confidentiality laws or other policies mean that some variables, such as the identities of victims or the names of confidential informants, can't be released. But even a partial database is much better than none, as long as you understand which questions the redacted database can ‚Äö√Ñ√¨ and ‚Äö√Ñ√¨ can't answer.
 
 **2. Find the right data sources**
 
@@ -2009,7 +2060,7 @@
 Logical errors, e.g. proportions with a percentage greater than 100%
 
 A good quick way to look for messiness is to create frequency tables of the categorical variables, the ones that would be expected to have a relatively small number of different values. (When using Excel, for instance, you can do this by using Filter or Pivot Tables on each categorical variable.)
-Take "Gender", an easy example. You may discover that your Gender field includes any of a mix of values like these: Male, Female, M, F, 1, 0, MALE, FEMALE, etc., including misspellings like Femal. To do a proper gender analysis, you must standardize ‚Äì Decide on M and F, perhaps, and then change all the variations to match the standards. Another common database with these kinds of problems are American campaign finance records, where the Occupation field might list "Lawyer", "Attorney", "Atty", "Counsel", "Trial Lawyer" and any of a wealth of variations and misspellings; again, the trick is to standardize the occupation titles into a shorter list of possibilities.
+Take "Gender", an easy example. You may discover that your Gender field includes any of a mix of values like these: Male, Female, M, F, 1, 0, MALE, FEMALE, etc., including misspellings like Femal. To do a proper gender analysis, you must standardize ‚Äö√Ñ√¨ Decide on M and F, perhaps, and then change all the variations to match the standards. Another common database with these kinds of problems are American campaign finance records, where the Occupation field might list "Lawyer", "Attorney", "Atty", "Counsel", "Trial Lawyer" and any of a wealth of variations and misspellings; again, the trick is to standardize the occupation titles into a shorter list of possibilities.
 Data cleanup gets even more problematic when working with names. Are "Joseph T. Smith", "Joseph Smith", "J.T. Smith", "Jos. Smith" and "Joe Smith" all the same person? It may take looking at other variables like address or date of birth, or even deeper research in other records, to decide. But tools like Google Refine can make the cleanup and standardization task faster and less tedious.
 Logical errors, e.g. proportions with a percentage greater than 100%
 Anomalous figures, e.g. data points that can't possibly be true
@@ -2017,7 +2068,7 @@
 
 Recognising anomalous figures requires some prior knowledge on your part, a familiarity with the subject of the data. If you were collecting the total number of US states won by candidate in the American presidential election, for example, you wouldn't expect to see Arnold Schwarzenegger on the list (however much you might want it to be true).
 
-Correlation between two variables can help detect outliers in your data. Deciding when to ignore them in your analysis can be tricky, however. The human http://en.wikipedia.org/wiki/Apophenia[brain detects meaningful patterns in random data], which means we can be tempted to remove outliers to create a clearer picture of what we hope to find. If you keep looking hard enough at the data, patterns will emerge from the noise. The danger is that you'll manipulate your data to fit the story you're looking for, cherry-picking the points that help support a result you're hoping to get, rather than giving the true story.
+Correlation between two variables can help detect outliers in your data. Deciding when to ignore them in your analysis can be tricky, however. The human brain detects meaningful patterns in random data, which means we can be tempted to remove outliers to create a clearer picture of what we hope to find. If you keep looking hard enough at the data, patterns will emerge from the noise. The danger is that you'll manipulate your data to fit the story you're looking for, cherry-picking the points that help support a result you're hoping to get, rather than giving the true story.
 
 **4. Data may have undocumented features**
 
@@ -2043,7 +2094,7 @@
 
 Not all data comes from measurement of real-life numbers. From individuals to organisations, the pressure to support an argument with stats can unfortunately lead people to fabricate, falsify and omit data.
 
-Even those who understand the importance of good data aren't beyond reproach: for example, http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0005738[2% of scientists have admitted to tampering with data]. This is a conservative estimate based on surveys, so the true number of researchers who have committed fraud through data manipulation may be much higher.
+Even those who understand the importance of good data aren't beyond reproach: for example, 2% of scientists have admitted to tampering with data. This is a conservative estimate based on surveys, so the true number of researchers who have committed fraud through data manipulation may be much higher.
 
 So how do you identify dodgy data? Although it's impossible to spot fraud simply by looking at numbers directly, luckily there are a few statistical tests that can help you detect anomalies. One of the most practical is a strange statistical phenomenon known as Benford's law, or the leading-digit law.
 
@@ -2062,7 +2113,7 @@
 
 - Link to 3.3 tools for analysing data (more specific on the types of things you can do to mend data with
 
-=== The £32 loaf of bread by Claire Miller (WalesOnline) ===
+=== The ¬£32 loaf of bread by Claire Miller (WalesOnline) ===
 
 ////
 
@@ -2070,9 +2121,9 @@
 
 ////
 
-A story for Wales on Sunday about how much the Welsh Government is spending on prescriptions for gluten-free products, contained the headline figure that it was paying £32 for a loaf of bread. (http://www.walesonline.co.uk/news/wales-news/2011/07/17/prescriptions-for-gluten-free-bread-costing-welsh-taxpayers-32-a-loaf-91466-29067430/[http://www.walesonline.co.uk/news/wales-news/2011/07/17/prescriptions-for-gluten-free-bread-costing-welsh-taxpayers-32-a-loaf-91466-29067430/])
+A story for Wales on Sunday about how much the Welsh Government is spending on prescriptions for gluten-free products, contained the headline figure that it was paying ¬£32 for a loaf of bread. (http://www.walesonline.co.uk/news/wales-news/2011/07/17/prescriptions-for-gluten-free-bread-costing-welsh-taxpayers-32-a-loaf-91466-29067430/)
 
-However, this was actually 11 loaves that cost ¬£2.82 each.
+However, this was actually 11 loaves that cost ¬¨¬£2.82 each.
 
 The figures, from a Welsh Assembly written answer and a Welsh NHS statistics release, listed the figure as cost per prescription item. However, they gave no additional definition in the data dictionary of what a prescription item might refer or how a separate quantity column might define it.
 
@@ -2131,47 +2182,47 @@
 **2. Tools for data filtering, interrogation, combination and analysis**
 Beginner level
 Spreadsheets
-Manual on Excel and Pivot Tables: http://www.tcij.org/training-material/data-journalism[http://www.tcij.org/training-material/data-journalism]
+Manual on Excel and Pivot Tables: http://www.tcij.org/training-material/data-journalism
 Google Spreadsheets
-Tutorial Excel: http://blog.buzzdata.com/post/11607498580/visualizing-torontos-water-usage-a-tutorial[http://blog.buzzdata.com/post/11607498580/visualizing-torontos-water-usage-a-tutorial]
+Tutorial Excel: http://blog.buzzdata.com/post/11607498580/visualizing-torontos-water-usage-a-tutorial
 Google Refine
-http://vis.stanford.edu/wrangler/[Stanford Data Wrangler]
-http://datapatterns.org/[Data Patterns]
-http://www.poynter.org/how-tos/digital-strategies/155975/how-journalists-can-use-google-refine-to-clean-dirty-data-sets/[How journalists can use Google Refine to clean 'dirty' data sets]
-http://overview.ap.org/[The Overview Project]
+Stanford Data Wrangler
+Data Patterns
+How journalists can use Google Refine to clean 'dirty' data sets
+The Overview Project
 http://googlerefine.blogspot.com/
 Cleaning data with Google Refine
-http://www.opendatacookbook.net/wiki/recipe/sliced_and_diced_aid_data_with_google_refine[http://www.opendatacookbook.net/wiki/recipe/sliced_and_diced_aid_data_with_google_refine]
-http://www.propublica.org/nerds/item/using-google-refine-for-data-cleaning[http://www.propublica.org/nerds/item/using-google-refine-for-data-cleaning]
-http://www.slideshare.net/onlinejournalist/combining-data-with-google-refine[Combining data with Google Refine]
+http://www.opendatacookbook.net/wiki/recipe/sliced_and_diced_aid_data_with_google_refine
+http://www.propublica.org/nerds/item/using-google-refine-for-data-cleaning
+Combining data with Google Refine
 Databases
 Microsoft Access / Filemaker (Mac)
 open-source SQL database managers
-http://www.w3schools.com/sql/default.asp[SQL Tutorial]
-https://github.com/tthibo/SQL-Tutorial#readme[A Gentle Introduction to SQL Using SQLite]
-http://notebook.okfn.org/2011/10/08/introducing-sql-for-lightweight-data-manipulation/[Introducing SQL for Lightweight Data Manipulation]
-http://helpmeinvestigate.posterous.com/structured-query-language-sql-an-introduction[Structured Query Language (SQL): an introduction]
+SQL Tutorial
+A Gentle Introduction to SQL Using SQLite
+Introducing SQL for Lightweight Data Manipulation
+Structured Query Language (SQL): an introduction
 NoSQL Databases
 Key Value Store
 Document Store
 Google Fusion Tables
-demo in http://www.opendatacookbook.net/wiki/recipe/fusion_cooking_with_foraged_data[Open Data Cookbook]
-http://support.google.com/fusiontables/bin/answer.py?hl=en&answer=185991[What options exist for displaying icons, lines and polygon colors on the map?]
-http://blog.buzzdata.com/post/12201120862/how-to-map-in-fusion-tables-a-basic-tutorial[How to map in Fusion Tables: a basic tutorial]
-http://michelleminkoff.com/2011/08/21/how-to-combine-multiple-fusion-tables-into-one-map/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+michelleminkofffeed+%28Michelle+Minkoff%29&utm_content=Google+Reader[How to combine multiple Fusion Tables into one map]
-http://michelleminkoff.com/2011/10/30/answering-some-faqs-about-fusion-tables/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+michelleminkofffeed+%28Michelle+Minkoff%29&utm_content=Google+Reader[Answering some FAQs about Fusion Tables]
+demo in Open Data Cookbook
+What options exist for displaying icons, lines and polygon colors on the map?
+How to map in Fusion Tables: a basic tutorial
+How to combine multiple Fusion Tables into one map
+Answering some FAQs about Fusion Tables
 
 
 
 Yahoo Pipes:
-http://www.slideshare.net/onlinejournalist/introduction-to-yahoo-pipes[Introduction to Yahoo Pipes]
-http://www.youtube.com/watch?v=J3tS_DkmbVA[Learn How to Build a Pipe in Just a Few Minutes on Yahoo!]
-http://blog.ouseful.info/2010/10/27/discovering-co-location-communities-tweets-near-wherever/[Discovering Co-location Communities ‚Äì Twitter Maps of Tweets Near Wherever‚Ä¶]
+Introduction to Yahoo Pipes
+Learn How to Build a Pipe in Just a Few Minutes on Yahoo!
+Discovering Co-location Communities ‚Äö√Ñ√¨ Twitter Maps of Tweets Near Wherever‚Äö√Ñ¬∂
 
 
 XML
 
-http://onlinejournalismblog.com/2011/08/05/sftw-asking-questions-of-a-webpage-and-finding-out-when-those-answers-change/[http://onlinejournalismblog.com/2011/08/05/sftw-asking-questions-of-a-webpage-and-finding-out-when-those-answers-change/]
+http://onlinejournalismblog.com/2011/08/05/sftw-asking-questions-of-a-webpage-and-finding-out-when-those-answers-change/
 
 
 
@@ -2182,18 +2233,18 @@
 UCINet, Gephi, NodeXL
 Example: Social networks
 R
-http://www.peteraldhous.com/CAR/Aldhous_CAR2011_RforStats.pdf[R for Statistics: First Steps] (PDF) by Peter Aldhous, http://jacobfenton.s3.amazonaws.com/R-handson.pdf[Hands-on R, a step-by-step tutorial] (PDF) by Jacob Fenton, and the project's own An Introduction to R.
-The http://www.r-statistics.com/tag/visualization/[R Statistics blog] has a number of visualization samples.
-http://www.readwriteweb.com/hack/2011/09/unlocking-big-data-with-r.php[Unlocking Big Data with R]
-http://blog.ouseful.info/2011/10/31/power-tools-for-aspiring-data-journalists-r/[Power Tools for Aspiring Data Journalists: Funnel Plots in R]
+R for Statistics: First Steps (PDF) by Peter Aldhous, Hands-on R, a step-by-step tutorial (PDF) by Jacob Fenton, and the project's own An Introduction to R.
+The R Statistics blog has a number of visualization samples.
+Unlocking Big Data with R
+Power Tools for Aspiring Data Journalists: Funnel Plots in R
 Book for journalists: Where are the bodies buried on the web? Big data for journalists: 'This short guide will cover my favorite resources, along with a few examples of how they've been used to create compelling journalism.'
-http://csvkit.readthedocs.org/en/latest/index.html[CSVKit] ("Got a fixed-width file and wish it was easier to work with? Look at FFS It's a list of schemas for converting fixed-width files to CSV using this tool)
+CSVKit ("Got a fixed-width file and wish it was easier to work with? Look at FFS It's a list of schemas for converting fixed-width files to CSV using this tool)
 
 
 
 Network Analysis
-Download this detailed http://casci.umd.edu/images/4/46/NodeXL_tutorial_draft.pdf[free NodeXL tutorial] (PDF) or these basic step-by-step instructions on http://faculty.washington.edu/pnhoward/teaching/newmedia/socialnetworkmap.pdf[analyzing your own Facebook social network] (PDF).
-http://onlinejournalismblog.com/2011/11/15/network-analysis-html5-data-journalism/[Following the money: making networks visible with HTML5]
+Download this detailed free NodeXL tutorial (PDF) or these basic step-by-step instructions on analyzing your own Facebook social network (PDF).
+Following the money: making networks visible with HTML5
 
 
 
@@ -2209,9 +2260,9 @@
 
 Mapping and visualisation
 Geocoding
-http://www.gpsvisualizer.com/geocoder/[GPS Visualiser]
-http://onlinejournalismblog.com/2011/08/12/how-to-convert-eastingnorthing-into-latlong-for-an-interactive-map/[How to: convert easting/northing into lat/long for an interactive map]
-http://www.doogal.co.uk/[Postcode Finder]
+GPS Visualiser
+How to: convert easting/northing into lat/long for an interactive map
+Postcode Finder
 
 
 **4. Tools for distributing your data projects**
@@ -2237,7 +2288,7 @@
 
 Make it exciting and remember who your audience are as you go.
 
-One example of this can be found in a project carried out by the Bureau of Investigative Journalism using the EU Commission's http://ec.europa.eu/beneficiaries/fts/index_en.htm[Financial Transparency System]. The story was constructed by approaching the data set with specific queries in mind.
+One example of this can be found in a project carried out by the Bureau of Investigative Journalism using the EU Commission's Financial Transparency System. The story was constructed by approaching the data set with specific queries in mind.
 
 We looked through the data for key terms like 'cocktail', 'golf' and 'away days'. This allowed us to determine what the Commission had spent on these items and raised plenty of questions and story lines to follow up.
 
@@ -2253,7 +2304,7 @@
 
 We queried the data, based on the Commission's own rules about what kinds of companies and associations should be prohibited from receiving structural funds. One example was expenditure on tobacco and tobacco producers.
 
-By querying the data with the names of tobacco companies, producers and growers we found data that revealed British American Tobacco were receiving ‚Ç¨1.5m for a factory in Germany.
+By querying the data with the names of tobacco companies, producers and growers we found data that revealed British American Tobacco were receiving ‚Äö√á¬®1.5m for a factory in Germany.
 
 As the funding was outside the rules of Commission expenditure, it was a quick way to find a story in the data.
 
@@ -2263,6 +2314,52 @@
 
 == 6. Delivering data ==
 
+=== How to build a news app by Chase Davis (Center for Investigative Reporting) ===
+
+News applications are windows into the data behind a story. They might be searchable databases, sleek visualizations or something else altogether. But no matter what form they take, news apps encourage readers to interact with data in a context that is meaningful to them: looking up crime trends in their area, checking the safety records of their local doctor, or searching political contributions to their candidate of choice. 
+
+More than just high-tech infographics, the best news apps are durable products. They live outside the news cycle, often by helping readers solve real-world problems, or answering questions in such a useful or novel way that they become enduring resources. When journalists at ProPublica wanted to explore the safety of American kidney dialysis clinics, they built http://projects.propublica.org/dialysis/[an application] that helped users check whether their hometown facility was safe. Providing such an important and relevant service creates a relationship with users that reaches far beyond what a narrative story can do alone.
+
+Therein lies both the challenge and the promise of building cutting-edge news apps: creating something of lasting value.  Whether you are a developer or a manager, any discussion about how to build a great news app should start with a product development mentality: Keep a laser focus on the user, and work to get the most bang for your buck. So before you start building, it helps to ask yourself three questions:
+
+**1. Who is my audience and what are their needs?**
+
+News apps don't serve the story for its own sake – they serve the user. Depending on the project, that user might be a dialysis patient who wants to know about the safety record of her clinic, or even a homeowner unaware of earthquake hazards near his home. No matter who it is, any discussion about building a news app, like any good product, should start with the people who are going to use it.
+
+A single app might serve many users. For instance, a project called http://curbwise.com/[Curbwise], built by the Omaha (Nebraska) World-Herald serves homeowners who believe they are being overtaxed; curious residents who are interested in nearby property values; and real estate workers trying to keep track of recent sales. In each of those cases, the app meets a specific need that keeps users coming back.
+
+Homeowners, for instance, might need help gathering information on nearby properties so they can argue that their taxes are unfairly high. Pulling together that information is time-consuming and complicated – a problem Curbwise solves for its users by compiling a http://curbwise.com/how-to-protest[user-friendly report] of all the information they need to challenge their property taxes to local authorities. Curbwise sells that report for $20, and people pay for it because it solves a real problem in their lives.
+
+Whether your app solves a real-world problem like Curbwise or supplements the narrative of a story with an interesting visualization, always be aware of the people who will be using it. And then concentrate on designing and building features based on their needs.
+
+**2. How much time should I spend on this?**
+
+Developers in the newsroom are like water in the desert: highly sought after and in short supply. Building news apps means balancing the daily needs of a newsroom against the long-term commitments it takes to build truly great products.
+
+Say your editor comes to you with an idea: The City Council is set to have a vote next week about whether to demolish several historic properties in your town. He suggests building a simple application that allows users to see the buildings on a map.
+
+As a developer, you have a few options. You can flex your engineering muscle by building a gorgeous map using custom software. Or you can use existing tools like Google Fusion Tables or open source mapping libraries and finish the job in a couple hours. The first option will give you a better app; but the second might give you more time to build something else with a better chance of having a lasting impact.
+
+Just because a story lends itself to a complex, beautiful news app doesn't mean you need to build one. Balancing priorities is critical. The trick is to remember that every app you build comes at a cost: namely, another potentially more impactful app you could have been working on instead. 
+
+**3. How can I take things to the next level?**
+
+Building high-end news apps can be time-consuming and expensive. That's why it always pays to ask about the payoff. How do you elevate a one-hit wonder into something special?
+
+Creating an enduring project that transcends the news cycle is one way. But so is building a tool that saves you time down the road (and open sourcing it!), or applying advanced analytics to your app to learn more about your audience.
+
+Lots of organizations build Census maps to show demographic shifts in their cities. But when the Chicago Tribune news apps team http://media.apps.chicagotribune.com/chicago-census/less-than-five.html[built theirs], they took things to the next level by developing tools and techniques to build those maps quickly, which they then http://blog.apps.chicagotribune.com/2011/03/08/making-maps-1/[made available] for other organizations to use.
+
+At my employer, the Center for Investigative Reporting, we coupled a simple searchable database with a fine-grained event tracking framework that allowed us to learn, among other things, how much users value serendipity and exploration in our news apps.
+
+At the risk of sounding like a bean-counter, always think about http://cironline.org/blog/post/beyond-three-ps-few-more-thoughts-business-news-apps[return on investment]. Solve a generic problem; create a new way to engage users; open source parts of your work; use analytics to learn more about your users; or even find cases like Curbwise where part of your app might generate revenue.
+
+**Wrapping up**
+
+News application development has come a long way in a very short time. News Apps 1.0 were a lot like Infographics 2.0 – interactive data visualizations, mixed with searchable databases, designed primarily to advance the narrative of the story. Now, many of those apps can be designed by reporters on deadline using open source tools, freeing up developers to think bigger thoughts.
+
+News Apps 2.0, where the industry is headed, is about combining the storytelling and public service strengths of journalism with the product development discipline and expertise of the technology world. The result, no doubt, will be an explosion of innovation around ways to make data relevant, interesting and especially useful to our audience – and at the same time hopefully helping journalism do the same.
+
 === Cunning Title for data visualisation chapter by Sarah Cohen (Washington Post) ===
 
 ////
@@ -2298,17 +2395,17 @@
 
 
 
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.rvt2hrtn99vh[The Data Journalism Handbook]
-4.3 https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.hn4t54n4ivru[Visualising data]
-4.3.1 https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.asz4fi3f5zz5[Roles of visualisation in journalism]
-4.3.2 https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.t6ljn9be97y9[Tools, tutorials and good examples of using visualisations to find stories]
-4.3.3 https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.am985xa1bkgf[Tools, tutorials and good examples of using visualisations to tell stories]
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.1kytl98ysj1u[When to use and when not to use visualisations to tell a story]
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.g1uyn5fojqgm[Types of stories visualisations can tell]
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.jzg4x2okmxk7[Which is the right visualisation for your story?]
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.8rrm06qq578m[Examples of good use of visualisations to tell stories]
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.8bihqssv6frx[When is a visualisation good and when is it bad?]
-https://docs.google.com/a/intern.ejc.net/document/d/1-KOWA-KSNtapAKbMG4DY0776WorunW8bJMCSoVlL9io/edit#heading=h.64kczy87qwoj[Toolkits and tutorials]
+The Data Journalism Handbook
+4.3 Visualising data
+4.3.1 Roles of visualisation in journalism
+4.3.2 Tools, tutorials and good examples of using visualisations to find stories
+4.3.3 Tools, tutorials and good examples of using visualisations to tell stories
+When to use and when not to use visualisations to tell a story
+Types of stories visualisations can tell
+Which is the right visualisation for your story?
+Examples of good use of visualisations to tell stories
+When is a visualisation good and when is it bad?
+Toolkits and tutorials
 
 
 
@@ -2349,14 +2446,14 @@
 (quote by William S. Cleveland in the preface of his book 'Visualising data')
 
 Everything is visualised
-Q: When do you need to visualise a dataset to explore it and find a story? When donÔøΩt you need to?
+Q: When do you need to visualise a dataset to explore it and find a story? When don√î√∏Œ©t you need to?
 
 Data by itself, consisting of bits and bytes stored in a file on a computer hard-drive, is invisible. In order to be able to see and make any sense of data, we need to visualise it. In this chapter I'm going to use a broader understanding of the term visualising, that includes even pure textual representations of data. For instance, just loading a dataset into a spreadsheet software can be considered as data visualisation. The invisible data suddenly turns into a visible 'picture' on our screen. Thus, the questions should not be whether journalists need to visualise data or not, but which kind of visualisation may be the most useful in which situation. In other words: when does it makes sense to go beyond the table visualisation.
 
 The short answer is: almost always. Tables alone are definitely not sufficient to give us some kind of overview or big picture of a dataset. Also tables alone don't allow us to immediately identify patterns within the data. The most common example here are geographical patterns which can only be observed after visualizing data on a map. But there are also other kinds of patterns which we will see later in this chapter.
 
 How can visualisation help us to discover a story in a dataset?
-How do you go about discovering a story? What tools do you use? What ÔøΩprotocolÔøΩ do you follow? What clues do you follow, what do you pay attention to? (lessons, tips, advice).
+How do you go about discovering a story? What tools do you use? What √î√∏Œ©protocol√î√∏Œ© do you follow? What clues do you follow, what do you pay attention to? (lessons, tips, advice).
 
 Well, discovering a story through visualisation is a rather big goal to start with. In fact, there is no set of rules or "protocol" that will guarantee us to discover a story. Instead, I think it makes more sense to seek for smaller chunks of knowledge, from now on called insights.
 
@@ -2422,7 +2519,7 @@
 The sample visualizations in the next section were created using the R, which is kind of the swiss army knife of scientific data visualisation.
 
 Example session: making sense of US election contribution data
-Examples of how to explore a dataset with a visualisation tool with a step by step description of the ÔøΩprotocolÔøΩ followed to find the story.
+Examples of how to explore a dataset with a visualisation tool with a step by step description of the √î√∏Œ©protocol√î√∏Œ© followed to find the story.
 
 Let us have look at the US Presidential Campaign Finance database which contains about 450,000 contributions to US Presidential candidates. The CSV file is 60 megabytes and way to large to handle it easily in Excel.
 
@@ -2506,11 +2603,11 @@
 
 ////
 
-There are times when data can tell a story better than words or photos, and this is why terms like "news application" and "data visualization" have attained buzzword status in so many newsrooms of late. Also fueling interest is the bumper crop of new tools and technologies designed to help even the most technically challenged journalist turn data into a piece of visual storytelling‚Äîmany of them free.
+There are times when data can tell a story better than words or photos, and this is why terms like "news application" and "data visualization" have attained buzzword status in so many newsrooms of late. Also fueling interest is the bumper crop of new tools and technologies designed to help even the most technically challenged journalist turn data into a piece of visual storytelling‚Äö√Ñ√Æmany of them free.
 
 Tools like Google Fusion Tables, Many Eyes, Tableau, Dipity and others make it easier than ever to create maps, charts, graphs or even full-blown data applications that heretofore were the domain of specialists. But with the barrier to entry now barely a speed bump, the question facing journalists now less about whether you can turn your dataset into a visualization, but whether you should.
 
-http://www.niemanlab.org/2011/10/word-clouds-considered-harmful/[Bad data visualization] is worse in many respects than none at all, but journalists have few resources (until now) available to learn the right way to approach visual storytelling.
+Bad data visualization is worse in many respects than none at all, but journalists have few resources (until now) available to learn the right way to approach visual storytelling.
 
 Types of stories visualisations can tell
 
@@ -2518,64 +2615,64 @@
 
 Provide Context
 
-http://www.nytimes.com/interactive/2011/03/13/world/asia/satellite-photos-japan-before-and-after-tsunami.html[Satellite Photos - Japan Before and After Tsunami]
+Satellite Photos - Japan Before and After Tsunami
 Compare satellite images of areas of Japan before and after the disaster.
-http://www.nytimes.com/interactive/2011/04/02/world/asia/assessing-the-radiation-danger.html[Assessing the Radiation Danger, Near and Far]
+Assessing the Radiation Danger, Near and Far
 Assessments of the radiation from the Fukushima Daiichi nuclear power plant by the Japanese authorities, the International Atomic Energy Agency and others.
-http://www.nytimes.com/packages/flash/newsgraphics/2011/0311-japan-earthquake-map/?view=daiichi[Map of Radiation Readings Near Fukushima Daiichi]
-http://www.nytimes.com/interactive/2009/11/06/business/economy/unemployment-lines.html[The Jobless Rate for People Like You - Interactive Graphic - NYTimes.com]
+Map of Radiation Readings Near Fukushima Daiichi
+The Jobless Rate for People Like You - Interactive Graphic - NYTimes.com
 Not all groups have felt the recession equally.
-http://www.nytimes.com/packages/html/newsgraphics/2011/0119-budget/index.html[Obama's 2012 Budget Proposal: How It's Spent - NYTimes.com]
+Obama's 2012 Budget Proposal: How It's Spent - NYTimes.com
 Explore every nook and cranny of President Obama's budget proposal.
 
 Reveal Patterns
 
-http://www.nytimes.com/interactive/2009/03/10/us/20090310-immigration-explorer.html[Interactive Map Showing Immigration Data Since 1880]
+Interactive Map Showing Immigration Data Since 1880
 See how foreign-born groups settled in your area and across the United States from 1880 to 2000.
-http://www.nytimes.com/packages/html/newsgraphics/pages/hp/2008/2008-11-05-1300.html[The Shifts in the Map - How Obama Won]
+The Shifts in the Map - How Obama Won
 Find breaking news, multimedia, reviews & opinion on Washington, business, sports, movies, travel, books, jobs, education, real estate, cars & more.
-http://www.nytimes.com/interactive/2009/06/23/us/Geothermal.html?ref=geothermalpower[The Danger of Digging Deeper]
-A project financed by the Energy Department aims to capture geothermal energy from hot bedrock ‚Äî a process that can cause earthquakes.
+The Danger of Digging Deeper
+A project financed by the Energy Department aims to capture geothermal energy from hot bedrock ‚Äö√Ñ√Æ a process that can cause earthquakes.
 
 Describe Processes
 
-http://www.nytimes.com/interactive/2011/03/12/world/asia/what-happens-in-a-nuclear-meltdown.html[What Happens in a Nuclear Meltdown]
+What Happens in a Nuclear Meltdown
 The operating reactors at Fukushima Daiichi power station automatically shut down during the earthquake. But after cooling failures, two of them went into partial meltdown.
-http://www.nytimes.com/interactive/2009/08/01/arts/dance/20090803-merce-graphic.html[Dissecting a Dance]
+Dissecting a Dance
 Alastair Macaulay, The Times's chief dance critic, analyzes Merce Cunningham's "Biped."
 Explain the Geography
-http://www.nytimes.com/packages/flash/newsgraphics/2011/0311-japan-earthquake-map/[Map of the Damage From the Japanese Earthquake]
-http://www.nytimes.com/interactive/2010/05/01/us/20100501-oil-spill-tracker.html[Map and Estimates of the Oil Spill in the Gulf of Mexico - Interactive Map - NYTimes.com]
+Map of the Damage From the Japanese Earthquake
+Map and Estimates of the Oil Spill in the Gulf of Mexico - Interactive Map - NYTimes.com
 The spreading slick, day by day, and a chart of how much oil has been spilled.
 
 Report and Research
 
-http://www.nytimes.com/2007/04/17/us/20070417_SHOOTING_GRAPHIC.html[Virginia Tech Shooting - New York Times]
+Virginia Tech Shooting - New York Times
 A recounting of the events on the day of the deadliest shooting rampage in American history. From official and survivor accounts of the shooting at Virginia Tech.
-http://www.nytimes.com/interactive/2011/03/16/world/asia/japan-nuclear-evaculation-zone.html[Map of Evacuation Zones Around Japan Nuclear Plant - Interactive Feature - NYTimes.com]
+Map of Evacuation Zones Around Japan Nuclear Plant - Interactive Feature - NYTimes.com
 Map of the evacuations zones recommended by the American Embassy in Tokyo and Japanese officials.
 What's the Story?
-http://www.nytimes.com/interactive/2010/06/29/magazine/rivera-pitches.html[How Mariano Rivera Dominates Hitters]
+How Mariano Rivera Dominates Hitters
 The closer has confounded hitters with mostly one pitch: his signature cutter.
-http://elections.nytimes.com/2010/results/house[House Map - Election Results 2010]
-http://elections.nytimes.com/2010/results/house/big-board[House Big Board - Election Results 2010]
-http://projects.nytimes.com/toxic-waters/contaminants/ia/johnson/ia5225079-iowa-city-water-department[Iowa City Water Department Water System - Interactive Database - The New York Times]
+House Map - Election Results 2010
+House Big Board - Election Results 2010
+Iowa City Water Department Water System - Interactive Database - The New York Times
 
 Sketch with Data
 
-http://www.nytimes.com/interactive/2010/01/10/nyregion/20100110-netflix-map.html[A Peek Into Netflix Queues - Interactive Graphic - NYTimes.com]
+A Peek Into Netflix Queues - Interactive Graphic - NYTimes.com
 Story+Data > Data
-http://elections.nytimes.com/2010/results/house/preview[Preview of Key House Races - Election Results 2010]
-http://www.nytimes.com/interactive/2009/01/17/washington/20090117_ADDRESSES.html[Inaugural Words - 1789 to the Present]
-http://www.nytimes.com/interactive/2009/07/02/business/economy/20090705-cycles-graphic.html[Turning a Corner?]
-http://www.nytimes.com/interactive/2007/09/22/business/20070923_NURSING_GRAPHIC.html[Layers of Ownership]
+Preview of Key House Races - Election Results 2010
+Inaugural Words - 1789 to the Present
+Turning a Corner?
+Layers of Ownership
 The Information Is What's Important
-http://www.accuweather.com/en/us/new-york-ny/10017/daily-weather-forecast/3712_pc[New York, NY 10017 Today's Weather Forecast - AccuWeather.com]
-http://weather.ericson.net/weather/forecast/New-York-NY[weather.ericson.net: New York, NY Weather]
-http://www.nytimes.com/interactive/2011/03/13/world/asia/satellite-photos-japan-before-and-after-tsunami.html[Satellite Photos - Japan Before and After Tsunami]
+New York, NY 10017 Today's Weather Forecast - AccuWeather.com
+weather.ericson.net: New York, NY Weather
+Satellite Photos - Japan Before and After Tsunami
 Compare satellite images of areas of Japan before and after the disaster.
-http://www.nytimes.com/packages/flash/newsgraphics/2011/0311-japan-earthquake-map/?view=daiichi[Map of Radiation Readings Near Fukushima Daiichi]
-http://www.nytimes.com/interactive/2010/02/26/sports/olympics/20100226-olysymphony.html[Fractions of a Second: An Olympic Musical - Interactive Graphic - NYTimes.com]
+Map of Radiation Readings Near Fukushima Daiichi
+Fractions of a Second: An Olympic Musical - Interactive Graphic - NYTimes.com
 
 
 === 4.3.x Visualization vocabulary (Kate hudson) ===
@@ -2593,8 +2690,8 @@
 
 
 Timelines (via Claire Miller)
-http://www.propublica.org/nerds/item/timelinesetter-a-new-way-to-display-timelines-on-the-web[TimelineSetter: A New Way to Display Timelines on the Web]
-http://www.tiki-toki.com/[Tiki Toki]
+TimelineSetter: A New Way to Display Timelines on the Web
+Tiki Toki
 
 (Lulu: I'd add in:)
 Sound and Motion
@@ -2619,7 +2716,7 @@
 Your audience must immediately (or at least clearly) intuit the information you're presenting from the visual markers. Choosing the appropriate overlays is essential. Objects can be plotted and made clickable for more information, the size of markers can be used to indicate quantity or severity (with or without a legend), overlays or polygons can represent zones.
 
 There are many tools that simplify the creation of maps from digital data. 
-http://code.google.com/apis/maps/index.html[http://code.google.com/apis/maps/index.html]
+http://code.google.com/apis/maps/index.html
 
 This classic map shows the advance and retreat of Napolean's army in Russia using width to indicate army size, color to represent direction and a sharp aesthetic to show the severity of the event. http://www.edwardtufte.com/tufte/posters
 
@@ -2636,10 +2733,10 @@
 (Lulu) Motion Graphics is one to add to taxomony:
 Motion graphics
 With a tight script, well timed animations and clear explanations motion graphics serve to bring complex numbers or ideas to life, guiding your audience through the story.
-Example 1: http://www.nytimes.com/interactive/2010/06/29/magazine/rivera-pitches.html[How Mariano Rivera dominates hitters]
+Example 1: How Mariano Rivera dominates hitters
 NYT's Joe Ward, sports graphics editor, is interviewed here on the making of it, a case-study of a piece of data journalism that might have been an interactive but resulted in a narrated piece of animated graphic video:
-Example 2: http://www.ted.com/talks/lang/en/hans_rosling_on_global_population_growth.html[The Hans Rosling video] is another good example of this type of presentation.
-Example 3: Whether or not you agree with their methodology I think the Economist's http://www.economist.com/blogs/multimedia/2011/02/unrest_arab_world[Shoe-throwers' index] is a good example of using video to tell a numbers-based story. You wouldn't, or shouldn't, present this graphic as a static image. There's far too much going on. But having built up to it step by step you're left with an understanding of how and why they got to this index.
+Example 2: The Hans Rosling video is another good example of this type of presentation.
+Example 3: Whether or not you agree with their methodology I think the Economist's Shoe-throwers' index is a good example of using video to tell a numbers-based story. You wouldn't, or shouldn't, present this graphic as a static image. There's far too much going on. But having built up to it step by step you're left with an understanding of how and why they got to this index.
 
 Custom Graphics and Interactives
 If you have an interesting story and the requisite production skills or resources, data visualization can become a deeply artistic endeavor. As a journalist, it is important to keep an editorial eye on custom graphics and interactives to ensure they stay on story, as there is a tendency with strong creative designers or coders to move toward showcases for aesthetics or functionality. See the case studies and appendix for more on custom visualizations.
@@ -2647,14 +2744,14 @@
 (Lulu) Agrees...
 Don't be tempted to throw an uber-complex interactive interface at the audience just because you've spent days developing it. If it has led you to some good stories then it has been worthwhile, but a simpler visualisation that tells a specific story might be more appropriate for the final presentation.
 
-Making choices about which charts to use, great overview here: http://i.imgur.com/YjWta.jpg[http://i.imgur.com/YjWta.jpg]
+Making choices about which charts to use, great overview here: http://i.imgur.com/YjWta.jpg
 
 Interaction
 (Lulu)
 Depending on what you want your audience to take away, different types of interaction can be used, as illustrated by these examples:
-- Story-telling: http://www.nytimes.com/interactive/2009/07/02/business/economy/20090705-cycles-graphic.html[NYT: Turning a Corner (Economic Cycles)]
-- No story, free data exploration by user: http://www.neighbourhood.statistics.gov.uk/HTMLDocs/dvc3/projections.html[ONS: Population Pyramids]
-- Learn by having a go: BERG/BBC: http://howbigreally.com/[How big really?]
+- Story-telling: NYT: Turning a Corner (Economic Cycles)
+- No story, free data exploration by user: ONS: Population Pyramids
+- Learn by having a go: BERG/BBC: How big really?
 
 When you think you're nearly there, try out your visualisation on a handful of other people. Observe them using it, exploring it. It becomes very clear very quickly what users do and don't 'get'. If your users don't realise there's another screen to progress to, all your hard work will have been wasted. Go back and adjust your work to address the obstacles that you saw users encounter.
 
@@ -2670,14 +2767,14 @@
 
 === Guardian Riot map (Farida) ===
 
-During the summer of 2011 the UK was hit by a wave of riots (full government report here todo: find link). Politicians suggested that these actions were categorically not linked to poverty and those that did the looting were simply criminals. The Guardian newspaper played a crucial role in using data driven journalism and a range of data visualizations in telling this story, allowing for better understanding who was doing the looting and why. By using simple maps (Google Fusion Tables) they showed the location of http://www.guardian.co.uk/news/datablog/interactive/2011/aug/09/uk-riots-incident-map[confirmed riots spots] and through mashing up deprivation data with where the riots took place started debunking the main political narrative that there was no link to http://www.guardian.co.uk/news/datablog/2011/aug/16/riots-poverty-map-suspects[poverty]. Both these examples use off the shelf visualization tools and in the second example combine location data with another data set, to start making other links. A final example worth mentioning here is the visualization the paper built around the use of social media. Again politicians had started to suggest that social media use might have to be curtailed during such troubles in future, but offering little concrete evidence that social media, Twitter in this case, played a role in encouraging people to riot. A visualization of riot related http://www.guardian.co.uk/uk/2011/aug/24/twitter-study-post-riot-plans#_[hashtags] used during this period, highlighted that Twitter was mainly used to respond to the riots rather than to organize people to go looting, with #riotcleanup showing the most significant spike during the riot period.
+During the summer of 2011 the UK was hit by a wave of riots (full government report here todo: find link). Politicians suggested that these actions were categorically not linked to poverty and those that did the looting were simply criminals. The Guardian newspaper played a crucial role in using data driven journalism and a range of data visualizations in telling this story, allowing for better understanding who was doing the looting and why. By using simple maps (Google Fusion Tables) they showed the location of confirmed riots spots and through mashing up deprivation data with where the riots took place started debunking the main political narrative that there was no link to poverty. Both these examples use off the shelf visualization tools and in the second example combine location data with another data set, to start making other links. A final example worth mentioning here is the visualization the paper built around the use of social media. Again politicians had started to suggest that social media use might have to be curtailed during such troubles in future, but offering little concrete evidence that social media, Twitter in this case, played a role in encouraging people to riot. A visualization of riot related hashtags used during this period, highlighted that Twitter was mainly used to respond to the riots rather than to organize people to go looting, with #riotcleanup showing the most significant spike during the riot period.
 
 These three examples show three different types of data visualization used very effectively.
 
-¬∑ 	The first one a simple map highlighting where riots took place using Google Fusion Tables.
-¬∑ 	The second map linked to an additional data set offering a further reading of events and generating more story leads.
-¬∑ 	Finally by looking at twitter data, visualizing the hashtags showed that significant traffic was concerned with cleaning up after the riots rather than inciting people to riot (if you were to do this yourself, you would need to think about where you would get this data).
-¬∑ 	Most of these visualizations used off the shelf tools to great effect for telling important stories (quickly).
+¬¨‚àë 	The first one a simple map highlighting where riots took place using Google Fusion Tables.
+¬¨‚àë 	The second map linked to an additional data set offering a further reading of events and generating more story leads.
+¬¨‚àë 	Finally by looking at twitter data, visualizing the hashtags showed that significant traffic was concerned with cleaning up after the riots rather than inciting people to riot (if you were to do this yourself, you would need to think about where you would get this data).
+¬¨‚àë 	Most of these visualizations used off the shelf tools to great effect for telling important stories (quickly).
 
 Example from Finland (Farida has contacted Petri Kola, with the request to quickly explain the story and send me the link to the vis they used) - where the first time the main Finish paper ran a DDJ story + vis was inspired by the work of the Guardian. The story highlighted election data and who the main sponsors to the main parties were. The vis was simple, but cause a buzz.
 
@@ -2701,7 +2798,7 @@
 
 
 (bad example) NYTimes election 2004 (Aron - needs input)
-http://www.nytimes.com/packages/html/politics/2004_ELECTIONRESULTS_GRAPHIC/[http://www.nytimes.com/packages/html/politics/2004_ELECTIONRESULTS_GRAPHIC/]
+http://www.nytimes.com/packages/html/politics/2004_ELECTIONRESULTS_GRAPHIC/
 What is the important thing?
 Location is shown first but the location of the state isn't important.
 Burrying the lead
@@ -2764,7 +2861,7 @@
 
 **1. When the visualization is the story:**
  
-Translation: Here is crime happening ‚Äì hour by hour
+Translation: Here is crime happening ‚Äö√Ñ√¨ hour by hour
 Link: http://www.vgtv.no/#!id=46131
 
 In this animated heatmap combined with a simple bar chart you can follow the development of crime downtown Oslo, Norway, hour by hour, during the weekend for several months. In the same animated heatmap, you can see the number of police officers working at the same time. When crime really is happening, the number of police officers is at the bottom.
@@ -2776,7 +2873,7 @@
 
 Translation: The network of the movie people
 Skuespillere = actors/actresses
-Regiss√∏rer = directors
+Regiss‚àö‚àèrer = directors
 In this Social Network Analysis, VG downloaded all relations in all Norwegian movies during more than ten years. Who were playing with whom, and which actors and actresses were playing with the different directors? A database with all relevant content was exported to UCINET, a program for social network analysis, and then it was quite easy to see who were connected with whom with different strength of ties. 
 . 
 Translation: Rich children are playing together
@@ -2832,10 +2929,10 @@
  
 Translation:
 Poeng landet har gitt = points given.
-Poeng landet f√•r = points received.
-Differanse mellom gir og f√•r = the difference between what you give and what you get.
-Poeng mottatt √•r for √•r = points received each year.
-MGP vinner √•r for √•r = the winner each year.
+Poeng landet f‚àö‚Ä¢r = points received.
+Differanse mellom gir og f‚àö‚Ä¢r = the difference between what you give and what you get.
+Poeng mottatt ‚àö‚Ä¢r for ‚àö‚Ä¢r = points received each year.
+MGP vinner ‚àö‚Ä¢r for ‚àö‚Ä¢r = the winner each year.
 LILIANA:
 Link DEAD AT THE MOMENT. WE COULD REACTIVATE IT IF YOU WANT TO.
 
@@ -2874,45 +2971,45 @@
 Toolkits and tutorials
 
 
-http://www.mirkolorenz.com/[http://www.mirkolorenz.com/]
+http://www.mirkolorenz.com/
 
 Tools as listed by NYT's Matt Ericson here: http://www.ericson.net/content/2011/04/international-journalism-festival-links/
-http://www.google.com/fusiontables/embedviz?viz=MAP&q=select+col0,+col1,+col2,+col3,+col4,+col5,+col6,+col7,+col8,+col9,+col10,+col11,+col12,+col13,+col14,+col15,+col16,+col17,+col18,+col19,+col20,+col21,+col22+from+628653+&h=false&lat=51.502758957640296&lng=-0.00823974609375&z=12&t=1&l=col0[Google Fusion Tables Example from The Guardian]
-http://www.tableausoftware.com/public/gallery/ken-griffey-viz[Tableau Public: Power Hitters]
-http://projects.nytimes.com/new-york-schools-test-scores/counties/kings/districts/new-york-city-district-15/schools/p-s-24[Google Charts from New York State Test Scores - The New York Times]
-http://www.nytimes.com/interactive/sports/soccer/2010-world-cup-team-rankings.html[HTML, CSS and Javascript: 2010 World Cup Rankings]
-http://jquery.com/[jQuery: The Write Less, Do More, JavaScript Library]
-http://jqueryui.com/[jQuery UI - Home]
-http://mbostock.github.com/protovis/[Protovis]
-http://raphaeljs.com/[Rapha√´l‚ÄîJavaScript Library]
-http://www.r-project.org/[The R Project for Statistical Computing]
-http://processing.org/[Processing.org]
-
-Google's tools http://code.google.com/apis/ajax/playground/[http://code.google.com/apis/ajax/playground/]
-http://support.google.com/mapmaker/bin/static.py?hl=en&guide=30028&page=guide.cs[http://www.google.com/support/mapmaker/bin/static.py?page=guide.cs&guide=30028]
-Image plot (Lev Manovich - Software Studies; explore patterns in large image collections) http://lab.softwarestudies.com/p/software.html[http://lab.softwarestudies.com/p/software.html]
+Google Fusion Tables Example from The Guardian
+Tableau Public: Power Hitters
+Google Charts from New York State Test Scores - The New York Times
+HTML, CSS and Javascript: 2010 World Cup Rankings
+jQuery: The Write Less, Do More, JavaScript Library
+jQuery UI - Home
+Protovis
+Rapha‚àö¬¥l‚Äö√Ñ√ÆJavaScript Library
+The R Project for Statistical Computing
+Processing.org
+
+Google's tools http://code.google.com/apis/ajax/playground/
+http://www.google.com/support/mapmaker/bin/static.py?page=guide.cs&guide=30028
+Image plot (Lev Manovich - Software Studies; explore patterns in large image collections) http://lab.softwarestudies.com/p/software.html
 A quick exercise for aspiring data journalists (from Paul Bradshaw):
 http://onlinejournalismblog.com/2011/10/31/a-quick-exercise-for-aspiring-data-journalists/
 Visualizing Toronto's water usage: a tutorial
-http://datadrivenjournalism.net/resources/visualizing_torontos_water_usage_a_tutorial[http://datadrivenjournalism.net/resources/visualizing_torontos_water_usage_a_tutorial]
+http://datadrivenjournalism.net/resources/visualizing_torontos_water_usage_a_tutorial
 Data visualizations for non-programmers (via Knight Digital Media Center):
-http://multimedia.journalism.berkeley.edu/tutorials/intro-dataviz/[http://multimedia.journalism.berkeley.edu/tutorials/intro-dataviz/]
-Visualizing Data (Andy Kirk): http://www.visualisingdata.com/index.php/resources/[http://www.visualisingdata.com/index.php/resources/]
+http://multimedia.journalism.berkeley.edu/tutorials/intro-dataviz/
+Visualizing Data (Andy Kirk): http://www.visualisingdata.com/index.php/resources/
 How We Visualized 23 Years of Geo Bee Contents (via Datavisualization.ch):
-http://datavisualization.ch/opinions/how-we-visualized-23-years-of-geo-bee-contests/[http://datavisualization.ch/opinions/how-we-visualized-23-years-of-geo-bee-contests/]
+http://datavisualization.ch/opinions/how-we-visualized-23-years-of-geo-bee-contests/
 
 Scattered Examples
-http://www.guardian.co.uk/news/datablog/2011/oct/17/data-visualisation-visualization[http://www.guardian.co.uk/news/datablog/2011/oct/17/data-visualisation-visualization]
-http://upload.wikimedia.org/wikipedia/commons/2/27/Snow-cholera-map-1.jpg[http://upload.wikimedia.org/wikipedia/commons/2/27/Snow-cholera-map-1.jpg]
-http://www.guardian.co.uk/news/datablog/2010/aug/13/florence-nightingale-graphics[http://www.guardian.co.uk/news/datablog/2010/aug/13/florence-nightingale-graphics]
+http://www.guardian.co.uk/news/datablog/2011/oct/17/data-visualisation-visualization
+http://upload.wikimedia.org/wikipedia/commons/2/27/Snow-cholera-map-1.jpg
+http://www.guardian.co.uk/news/datablog/2010/aug/13/florence-nightingale-graphics
 
 Articles and personalities
-http://lilt.ilstu.edu/gmklass/pos138/datadisplay/sections/goodcharts.htm[http://lilt.ilstu.edu/gmklass/pos138/datadisplay/sections/goodcharts.htm]
-http://www.ericson.net/content/2011/10/when-maps-shouldnt-be-maps/[http://www.ericson.net/content/2011/10/when-maps-shouldnt-be-maps/]
+http://lilt.ilstu.edu/gmklass/pos138/datadisplay/sections/goodcharts.htm
+http://www.ericson.net/content/2011/10/when-maps-shouldnt-be-maps/
 
 Infographic and Information Design Conferences
-http://www.thedesignofunderstanding.com/[The Design of Understanding: January 2012, London]
-http://www.malofiej20.com/[Malofiej: March 2012, Pamplona, Spain]
+The Design of Understanding: January 2012, London
+Malofiej: March 2012, Pamplona, Spain
 Information Design Conference: April 2012, London
 
 Books:
@@ -2921,7 +3018,7 @@
 The Online Journalism Handbook: Skills to survive and thrive in the digital age (Liisa Rohumaa, Bournemouth Media School | Paul Bradshaw, Birmingham City University) - todo: to go in general section?
 
 
-http://catalogue.pearsoned.co.uk/educator/product/The-Online-Journalism-Handbook-Skills-to-survive-and-thrive-in-the-digital-age/9781405873406.page[http://catalogue.pearsoned.co.uk/educator/product/The-Online-Journalism-Handbook-Skills-to-survive-and-thrive-in-the-digital-age/9781405873406.page]
+http://catalogue.pearsoned.co.uk/educator/product/The-Online-Journalism-Handbook-Skills-to-survive-and-thrive-in-the-digital-age/9781405873406.page
 
 
 
@@ -2929,29 +3026,29 @@
 
 Exploring survey data with IBM Many Eyes
 
-http://www.opendatacookbook.net/wiki/recipe/exploring_survey_data_with_many_eyes[http://www.opendatacookbook.net/wiki/recipe/exploring_survey_data_with_many_eyes]
+http://www.opendatacookbook.net/wiki/recipe/exploring_survey_data_with_many_eyes
 
 Mapping:
 
-http://mapalist.com/[http://mapalist.com/]
-http://geocommons.com/[http://geocommons.com/]
-Costs money but recommended - http://www.esri.com/software/arcgis/index.html[ArcGIS http://www.esri.com/software/arcgis/index.html]
+http://mapalist.com/
+http://geocommons.com/
+Costs money but recommended - ArcGIS http://www.esri.com/software/arcgis/index.html
 
 (Via Claire Miller)
 
-http://stamen.com/opensource[Stamen Design]
-Try this http://wiki.openstreetmap.org/wiki/OpenLayers_Simple_Example[OpenLayers Simple Example]. A good sample is http://haiti.ushahidi.com/[Ushahidi's Haiti map].
-There are other JavaScript libraries for overlaying information on maps, such as http://polymaps.org/[Polymaps]. And there are a number of other mapping platforms, such as Google Maps, which offers numerous http://code.google.com/apis/maps/index.html[mapping APIs]; http://developer.yahoo.com/maps/[Yahoo Maps Web Services], with its own APIs; the http://www.microsoft.com/maps/developers/web.aspx[Bing Maps] platform and APIs; and http://geocommons.com/[GeoCommons].
-http://leaflet.cloudmade.com/[Leaflet]
-http://jebruner.com/2011/11/how-to-build-an-interactive-map-with-open-source-tools/[How To Build an Interactive Map with Open-Source Tools]
-http://blog.apps.chicagotribune.com/2011/03/08/making-maps-1/[Making maps, part 1: Less interactivity]
+Stamen Design
+Try this OpenLayers Simple Example. A good sample is Ushahidi's Haiti map.
+There are other JavaScript libraries for overlaying information on maps, such as Polymaps. And there are a number of other mapping platforms, such as Google Maps, which offers numerous mapping APIs; Yahoo Maps Web Services, with its own APIs; the Bing Maps platform and APIs; and GeoCommons.
+Leaflet
+How To Build an Interactive Map with Open-Source Tools
+Making maps, part 1: Less interactivity
 
 Tableau (via Claire Miller)
-http://theinformationlab.co.uk/blog/2011/9/23/blue-things-and-green-things.html[Blue things and Green things]
-http://theinformationlab.co.uk/blog/2011/12/7/making-table-calculations-work-in-tableau.html[Making Table Calculations work in Tableau]
-http://theinformationlab.co.uk/blog/2011/12/12/show-me-when-less-is-definitely-more.html[Show Me! ‚Äì When less is definitely more]
-http://vimeo.com/19919944[Preprocess shapefile for Tableau Tutorial Video]
-http://www.datarevelations.com/hey-your-tableau-public-viz-is-ugly-and-confusing.html[Hey! Your Tableau Public Viz is Ugly *and* Confusing]
+Blue things and Green things
+Making Table Calculations work in Tableau
+Show Me! ‚Äö√Ñ√¨ When less is definitely more
+Preprocess shapefile for Tableau Tutorial Video
+Hey! Your Tableau Public Viz is Ugly *and* Confusing
 
 
 
@@ -2967,7 +3064,7 @@
 Length: 2-3 pages (including examples)
 
 
-=== Data-driven apps case studies ‚Äì Internews in Kenya by Mark Irungu (Internews Network) ===
+=== Data-driven apps case studies ‚Äö√Ñ√¨ Internews in Kenya by Mark Irungu (Internews Network) ===
 
 ////
 
@@ -2989,7 +3086,7 @@
 
 The APP
 
-The power of data cannot be under estimated. It is time that newsrooms and journalists moved away from the "he said, she said" reporting. Numbers don't lie, they can help journalists produce in-depth features, and explore untold stories and trends that are not immediately known or visible to the general public.. Unfortunately, journalists in Kenya have not made good use of the opened data. I work at Internews in Kenya ‚Äì a media development organisation that trains and supports journalists to be better storytellers, In our journalism workshops we have designed a number of courses to help journalists use numbers and data better for their storytelling. This is important as it helps journalists to enrich their enquiry and stories 
+The power of data cannot be under estimated. It is time that newsrooms and journalists moved away from the "he said, she said" reporting. Numbers don't lie, they can help journalists produce in-depth features, and explore untold stories and trends that are not immediately known or visible to the general public.. Unfortunately, journalists in Kenya have not made good use of the opened data. I work at Internews in Kenya ‚Äö√Ñ√¨ a media development organisation that trains and supports journalists to be better storytellers, In our journalism workshops we have designed a number of courses to help journalists use numbers and data better for their storytelling. This is important as it helps journalists to enrich their enquiry and stories 
 
 It is with this realization that the idea of developing an app to query KODI was born. There is need for a a solution that would help journalists clean up raw data in the back end and help journalist to identify emerging stories and trends.That app should also help in presenting the content in visually appealing ways. 
 
@@ -3032,7 +3129,7 @@
 
 3.	Citizen reporting- these are apps whose main source of data is the citizen. These apps provide an interface for citizen-journalism and then visualize the data graphically or on a map. E.g.: Ushahidi, crowdmap, swiftriver
 
-4.	DATA apps ‚Äì These are apps that query DATA sets from governments, organizations, civil society etc. These Apps may have their own storage engine that is updated regularly from the main data source e.g. World Bank finances, Kenya open data. Examples of such applications: CDF monitor (Kenya) Internews Open DATA app(Kenya)
+4.	DATA apps ‚Äö√Ñ√¨ These are apps that query DATA sets from governments, organizations, civil society etc. These Apps may have their own storage engine that is updated regularly from the main data source e.g. World Bank finances, Kenya open data. Examples of such applications: CDF monitor (Kenya) Internews Open DATA app(Kenya)
 
 
 
@@ -3109,7 +3206,7 @@
 
 === Public Data goes Social by Full Name Here ===
 
-Data is invaluable. To the uninformed person where information asymmetry thrives, access to data illuminates the path to facts and provokes emotions that trigger results. Nevertheless, poor handling of data puts valuable facts in an opaque structure that communicates nothing. Data could be in a maze of thick document riddled with complex terms or iterations of figures that doesn’t connect the user.  Not being able to promote discussion nor give provide contextual understanding, data may could be worthless. 
+Data is invaluable. To the uninformed person where information asymmetry thrives, access to data illuminates the path to facts and provokes emotions that trigger results. Nevertheless, poor handling of data puts valuable facts in an opaque structure that communicates nothing. Data could be in a maze of thick document riddled with complex terms or iterations of figures that doesn't connect the user.  Not being able to promote discussion nor give provide contextual understanding, data may could be worthless. 
 
 Nigeria returned to democracy in 1999 after lengthy years of military rule. Data under the barrel of the gun was an exclusive preserve of rulers as probing the facts behind data is taken as an affront to authority and strive to question the stained reputation of the junta. Civil servants were bound by the Official Secrets Act not to share government information hereby putting the citizens in the dark. Even after thirteen years of return to democracy, there is clearly a gap in accessing public data with some government officials still stricken with military era hangover. Data especially in terms of public expenditure communicates little to the larger sections of public who are not versed in financial accounting nor have requisite understanding to evaluate the complex arithmetic. 
 
@@ -3128,7 +3225,7 @@
 
 *Engaging the Citizen*
 
-Across every society lies a literacy span and engaging every component is highly critical to the societal growth and stability. There is always a storyboard in every life that volumes of data can be matched with. People constantly want to be more informed especially concerning issues that they find difficult to understand. Engaging citizens is to take critical analysis of the target users at a time and itemize the possible profiles. A look at user profile demands a thorough analysis of their empathy, attention and insight towards the data available to them. What does the Nigerian citizen care about? Where is the information gap? How quickly can we reach out to them and place data in the storyboard of their lives? A critical understanding of the user’s psychology and the perceived response to the data is the first needed level of analysis. BudgIT’s immediate reach is to the average literate Nigerian connected to online forums and social media. Most online users amidst the array of interests in gaming, reading and sharing social connections within a limited timeframe will definitely need data in a brief and concise manner. After a snapshot of data  either as a tweet or infographics, there’s an opportunity to build linked data on other platforms where the big picture can be set and interaction can be enhanced.  
+Across every society lies a literacy span and engaging every component is highly critical to the societal growth and stability. There is always a storyboard in every life that volumes of data can be matched with. People constantly want to be more informed especially concerning issues that they find difficult to understand. Engaging citizens is to take critical analysis of the target users at a time and itemize the possible profiles. A look at user profile demands a thorough analysis of their empathy, attention and insight towards the data available to them. What does the Nigerian citizen care about? Where is the information gap? How quickly can we reach out to them and place data in the storyboard of their lives? A critical understanding of the user's psychology and the perceived response to the data is the first needed level of analysis. BudgIT's immediate reach is to the average literate Nigerian connected to online forums and social media. Most online users amidst the array of interests in gaming, reading and sharing social connections within a limited timeframe will definitely need data in a brief and concise manner. After a snapshot of data  either as a tweet or infographics, there's an opportunity to build linked data on other platforms where the big picture can be set and interaction can be enhanced.  
 
 An important angle of visualization to us is understanding the data appreciation level of the users. Complex diagrams, superb infographics and aesthetic interactive applications might not convey the exact meaning to user based on his/her previous approach to data. Data vizualization needs to take into consideration how users can easily grasp the vizualized data and subject it to personal interpretation. A good visualization transfers knowledge and mostly important brings forth a story the user can easily connect with. 
 
@@ -3136,15 +3233,15 @@
 
 *Stimulating discussion around Trends*: In engaging with users on public data, BudgIT keeps track of online and offline discussions and seeks to provide data to enliven the interactions. A glaring example was the fuel strikes in January 2012 where there was a constant agitation among the protesters on the need to reduce the size of governance. BudgIT tracking the discussion via social media in 36 active hours quickly built an app that allows citizens to cut the Nigerian budget. The huge response with over 3,000 users who interacted with the budget using the app refined our  engagement model. We keep looking for trends in the polity and matching it with relevant data quickly rendered into tweets or infographic display that quickly  extends our influence. 
 
-*Constructive feedback mechanism and Balanced outlook*: Data speaks volumes and individuals subject it to personal interpretations. In the engagement with users, feedback is enabled through discussion boards or retweets. Most users throw up discussions that tend to ask about stories behind the data and seeking opinions of BudgIT. Its of utmost priority to ensure that opinions only explain the facts  behind the data and does not conform to individual disposition to the subject matter. It’s most necessary to build up feedback channels and engage the users creatively to ensure the community built around the data is sustained. 
+*Constructive feedback mechanism and Balanced outlook*: Data speaks volumes and individuals subject it to personal interpretations. In the engagement with users, feedback is enabled through discussion boards or retweets. Most users throw up discussions that tend to ask about stories behind the data and seeking opinions of BudgIT. Its of utmost priority to ensure that opinions only explain the facts  behind the data and does not conform to individual disposition to the subject matter. It's most necessary to build up feedback channels and engage the users creatively to ensure the community built around the data is sustained. 
 
-*Localize Outlook of Data*: For a dataset targeted at a particular group, BudgIT is building competency to localize its content and promote a channel of discussion that connects to the users. This involves taking a cultural outlook at the icons, symbols, objects and language to ensure that engagement concerning the budget flows seamlessly. This phase of engagement is with the grassroots who  mostly don’t have access to Internet but only possess SMS-based mobile phones. 
+*Localize Outlook of Data*: For a dataset targeted at a particular group, BudgIT is building competency to localize its content and promote a channel of discussion that connects to the users. This involves taking a cultural outlook at the icons, symbols, objects and language to ensure that engagement concerning the budget flows seamlessly. This phase of engagement is with the grassroots who  mostly don't have access to Internet but only possess SMS-based mobile phones. 
 
 After making the public expenditure data  available in an easy-to-read format as shown on our portal yourbudgit.com, we reach out to the citizens through the civil society organizations to ensure that citizens monitor capital projects in the budget. We also plan to develop a participatory framework where citizens and government institutions can meet in town halls to define key items in the budget that needs to be prioritized. Once we get citizens to be aware of capital projects in the budget and connect them with civil societies where BudgIT is not located, citizens can track report projects and report status. Ensuring that citizens of any literacy span are armed with data and possess a clear path to demand action, BudgIT is crossing the rubicon from open data to open action. 
 
 
 
-=== Citizen engagement with data journalism by C√©sar Viana (Estacio de Sa University) ===
+=== Citizen engagement with data journalism by César Viana (Estacio de Sa University) ===
 
 ////
 
@@ -3160,17 +3257,17 @@
 The multidisciplinarity common to the variety of editorial sections of journalism has always collaborated with the interrelationship among different domains. When drawing or implementing strategies and plans consider leveraging opportunities and providing the knowledge and the skills to warrant inclusiveness, diversity and innovation in our societies. Make sure your project contributes to empower people through technology and/or media literacy.
 If only by consuming or sharing news, the public is involved in modeling of information systems. Therefore, it is necessary to provide the best resources for collaboration and joint construction of stories. There is a growing emergence of examples that stand out in this foray:
 
-http://www.propublica.org/nerds/item/introducing-docdiver[DocDiver] is an application to stimulate readers on working beside ProPublica investigative reporters' team to identify and share key bits of information in documents.
+DocDiver is an application to stimulate readers on working beside ProPublica investigative reporters' team to identify and share key bits of information in documents.
 
-http://www.documentcloud.org/home[DocumentCloud] is preparing a new feature to engage readers in discussing and crowdsourcing news by allowing them to add their own notes and comments to material collected and displayed.
+DocumentCloud is preparing a new feature to engage readers in discussing and crowdsourcing news by allowing them to add their own notes and comments to material collected and displayed.
 
-http://www.ft.com/intl/eu-funds[EUfunds] is collaboration between the Financial Times and the Bureau of Investigative Journalism to help readers on tracking European Union structural funds.
+EUfunds is collaboration between the Financial Times and the Bureau of Investigative Journalism to help readers on tracking European Union structural funds.
 
-https://www.drumbeat.org/en-US/journalism/about/[MoJo] is the Knight-Mozilla partnership to bring together technologists and journalists in developing innovative solutions.
+MoJo is the Knight-Mozilla partnership to bring together technologists and journalists in developing innovative solutions.
 
-http://www.a24media.com/whatsyourstory/[Africa: What's Your Story"] is a collaborative platform of the citizen news agency A24Media to implicate people from across the continent on sharing information about media freedom, corruption, health, education and other issues in video, text and audio.
+Africa: What's Your Story" is a collaborative platform of the citizen news agency A24Media to implicate people from across the continent on sharing information about media freedom, corruption, health, education and other issues in video, text and audio.
 
-The collaborative ways of treating or recirculating information and the bias for popular mobilizations are already means for important changes in this recent world of new media, big data sources and participatory culture. Even if only around 30 percent of the world population was online by the end 2010 (source: http://www.itu.int/ITU-D/ict/publications/idi/2011/index.html[2011 ITU report]), there are space for commitment to spread the principles of freedom and to share experiences, best practice and opportunities to improve the capability of citizens and other stakeholders to write/interact/play/sense the next chapters of the history of press. 
+The collaborative ways of treating or recirculating information and the bias for popular mobilizations are already means for important changes in this recent world of new media, big data sources and participatory culture. Even if only around 30 percent of the world population was online by the end 2010 (source: 2011 ITU report), there are space for commitment to spread the principles of freedom and to share experiences, best practice and opportunities to improve the capability of citizens and other stakeholders to write/interact/play/sense the next chapters of the history of press. 
 
 
 == 8. The bottom line ==
@@ -3204,7 +3301,7 @@
 
 By Sascha Venohr
 
-Data journalism projects can bring newsrooms into the exciting position to bring a Wow-Effect to the audience and give a new way of bringing stories and facts on their side. For example, there was a wide coverage about the situation at the nuclear plant in japanese Fukushima after the Tsunami. After radioactive material escaped from the power plant, everyone within 30 kilometres of the plant was evacuated. People could read and see a lot about the evacuations. ZEIT ONLINE found a innovative way to explain it's German audience the impact using data journalism. We asked: How many people live near a nuclear power plant in Germany? How many people lives within a radius of 30 kilometres? A map showes http://opendata.zeit.de/atomreaktoren/#/en/[how many people would have to be evacuated in a similar situation in Germany]. The result: A big traffic success and one of these Wow-Effects waving over the social media sphere. In addition, projects based on structured data can easily adopted to other perspectives and languages. So we did. We transponded the Map to http://opendata.zeit.de/nuclear-reactors-usa/#/en/[nuclear power plants in the US] in an english version. A great traffic-motor again.
+Data journalism projects can bring newsrooms into the exciting position to bring a Wow-Effect to the audience and give a new way of bringing stories and facts on their side. For example, there was a wide coverage about the situation at the nuclear plant in japanese Fukushima after the Tsunami. After radioactive material escaped from the power plant, everyone within 30 kilometres of the plant was evacuated. People could read and see a lot about the evacuations. ZEIT ONLINE found a innovative way to explain it's German audience the impact using data journalism. We asked: How many people live near a nuclear power plant in Germany? How many people lives within a radius of 30 kilometres? A map showes how many people would have to be evacuated in a similar situation in Germany. The result: A big traffic success and one of these Wow-Effects waving over the social media sphere. In addition, projects based on structured data can easily adopted to other perspectives and languages. So we did. We transponded the Map to nuclear power plants in the US in an english version. A great traffic-motor again.
 Another point is, that news labels want to be respected as a trusted source. Using data journalism projects combined with enabling the readers to look and reuse the raw data brings a high value of credibility to these newsrooms. Facts are sacred and they RULEZ!
 
 ### Case study 2: Texas Tribune ###
@@ -3254,7 +3351,7 @@
 
 What if we would have thousands of really experienced data-journalists, providing information on all levels of society: Locally, in regions, for countries or the world as a whole. There surely would be problems and wrong interpretations of data, too. But by and large we could hope that many investigations into data could help all of us get along better.
 
-Sometimes visualizing the results of data interrogations becomes an art, but equally often being able to show a specific development in relatively simple charts can still come as a surprise. A prime example of that is the cool http://www.nytimes.com/2011/07/24/opinion/sunday/24sun4.html["How the deficit got this big"] story from the New York Times, in which they compare the estimated and actual budgets of the US. Having a longer memory, being able to boil down something into one picture that puzzles everybody is the new scoop. Data journalism is a tool to do that. It's like switching on a light in a black room.
+Sometimes visualizing the results of data interrogations becomes an art, but equally often being able to show a specific development in relatively simple charts can still come as a surprise. A prime example of that is the cool "How the deficit got this big" story from the New York Times, in which they compare the estimated and actual budgets of the US. Having a longer memory, being able to boil down something into one picture that puzzles everybody is the new scoop. Data journalism is a tool to do that. It's like switching on a light in a black room.
 
 **4. Money is no scarce resource**
 
@@ -3327,11 +3424,11 @@
 
 Building a business
 
-End of 2010 we, then two partners, founded our company named http://www.opendatacity.de/[OpenDataCity]. There was more or less no modern data journalism happening in German media before this year.
+End of 2010 we, then two partners, founded our company named OpenDataCity. There was more or less no modern data journalism happening in German media before this year.
 
 Why did we do this? Now so often we heard from people working for newspapers and broadcasters: "No, we are not ready to put up a data journalism unit in our newsroom. But we would be happy to outsource this to someone." So we got ready.
 
-Until today we are the only company in Germany, specialized in data journalism as far as we know. Nowadays we are three partners, two of us with a journalism background and one with a deep understanding of code and visualisation. We are working within a network of a handful freelancing hackers, designers and journalists. In the last twelve month we did four data projects with newspapers, gave several trainings and consultations to media workers, scientists and journalism schools. The first app we did was an http://www.taz.de/1/berlin/fluglaerm-bbi/[interactive tool on airport noise] around the the newly built airport in Berlin. Second worth mentioning was an http://www.zeit.de/datenschutz/malte-spitz-data-retention[application about data retention] of the mobilephone usage of a German politician (.For this we won together with ZEIT Online a http://www.grimme-institut.de/html/index.php?id=1345[Grimme Online Award] and Lead Award in Germany. And in the US an Online Journalism Award by the http://journalists.org/2011/09/25/2011-online-journalism-award-winners-announced/[Online Journalism Association].
+Until today we are the only company in Germany, specialized in data journalism as far as we know. Nowadays we are three partners, two of us with a journalism background and one with a deep understanding of code and visualisation. We are working within a network of a handful freelancing hackers, designers and journalists. In the last twelve month we did four data projects with newspapers, gave several trainings and consultations to media workers, scientists and journalism schools. The first app we did was an interactive tool on airport noise around the the newly built airport in Berlin. Second worth mentioning was an application about data retention of the mobilephone usage of a German politician (.For this we won together with ZEIT Online a Grimme Online Award and Lead Award in Germany. And in the US an Online Journalism Award by the Online Journalism Association.
 
 Today, end of 2011, we are having several projects in our pipeline - ranging from more simple interactive infographics up to full blown realtime data applications.
 Of course, winning prizes helps to built a reputation. But when we talk to the publishers, who have to ok the often expensive projects our argument for investing into data journalism is not about winning prizes. It's about getting attention on a long run in a sustainable way. Building things for the long term effect, not for the scoop, which often is forgotten after some days.
@@ -3373,24 +3470,24 @@
 
 The firm undertakes about 100 projects per year, ranging in duration from a few hours to a few months. It also continuously invests in projects that expand its capacity and offerings. The celebrity monitoring service was one such experiment. Another involved scraping the Internet for news of home foreclosures and creating maps of the events. The partners say that their first criteria for projects is whether they enjoy the work and learn from it; markets are sought after a new service is defined. They make it clear that in the news industry, they found it difficult to develop new methods and new business. Comments Mulvad:
 
-"We have no editors or bosses to decide which projects we can do, which software or hardware we can buy. We can buy the tools according to project needs ‚Äì like the best solutions for text scraping and mining. Our goal is to be cutting edge in these areas. We try to get customers who are willing to pay, or if the project is fun we do it for a lower charge."
+"We have no editors or bosses to decide which projects we can do, which software or hardware we can buy. We can buy the tools according to project needs ‚Äö√Ñ√¨ like the best solutions for text scraping and mining. Our goal is to be cutting edge in these areas. We try to get customers who are willing to pay, or if the project is fun we do it for a lower charge."
 
 **2. Value created: Personal and firm brands and revenue**
 
-Turnover in 2009 was approximately 2.5 million Danish kroner, or ‚Ç¨ 336,000. The firm also sustains the partners' reputations as cutting edge journalists, which maintains demand for their teaching and speaking services. Their public appearances, in turn, support the firm's brand.
+Turnover in 2009 was approximately 2.5 million Danish kroner, or ‚Äö√á¬® 336,000. The firm also sustains the partners' reputations as cutting edge journalists, which maintains demand for their teaching and speaking services. Their public appearances, in turn, support the firm's brand.
 
 **3. Key insights of this example**
 
-‚Ä¢	The news industry's crisis of declining capacity is also a crisis of under-utilisation of capacity. Kaas and Mulvad had to leave the news industry to do work they valued, and that pays. Nothing prevented a news organisation from capturing that value.
+‚Äö√Ñ¬¢	The news industry's crisis of declining capacity is also a crisis of under-utilisation of capacity. Kaas and Mulvad had to leave the news industry to do work they valued, and that pays. Nothing prevented a news organisation from capturing that value.
 
-‚Ä¢ 	In at least some markets, there exists a profitable market for semi-finished content that serves the interests of stakeholder groups.
+‚Äö√Ñ¬¢ 	In at least some markets, there exists a profitable market for semi-finished content that serves the interests of stakeholder groups.
 
-‚Ä¢	However, this opportunity raises the issue of how much control journalists can exercise over the presentation and use of their work by third parties. We recall that this issue already exists within the news industry (where editors can impose changes on a journalist's product), and it has existed within other media industries (such as the film industry, where conflicts between directors and studios over "final cuts" are hardly rare). It is not a particular moral hazard of stakeholder media.
+‚Äö√Ñ¬¢	However, this opportunity raises the issue of how much control journalists can exercise over the presentation and use of their work by third parties. We recall that this issue already exists within the news industry (where editors can impose changes on a journalist's product), and it has existed within other media industries (such as the film industry, where conflicts between directors and studios over "final cuts" are hardly rare). It is not a particular moral hazard of stakeholder media.
 
-‚Ä¢	From a revenue standpoint, a single product or service is not enough. Successful watchdog enterprises would do better to take a portfolio approach, in which consulting, teaching, speaking and other services bring in extra revenue, support the watchdog brand, and enrich the lifestyle of the operators.
+‚Äö√Ñ¬¢	From a revenue standpoint, a single product or service is not enough. Successful watchdog enterprises would do better to take a portfolio approach, in which consulting, teaching, speaking and other services bring in extra revenue, support the watchdog brand, and enrich the lifestyle of the operators.
 
 
-=== When code pays for words by Cl√©ment Renaud (Sharism Lab?) ===
+=== When code pays for words by Clément Renaud (Sharism Lab?) ===
 
 Example from OWNI
 
@@ -3403,84 +3500,83 @@
 
 Data Blogs
 
-http://blogs.montrealgazette.com/category/montreal/data-points/[http://blogs.montrealgazette.com/category/montreal/data-points/]
-http://onlinejournalismblog.com/[http://onlinejournalismblog.com/]
-Hard core: http://thingsivelearned.posterous.com/[http://thingsivelearned.posterous.com/]
-http://datadrivenjournalism.net[http://datadrivenjournalism.net]
-http://www.datajournalismblog.com/[http://www.datajournalismblog.com/]
-http://www.calculatedriskblog.com/[http://www.calculatedriskblog.com/]
-http://www.datauncovered.com/about[http://www.datauncovered.com/about]
-http://blogs.channel4.com/factcheck/[http://blogs.channel4.com/factcheck/]
-http://www.freakonomics.com/blog/[http://www.freakonomics.com/blog/]
-http://www.guardian.co.uk/news/datablog[http://www.guardian.co.uk/news/datablog]
-http://localdata.citizenshipfoundation.org.uk/[http://localdata.citizenshipfoundation.org.uk/]
-http://www.madwdata.org.uk/blog[http://www.madwdata.org.uk/blog]
-http://www.propublica.org/tools/[http://www.propublica.org/tools/]
-http://blog.timetric.com/[http://blog.timetric.com/]
-https://wikileaksdatajournalism.wordpress.com/[https://wikileaksdatajournalism.wordpress.com/]
+http://blogs.montrealgazette.com/category/montreal/data-points/
+http://onlinejournalismblog.com/
+Hard core: http://thingsivelearned.posterous.com/
+http://datadrivenjournalism.net
+http://www.datajournalismblog.com/
+http://www.calculatedriskblog.com/
+http://www.datauncovered.com/about
+http://blogs.channel4.com/factcheck/
+http://www.freakonomics.com/blog/
+http://www.guardian.co.uk/news/datablog
+http://localdata.citizenshipfoundation.org.uk/
+http://www.madwdata.org.uk/blog
+http://www.propublica.org/tools/
+http://blog.timetric.com/
+https://wikileaksdatajournalism.wordpress.com/
 
 FOI blogs
 
-http://heatherbrooke.org/[http://heatherbrooke.org/]
+http://heatherbrooke.org/
 
 Tech Discussion
 
-http://gigaom.com/cloud/[http://gigaom.com/cloud/]
-http://highscalability.com/[http://highscalability.com/]
+http://gigaom.com/cloud/
+http://highscalability.com/
 
 Data Visualization Blogs:
 Stephen Few's Perceptual Edge
-http://www.perceptualedge.com/examples.php[http://www.perceptualedge.com/examples.php]
+http://www.perceptualedge.com/examples.php
 David McCandless's Information is Beautiful
-http://www.informationisbeautiful.net/[http://www.informationisbeautiful.net/]
+http://www.informationisbeautiful.net/
 Doug McCune's Adobe Flex- and ActionScript-focused blog:
-http://dougmccune.com/blog/[http://dougmccune.com/blog/]
-http://flowingdata.com/[http://flowingdata.com/]
-http://infosthetics.com/[http://infosthetics.com/]
-http://www.pdviz.com/[http://www.pdviz.com/]
-http://chartporn.org/[http://chartporn.org/]
-http://eagereyes.org/[http://eagereyes.org/]
-http://visualoop.tumblr.com/[http://visualoop.tumblr.com/]
+http://dougmccune.com/blog/
+http://flowingdata.com/
+http://infosthetics.com/
+http://www.pdviz.com/
+http://chartporn.org/
+http://eagereyes.org/
+http://visualoop.tumblr.com/
 
 Examples
 
 TODO: group by chapter
 
-
-http://www.nytimes.com/interactive/2011/10/23/sunday-review/an-overview-of-the-euro-crisis.html[http://www.nytimes.com/interactive/2011/10/23/sunday-review/an-overview-of-the-euro-crisis.html]
+http://www.nytimes.com/interactive/2011/10/23/sunday-review/an-overview-of-the-euro-crisis.html
 The New York Times' interactive tool, allowing you both to check a few different standard perspectives (links on the left) and to explore the landscape on your own (hover/click on particular countries).
 
-http://www.oecdbetterlifeindex.org/[http://www.oecdbetterlifeindex.org/]
+http://www.oecdbetterlifeindex.org/
 Combines data on political support for, and citizens' opinions of, various aspects of their quality of life. Enables each use both to compare among countries and to see how countries rank relative to their own priorities.
 
-http://www.gapminder.org/[http://www.gapminder.org/]
+http://www.gapminder.org/
 The classic example of a site that permits the telling of many different historical back-stories to key social issues of today.
 
-http://www.politifact.com/subjects/afghanistan/[http://www.politifact.com/subjects/afghanistan/]
+http://www.politifact.com/subjects/afghanistan/
 An example of how political dialogue can be partially visualized according to its relative "truthiness." There are may examples at politifact.com; this is just one.
 
-http://poligraft.com/[http://poligraft.com/]
+http://poligraft.com/
 A project of the Sunlight Foundation (which has many excellent projects), this particular one allows the addition of influence-peddling metadata to an existing article or blog post via the submission of plain text or the URL.
 
 Crowd sourcing data:
-http://www.bbc.co.uk/news/technology-14644507[http://www.bbc.co.uk/news/technology-14644507]
+http://www.bbc.co.uk/news/technology-14644507
 Many examples - investigate further...
-http://greatjournalism.net/[http://greatjournalism.net/]
+http://greatjournalism.net/
 
 Case Studies FOI :
 
 
-Campaign for Freedom of Information www.cfoi.org.uk[www.cfoi.org.uk] has summaries, e.g. http://www.cfoi.org.uk/pdf/FOIStories2006-07.pdf[http://www.cfoi.org.uk/pdf/FOIStories2006-07.pdf]
-BBC Open Secrets blog: http://www.bbc.co.uk/blogs/opensecrets/2011/04/commissioner_attacks_cabinet_office_foi_delays.html[http://www.bbc.co.uk/blogs/opensecrets/2011/04/commissioner_attacks_cabinet_office_foi_delays.html]
+Campaign for Freedom of Information www.cfoi.org.uk has summaries, e.g. http://www.cfoi.org.uk/pdf/FOIStories2006-07.pdf
+BBC Open Secrets blog: http://www.bbc.co.uk/blogs/opensecrets/2011/04/commissioner_attacks_cabinet_office_foi_delays.html
 The BBC News website contains a section featuring selected news stories obtained under freedom of information - http://news.bbc.co.uk/1/hi/in_depth/uk/2006/foi/default.stm.
-Guardian http://www.guardian.co.uk/politics/freedomofinformation[http://www.guardian.co.uk/politics/freedomofinformation]
-Legal Leaks: we have a couple of stories, one from Bulgaria one from Spain, and plan to put up more: http://www.legalleaks.info/blog.html[http://www.legalleaks.info/blog.html]
-See also the excellent study released by AP: https://www.facebook.com/note.php?note_id=10150914656220651[https://www.facebook.com/note.php?note_id=10150914656220651]
+Guardian http://www.guardian.co.uk/politics/freedomofinformation
+Legal Leaks: we have a couple of stories, one from Bulgaria one from Spain, and plan to put up more: http://www.legalleaks.info/blog.html
+See also the excellent study released by AP: https://www.facebook.com/note.php?note_id=10150914656220651
 
 Tools
 
 Investigative Dashboard
-Access Social data, analyze it, and get value from it. http://blog.datasift.com/ ? Include[http://blog.datasift.com/] ? Include
+Access Social data, analyze it, and get value from it. http://blog.datasift.com/ ? Include
 
 
 
@@ -3489,34 +3585,34 @@
 Resources for FOI:
 
 
-‚Ä¢ Reporters Committee for Freedom of the Press http://www.rcfp.org/foialetter/index.php[FOIA Letter Generator]
-‚Ä¢ National Freedom of Information Coalition http://www.nfoic.org/sample-foia-letters[sample FOIA letters]
-‚Ä¢ http://www.foiadvocates.net/[FOIAnet]"
+‚Äö√Ñ¬¢ Reporters Committee for Freedom of the Press FOIA Letter Generator
+‚Äö√Ñ¬¢ National Freedom of Information Coalition sample FOIA letters
+‚Äö√Ñ¬¢ FOIAnet"
 
 Learn to code
 
-http://lifehacker.com/5863823/ask-and-answer-questions-about-coding[Coding Q and A]
-http://www.codecademy.com/[Code Academy (beginning lesson = JavaScript)]
+Coding Q and A
+Code Academy (beginning lesson = JavaScript)
 
 
 
 Ruby
-http://datadrivenjournalism.net/resources/the_bastards_book_of_ruby[The Bastards Book of Ruby]
-http://hackety.com/[Hackety Hack]
-http://railscasts.com/[Rails Casts]
+The Bastards Book of Ruby
+Hackety Hack
+Rails Casts
 
 
 Python
-http://greenteapress.com/thinkpython/[Think Python]
-http://learnpythonthehardway.org/[Learn Python The Hard Way]
-http://stephensugden.com/crash_into_python/[Crash into Python]
-http://www.khanacademy.org/#computer-science[Khan Academy]
+Think Python
+Learn Python The Hard Way
+Crash into Python
+Khan Academy
 
 
 CSS
-http://learncss.tutsplus.com/[Learn Html & CSS in 30 days]
+Learn Html & CSS in 30 days
 Javascript
-http://nathansjslessons.appspot.com/lesson?id=1000[Nathan's Lessons]
+Nathan's Lessons
 
 
 Communities
